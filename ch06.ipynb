{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "remove=('headers', 'footers', 'quotes'),\n",
    "categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    categories=categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cachedStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
    "english_stops = set(cachedStopWords)\n",
    "english_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower())\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    features = list(map(lambda token: PorterStemmer().stem(token), words))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2034x20085 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 133319 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1353x20085 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 86961 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616519174041298"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7605321507760532"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#138p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2000, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 2000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 2000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.61800229e-03, 5.90022378e-03, 5.36769541e-03, ...,\n",
       "       5.04719177e-35, 4.30496364e-35, 3.58379128e-35])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616519174041298"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7605321507760532"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7900688298918387"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7184035476718403"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lasso_clf.coef_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=321, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 321)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 321)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43713822276498226"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8746312684365781"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7509238728750924"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 140 page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2107984947279019"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8072763028515241"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738359201773836"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=2000, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TruncatedSVD(n_components=2000, random_state=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD(n_components=2000, random_state=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TruncatedSVD(n_components=2000, random_state=7)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = svd.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 2000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 2000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.fit(X_train_lsa, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616519174041298"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_train_lsa, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7605321507760532"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_test_lsa, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#144 잠재의미분석 100개 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2086660366146553\n",
      "0.8102261553588987\n",
      "0.7450110864745011\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=1)\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = svd.transform(X_test_tfidf)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "LR_clf.fit(X_train_lsa, y_train)\n",
    "print(LR_clf.score(X_train_lsa, y_train))\n",
    "print(LR_clf.score(X_test_lsa, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#145p lsa 이용 문서 간 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.03997949, 0.0188936 , ..., 0.18398695, 0.01109302,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_result = cosine_similarity([X_train_lsa[0]], X_train_lsa)\n",
    "sim_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sim_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.04, 0.02, ..., 0.18, 0.01, 0.  ])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_result[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.74, 0.74, 0.72, 0.7, 0.7, 0.69, 0.67, 0.66, 0.65]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sim_result[0].round(2), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.03997949, 0.0188936 , ..., 0.18398695, 0.01109302,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -0.03997949, -0.0188936 , ..., -0.18398695,\n",
       "       -0.01109302, -0.        ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-sim_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -133, -1243,   -12, ..., -1674, -1957,     0], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-sim_result[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -0.03997949, -0.0188936 , ..., -0.18398695,\n",
       "       -0.01109302, -0.        ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-sim_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1957, 1674, ...,   12, 1243,  133], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-sim_result[0]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1957, 1674,  501, 1995, 1490,  790, 1902, 1575, 1209],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_index = (-sim_result[0]).argsort()[:10]\n",
    "sim_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y_train[i] for i in sim_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'comp.graphics']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[newsgroups_train.target_names[y_train[i]] for i in sim_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 146 ifidF로 하면 어떤가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.00356479, 0.        , ..., 0.02546912, 0.00976539,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_result = cosine_similarity(X_train_tfidf[0], X_train_tfidf)\n",
    "sim_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x20085 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 36 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.22224900e-01,  1.39746377e-01, -1.57423309e-01, -2.46461193e-02,\n",
       "       -6.76315261e-03,  1.25175316e-01,  1.53389442e-01,  1.63682256e-01,\n",
       "       -8.92082203e-02,  4.42711458e-02,  5.13158390e-02, -4.64975485e-02,\n",
       "        5.63647967e-02, -8.42787243e-02, -3.97329413e-02,  1.66242932e-02,\n",
       "        3.89466573e-02, -1.31160688e-02, -8.70584560e-03, -2.13730289e-02,\n",
       "       -8.58229287e-03,  1.93537190e-02, -3.42789565e-02, -3.10810631e-02,\n",
       "       -5.72877947e-02, -2.78641147e-02,  5.70231345e-02, -2.54288286e-02,\n",
       "        7.89685936e-02, -3.24719631e-02,  3.13095268e-03,  2.05738874e-03,\n",
       "        3.77557558e-02, -8.39914815e-03,  6.80248400e-02,  5.60560010e-05,\n",
       "        6.99739014e-02, -1.53777116e-02,  6.95543113e-03,  5.52281667e-02,\n",
       "        1.44068877e-02,  6.56036296e-02, -1.54072425e-02,  1.92320502e-02,\n",
       "       -2.23767293e-02, -1.82884461e-02, -6.47586412e-03, -4.07359997e-02,\n",
       "       -2.75240599e-02,  2.54490749e-02, -5.67970065e-02,  1.87402792e-02,\n",
       "       -2.14327970e-02,  1.95532269e-03,  4.16299755e-02,  5.87366630e-03,\n",
       "        5.51554393e-02,  5.55793579e-02,  2.08514416e-02, -9.32587158e-02,\n",
       "        3.17480634e-02,  3.64671999e-03, -1.66652502e-02,  1.44307216e-02,\n",
       "       -5.86358301e-03,  3.66727608e-03,  1.41308983e-02, -5.01634823e-02,\n",
       "       -3.21951963e-02,  3.96663740e-02,  1.01307022e-02,  4.56181282e-02,\n",
       "        4.13069106e-02,  2.57744343e-02,  1.40866726e-02, -3.67245427e-02,\n",
       "        2.00006780e-02, -2.58287700e-02,  8.19923120e-03, -2.75165608e-02,\n",
       "       -1.95093264e-02,  4.52228306e-03, -3.12727296e-04, -3.74829219e-03,\n",
       "       -1.53202604e-04,  4.51250422e-02,  5.09315330e-02, -4.86902800e-02,\n",
       "       -5.16043109e-02, -4.66452634e-03,  6.26612490e-02,  1.29923571e-02,\n",
       "        4.66852803e-02,  3.92141540e-03,  2.38607467e-02,  4.04087438e-02,\n",
       "        7.45296202e-03, -1.00482140e-02, -5.55958755e-02,  3.87747194e-02])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lsa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.3,\n",
       " 0.22,\n",
       " 0.21,\n",
       " 0.19,\n",
       " 0.19,\n",
       " 0.19,\n",
       " 0.17,\n",
       " 0.16,\n",
       " 0.16,\n",
       " 0.16,\n",
       " 0.15,\n",
       " 0.15,\n",
       " 0.15,\n",
       " 0.15,\n",
       " 0.15,\n",
       " 0.15,\n",
       " 0.15,\n",
       " 0.15,\n",
       " 0.14,\n",
       " 0.14,\n",
       " 0.14,\n",
       " 0.14,\n",
       " 0.14,\n",
       " 0.14,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.12,\n",
       " 0.12,\n",
       " 0.12,\n",
       " 0.12,\n",
       " 0.12,\n",
       " 0.12,\n",
       " 0.12,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.09,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.06,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sim_result[0].round(2), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1575, 1892, 1490,  501, 1290, 1013,  998, 1636, 1705],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_index = (-sim_result[0]).argsort()[:10]\n",
    "sim_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y_train[i] for i in sim_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#147 토픽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=10, random_state=1)\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = svd.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 10)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 10)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0450355815145758"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'20'\", \"'27\", \"'30'\", ..., 'zware', 'zwart', 'zyxel'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = tfidf.get_feature_names_out()\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20085)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20085"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.95072043e-04, 7.35703363e-04, 1.03296980e-03, ...,\n",
       "       3.56108314e-06, 7.12216629e-06, 5.51870437e-04])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20085"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svd.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(model, feature_names, n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(idx+1, [feature_names[i] for i in topic.argsort()[:-n-1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['would', 'one', 'god', 'think', 'use', 'peopl', 'know', 'like', 'say', 'space']\n",
      "2 ['file', 'imag', 'thank', 'program', 'graphic', 'space', 'format', 'use', 'color', 'ftp']\n",
      "3 ['space', 'orbit', 'nasa', 'launch', 'shuttl', 'satellit', 'year', 'moon', 'lunar', 'cost']\n",
      "4 ['moral', 'object', 'system', 'valu', 'goal', 'think', 'anim', 'absolut', 'natur', 'defin']\n",
      "5 ['ico', 'bobb', 'tek', 'beauchain', 'bronx', 'manhattan', 'sank', 'queen', 'vice', 'blew']\n",
      "6 ['god', 'file', 'imag', 'object', 'moral', 'exist', 'space', 'format', 'system', 'color']\n",
      "7 ['file', 'islam', 'imag', 'cview', 'use', 'format', 'color', 'muslim', 'religion', 'peopl']\n",
      "8 ['post', 'file', 'space', 'islam', 'read', 'cview', 'format', 'articl', 'group', 'moral']\n",
      "9 ['christian', 'graphic', 'imag', 'jesu', 'book', 'data', 'group', 'softwar', 'law', 'code']\n",
      "10 ['exist', 'atheism', 'atheist', 'graphic', 'delet', 'post', 'god', 'one', 'group', 'newsgroup']\n"
     ]
    }
   ],
   "source": [
    "get_topics(svd, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#149p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, min_df=5, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1000)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=1)\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 100)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1000)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.singular_values_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.99024928,  5.08550206,  4.736259  ,  4.13912119,  3.83626047,\n",
       "        3.60949021,  3.49158055,  3.43277087,  3.28437202,  3.20352217,\n",
       "        3.15439783,  3.11720268,  3.07133602,  3.05618627,  3.01348331,\n",
       "        2.98376499,  2.95458416,  2.94555221,  2.89641994,  2.88934897,\n",
       "        2.85179776,  2.83107471,  2.82284905,  2.79625028,  2.77161204,\n",
       "        2.75636914,  2.7448653 ,  2.719103  ,  2.67491726,  2.66405658,\n",
       "        2.65136024,  2.63460323,  2.61721653,  2.61689242,  2.59826367,\n",
       "        2.57925288,  2.56848696,  2.56097225,  2.54782903,  2.53003601,\n",
       "        2.50824379,  2.50406459,  2.4945412 ,  2.48473988,  2.47921061,\n",
       "        2.47131298,  2.45848917,  2.44503912,  2.43004866,  2.41240103,\n",
       "        2.39805249,  2.38635173,  2.37919284,  2.37413574,  2.35827326,\n",
       "        2.35795264,  2.35363901,  2.3378803 ,  2.32596349,  2.31265179,\n",
       "        2.30507953,  2.29697583,  2.29312268,  2.28564945,  2.27348261,\n",
       "        2.26912426,  2.25477336,  2.25063822,  2.24669823,  2.24432466,\n",
       "        2.23483401,  2.22107964,  2.20975485,  2.20004179,  2.19491545,\n",
       "        2.18930397,  2.17440495,  2.17008969,  2.16806207,  2.16213797,\n",
       "        2.15199651,  2.13794127,  2.13110069,  2.1245736 ,  2.11692642,\n",
       "        2.10048233,  2.09338806,  2.08018668,  2.07285048,  2.0676536 ,\n",
       "        2.05679707,  2.04738347,  2.03758385,  2.03018996,  2.02412908,\n",
       "        2.01614408,  2.00619087,  2.00175623,  1.99223766,  1.97933121])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08711007,  0.13536259,  0.20657465, ...,  1.26819104,\n",
       "         0.12127331,  0.04912362],\n",
       "       [ 0.09463711,  0.0924609 ,  0.14505065, ..., -0.69568983,\n",
       "        -0.06441922,  0.07170835],\n",
       "       [ 0.0506618 , -0.08587566, -0.07368785, ...,  0.67561283,\n",
       "         0.04810798,  0.07914622],\n",
       "       ...,\n",
       "       [-0.09926485,  0.0015824 ,  0.02778213, ..., -0.04092142,\n",
       "        -0.03108177, -0.00442776],\n",
       "       [ 0.00183211,  0.03967254,  0.05398316, ..., -0.06812015,\n",
       "        -0.00891261, -0.01131418],\n",
       "       [-0.02069885, -0.1349022 , -0.08888969, ...,  0.07721648,\n",
       "         0.00947348, -0.06003868]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(svd.singular_values_).dot(svd.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1000)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(svd.singular_values_).dot(svd.components_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08711007,  0.09463711,  0.0506618 , ..., -0.09926485,\n",
       "         0.00183211, -0.02069885],\n",
       "       [ 0.13536259,  0.0924609 , -0.08587566, ...,  0.0015824 ,\n",
       "         0.03967254, -0.1349022 ],\n",
       "       [ 0.20657465,  0.14505065, -0.07368785, ...,  0.02778213,\n",
       "         0.05398316, -0.08888969],\n",
       "       ...,\n",
       "       [ 1.26819104, -0.69568983,  0.67561283, ..., -0.04092142,\n",
       "        -0.06812015,  0.07721648],\n",
       "       [ 0.12127331, -0.06441922,  0.04810798, ..., -0.03108177,\n",
       "        -0.00891261,  0.00947348],\n",
       "       [ 0.04912362,  0.07170835,  0.07914622, ..., -0.00442776,\n",
       "        -0.01131418, -0.06003868]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_words = np.diag(svd.singular_values_).dot(svd.components_).T\n",
    "t_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.23790538e-01,  1.16044954e+00, -7.14932330e-01,  1.74270247e+00,\n",
       "        2.92788076e-01, -2.81005032e-01,  6.18394915e-01,  9.77813968e-01,\n",
       "        8.57532623e-01, -3.18066922e-02,  5.69219802e-02, -1.25622563e-01,\n",
       "       -4.57637488e-01, -4.28695037e-01, -1.83563320e-01, -4.64849086e-01,\n",
       "       -4.47170510e-02, -8.82377609e-02,  3.52408556e-01,  4.71765415e-01,\n",
       "       -1.55008175e-01, -1.70104039e-01, -1.59044262e-01,  1.15446128e-01,\n",
       "       -4.00053771e-01,  3.80213519e-01,  2.71960009e-01,  2.81819907e-01,\n",
       "        2.15995362e-01,  9.25286366e-02,  5.12706664e-03, -2.11818309e-01,\n",
       "        9.50767276e-02, -6.91903478e-02, -2.20314468e-01, -1.67044073e-02,\n",
       "       -1.74854960e-01, -1.39904743e-01, -1.37699873e-01,  9.10811519e-02,\n",
       "        5.82056450e-02, -1.09023401e-01,  1.08770713e-02, -2.04214889e-01,\n",
       "       -1.30902315e-01, -3.15917278e-02, -5.64039279e-02,  2.38626142e-01,\n",
       "       -2.18891767e-02, -8.83351703e-02, -7.57441051e-02,  1.89123498e-01,\n",
       "       -6.14792892e-02, -8.19583730e-02,  9.92303787e-02, -1.00255517e-01,\n",
       "       -7.30951558e-02, -5.21633993e-02, -5.09575264e-02,  2.34388521e-01,\n",
       "       -2.38281574e-01, -1.41991550e-02, -4.84959336e-02, -3.86313593e-02,\n",
       "       -1.50024484e-02,  2.55482535e-01, -5.39553937e-02, -7.23128871e-02,\n",
       "        9.36014647e-02, -1.12739218e-01,  6.66537965e-03, -1.31873557e-01,\n",
       "       -1.10878407e-01,  3.46421033e-02, -3.76572635e-02, -1.23788879e-01,\n",
       "        1.22324154e-01, -2.10406539e-01, -9.16373932e-02,  1.69814614e-01,\n",
       "       -5.26658850e-02,  1.52352015e-03,  5.33574822e-02, -2.65169577e-02,\n",
       "       -8.59754876e-03, -1.15319105e-02,  2.89306856e-02,  2.17422891e-02,\n",
       "       -6.10427698e-02,  5.23098096e-02, -1.06411117e-01,  8.88743685e-03,\n",
       "       -1.48287106e-02, -1.18398570e-02, -6.52195443e-02, -3.46517636e-02,\n",
       "       -1.63389467e-01,  4.14201731e-02,  8.61179536e-02, -6.77213203e-02])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_words[np.where(tfidf.get_feature_names_out() == 'space')[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_words[np.where(tfidf.get_feature_names_out() == 'space')[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.23790538e-01,  1.16044954e+00, -7.14932330e-01,  1.74270247e+00,\n",
       "        2.92788076e-01, -2.81005032e-01,  6.18394915e-01,  9.77813968e-01,\n",
       "        8.57532623e-01, -3.18066922e-02,  5.69219802e-02, -1.25622563e-01,\n",
       "       -4.57637488e-01, -4.28695037e-01, -1.83563320e-01, -4.64849086e-01,\n",
       "       -4.47170510e-02, -8.82377609e-02,  3.52408556e-01,  4.71765415e-01,\n",
       "       -1.55008175e-01, -1.70104039e-01, -1.59044262e-01,  1.15446128e-01,\n",
       "       -4.00053771e-01,  3.80213519e-01,  2.71960009e-01,  2.81819907e-01,\n",
       "        2.15995362e-01,  9.25286366e-02,  5.12706664e-03, -2.11818309e-01,\n",
       "        9.50767276e-02, -6.91903478e-02, -2.20314468e-01, -1.67044073e-02,\n",
       "       -1.74854960e-01, -1.39904743e-01, -1.37699873e-01,  9.10811519e-02,\n",
       "        5.82056450e-02, -1.09023401e-01,  1.08770713e-02, -2.04214889e-01,\n",
       "       -1.30902315e-01, -3.15917278e-02, -5.64039279e-02,  2.38626142e-01,\n",
       "       -2.18891767e-02, -8.83351703e-02, -7.57441051e-02,  1.89123498e-01,\n",
       "       -6.14792892e-02, -8.19583730e-02,  9.92303787e-02, -1.00255517e-01,\n",
       "       -7.30951558e-02, -5.21633993e-02, -5.09575264e-02,  2.34388521e-01,\n",
       "       -2.38281574e-01, -1.41991550e-02, -4.84959336e-02, -3.86313593e-02,\n",
       "       -1.50024484e-02,  2.55482535e-01, -5.39553937e-02, -7.23128871e-02,\n",
       "        9.36014647e-02, -1.12739218e-01,  6.66537965e-03, -1.31873557e-01,\n",
       "       -1.10878407e-01,  3.46421033e-02, -3.76572635e-02, -1.23788879e-01,\n",
       "        1.22324154e-01, -2.10406539e-01, -9.16373932e-02,  1.69814614e-01,\n",
       "       -5.26658850e-02,  1.52352015e-03,  5.33574822e-02, -2.65169577e-02,\n",
       "       -8.59754876e-03, -1.15319105e-02,  2.89306856e-02,  2.17422891e-02,\n",
       "       -6.10427698e-02,  5.23098096e-02, -1.06411117e-01,  8.88743685e-03,\n",
       "       -1.48287106e-02, -1.18398570e-02, -6.52195443e-02, -3.46517636e-02,\n",
       "       -1.63389467e-01,  4.14201731e-02,  8.61179536e-02, -6.77213203e-02])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = t_words[np.where(tfidf.get_feature_names_out() == 'space')[0][0]]\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_result = cosine_similarity([source], t_words)\n",
    "len(sim_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.66001727e-02,  1.51647939e-01,  2.54089060e-01,  1.87075445e-01,\n",
       "        2.17772901e-01,  2.67740694e-01,  2.30914409e-01,  2.43851900e-01,\n",
       "        3.43433100e-01,  2.93004757e-01,  1.69359820e-01,  1.03591061e-01,\n",
       "        3.25371440e-01,  2.33060858e-01,  1.73347398e-01,  1.58144352e-01,\n",
       "        3.52891636e-02,  2.24476246e-01,  8.83590882e-02,  1.28772901e-01,\n",
       "        2.88869383e-02,  1.86572382e-01,  3.48478005e-02,  2.19203584e-01,\n",
       "        3.29555350e-01,  1.98542693e-01, -6.10364986e-03,  6.70400681e-02,\n",
       "        1.06277182e-01,  4.23604400e-01,  1.33797145e-01,  1.34827158e-01,\n",
       "        9.33808207e-02,  5.48567985e-02,  9.76480932e-03,  2.41879231e-01,\n",
       "        7.51346316e-02,  1.89420827e-01,  1.52342396e-01,  6.40601483e-03,\n",
       "        4.66627139e-01,  7.82408114e-02,  1.31964529e-01,  1.38528953e-01,\n",
       "        1.88807957e-01,  1.22793995e-01,  2.04636969e-03,  2.00804408e-01,\n",
       "        8.73645107e-02,  3.40491722e-02,  1.87172967e-01,  5.31675103e-02,\n",
       "        3.93757890e-01,  8.43255855e-03,  1.00907333e-01, -9.41457367e-03,\n",
       "        4.36289026e-02,  1.17310102e-01,  1.78614295e-01,  8.93831908e-02,\n",
       "        2.35984629e-01,  5.31549813e-02,  1.59502316e-01,  1.43102742e-01,\n",
       "        6.55116218e-02,  2.76646016e-01,  2.07057315e-01,  3.18546199e-02,\n",
       "        1.51789791e-01,  1.64786499e-01,  2.02687112e-01,  3.19450820e-02,\n",
       "        2.71661316e-01,  7.25810868e-02,  6.04216958e-02,  7.76575744e-02,\n",
       "       -2.66550719e-03,  6.68437921e-02,  4.20523470e-02,  9.25373412e-02,\n",
       "        1.12149333e-01,  9.76759617e-02,  9.04845562e-02,  3.07396531e-01,\n",
       "        2.79416129e-02,  4.52393575e-02,  1.45785359e-01,  1.90200213e-01,\n",
       "        3.92742177e-01,  1.41452921e-01,  3.57883892e-01,  5.91888587e-02,\n",
       "       -8.49410102e-03, -1.06011999e-02,  2.55801810e-01,  1.33581089e-01,\n",
       "        1.25631833e-01,  1.91139005e-01,  8.53500199e-02,  1.52813802e-01,\n",
       "        2.31467729e-02,  5.17999935e-01,  2.97771209e-01,  3.13196855e-01,\n",
       "        2.11561993e-01, -3.87718706e-03,  1.55995131e-03,  2.09267475e-04,\n",
       "        3.28519773e-01,  8.47829935e-02,  1.06945091e-01,  4.08039755e-03,\n",
       "        2.32023367e-01,  4.40237055e-02,  1.82474396e-01,  7.82355281e-02,\n",
       "        1.91770302e-01,  2.81046856e-01,  1.17633275e-01,  1.72656251e-01,\n",
       "        8.26628205e-02,  1.93445709e-01,  3.08504422e-02,  9.22429303e-02,\n",
       "        1.16130937e-01,  1.76220422e-01,  1.83854755e-01,  5.07966429e-03,\n",
       "       -7.35507313e-03,  8.23477444e-02,  2.02221501e-01,  1.47179345e-01,\n",
       "        1.48625461e-01,  1.07579544e-01,  1.00429607e-01, -1.45847212e-02,\n",
       "       -7.62564072e-04,  1.63248935e-01,  6.16298784e-02,  3.35113617e-01,\n",
       "        7.10205643e-02,  1.18439441e-01,  1.29138048e-01,  5.71062742e-02,\n",
       "        6.34279978e-03,  2.93831365e-01,  5.64523807e-02,  8.75943675e-02,\n",
       "        1.58851782e-01,  2.54187716e-01,  4.64085542e-01,  2.65019041e-01,\n",
       "        1.50159342e-01,  2.18564748e-01,  1.67042732e-01,  9.41508869e-02,\n",
       "        2.11696059e-01,  2.72556448e-01,  4.82433660e-02,  1.17405902e-01,\n",
       "        1.20101050e-01,  1.68620216e-01,  3.79222935e-02, -9.69042671e-03,\n",
       "        3.47442188e-02,  9.38556832e-02,  1.29182182e-01,  1.95193832e-02,\n",
       "        3.12332581e-01,  1.40164278e-01,  1.38754827e-01,  1.48512820e-01,\n",
       "        1.23073479e-01,  1.52364306e-02,  5.94665366e-02,  2.67116941e-02,\n",
       "       -6.96304336e-03, -1.63153579e-02, -1.83611613e-02, -1.49469642e-02,\n",
       "       -1.32776665e-02,  1.10619792e-01,  3.97970675e-02,  5.51213367e-02,\n",
       "        1.67365608e-01,  1.13994483e-01,  1.28992943e-01,  2.55018767e-01,\n",
       "        1.62520748e-04,  1.20533968e-01,  3.41507017e-02,  4.97599449e-02,\n",
       "        6.98844878e-02,  7.40720432e-02,  5.95891287e-02,  2.15181673e-01,\n",
       "        4.34033344e-01,  5.33316791e-02,  1.44786048e-02,  1.69030293e-01,\n",
       "        1.12133489e-01,  2.02928714e-01,  3.29262809e-02,  1.66634575e-01,\n",
       "       -9.47627835e-03,  2.00118875e-01,  8.51742510e-02,  9.61898850e-02,\n",
       "        1.89853697e-01,  8.34000488e-02, -2.92574156e-03,  2.29595002e-01,\n",
       "        6.11743886e-02, -1.09619521e-02,  1.46589673e-01,  5.28219602e-02,\n",
       "        3.19090580e-01,  1.92874398e-01,  9.28062686e-02,  2.34739108e-01,\n",
       "        6.57577543e-02,  1.51388340e-01,  5.02349219e-02,  1.65104394e-02,\n",
       "        1.08480470e-01,  1.70931121e-01,  2.59682002e-01,  3.16127090e-01,\n",
       "        1.25195575e-01,  3.53307866e-01,  3.63162491e-02,  2.68106909e-01,\n",
       "        3.59109370e-01,  3.02431211e-01,  1.48080869e-01,  1.39280076e-01,\n",
       "        2.96087579e-01,  4.14650054e-02,  1.02316948e-02, -3.08240670e-02,\n",
       "        2.15032021e-03,  3.92286102e-02,  1.31048676e-01,  7.35651659e-02,\n",
       "        3.75670683e-01,  2.78504444e-01,  1.60538447e-01,  3.30643659e-01,\n",
       "        2.66856078e-01,  5.22901214e-02,  1.06407385e-01,  1.71154534e-02,\n",
       "        5.45373814e-02,  8.66400098e-02,  4.69412413e-02,  2.07337023e-01,\n",
       "        1.74955904e-01,  6.62773502e-02,  2.64082324e-01,  8.16736549e-02,\n",
       "        1.51452719e-01,  8.41045674e-02,  6.34554351e-02,  1.84598010e-02,\n",
       "        3.16208724e-02,  6.11937514e-02,  1.59124337e-01,  3.92130408e-02,\n",
       "        5.55274972e-02,  2.02087810e-01,  3.14804104e-01,  2.83141385e-02,\n",
       "        4.82488297e-02,  4.96225052e-02,  2.38560474e-01,  1.22329390e-01,\n",
       "        5.76998536e-02,  2.58594103e-01,  2.36797615e-01, -3.68820245e-04,\n",
       "        3.50697356e-02,  9.93711573e-02,  3.22499706e-01,  5.98232451e-02,\n",
       "        1.67926670e-01,  1.21221720e-01,  1.84551849e-01,  3.28638703e-01,\n",
       "        2.34591136e-01,  1.85165770e-01,  1.51578945e-01,  2.51985465e-01,\n",
       "        3.00182026e-01,  2.81870445e-02,  1.58160179e-01,  1.98583765e-01,\n",
       "        1.44393028e-01,  4.61614989e-02,  8.65739441e-02,  2.43676637e-01,\n",
       "        1.41006286e-01,  1.23336253e-01,  1.14188853e-01,  1.02306573e-02,\n",
       "       -1.00230772e-02,  1.23634781e-01,  1.18798876e-01,  5.78472429e-02,\n",
       "        3.66006616e-02,  1.31145696e-02,  1.92239048e-01,  1.73587928e-01,\n",
       "        1.53054792e-01,  2.66200396e-02,  7.33312717e-01,  1.02546806e-01,\n",
       "        8.30997602e-02, -3.37118452e-03,  1.07170769e-01, -2.38050150e-02,\n",
       "       -1.79831473e-02,  2.09149230e-01,  9.14458900e-02,  8.70984842e-02,\n",
       "        3.15690748e-01,  1.12660290e-01,  5.81979605e-02,  1.63436381e-01,\n",
       "        2.68249879e-01,  2.79593365e-02,  4.87312113e-02,  8.62760448e-02,\n",
       "        2.10634075e-01,  1.02384891e-01,  2.49149749e-01,  8.54413254e-02,\n",
       "        2.72367991e-01,  3.03945581e-01,  1.49616275e-01,  1.02801313e-02,\n",
       "        2.83359508e-02,  1.45776792e-01,  1.17067193e-01,  1.30709635e-01,\n",
       "        2.09115262e-01,  6.91494961e-02,  1.09577147e-01,  6.55377882e-02,\n",
       "        2.74444763e-01,  9.65062263e-02,  3.69362540e-01,  1.71079969e-01,\n",
       "        1.02672027e-02,  2.49933331e-01,  1.60994903e-01,  1.29806493e-01,\n",
       "        7.22602892e-02,  2.79674586e-01,  1.23012495e-01,  9.80621830e-02,\n",
       "        7.27665551e-02,  1.75449975e-01,  1.22703871e-02,  1.48892313e-02,\n",
       "        1.93074424e-01,  8.12054037e-02,  7.09016800e-02,  8.15633692e-02,\n",
       "        3.09503134e-01,  2.18615714e-01,  2.26533521e-03,  2.35080691e-01,\n",
       "       -2.17613422e-02,  4.23673248e-01,  1.59938180e-01,  1.56221215e-01,\n",
       "        9.58673147e-02,  1.44586529e-01,  1.46605193e-01,  1.01748033e-01,\n",
       "        1.33945436e-01,  1.17637745e-01,  1.78645095e-01,  1.62006632e-01,\n",
       "        5.05065503e-02,  9.10191653e-02,  5.42067276e-02,  1.88992016e-01,\n",
       "        8.38938321e-02,  1.22700739e-01,  1.05806246e-01,  4.87040506e-02,\n",
       "        7.61678825e-02,  1.30399872e-01,  9.79410766e-02,  1.74438956e-02,\n",
       "        2.42711289e-01,  1.72624893e-01,  5.84508641e-02,  2.03265245e-03,\n",
       "        8.22363447e-02,  1.73906840e-01,  1.16459365e-01, -1.31911274e-03,\n",
       "        6.33022426e-03,  1.18615190e-01,  2.12315776e-01,  6.82702490e-02,\n",
       "        1.43706352e-01,  8.03690755e-02, -5.00333290e-03,  4.23351036e-02,\n",
       "        2.84287208e-01,  1.98151454e-01,  1.41482807e-01,  2.61014916e-02,\n",
       "        1.07158608e-01,  7.51475988e-02,  8.34429145e-02,  3.00844048e-01,\n",
       "        4.05962288e-01,  1.51801089e-01,  2.99663128e-01,  2.43726292e-01,\n",
       "        5.17941239e-02,  1.23006375e-01,  1.74310059e-01,  1.89940972e-01,\n",
       "        1.75686068e-01,  3.08730181e-01,  3.80168614e-02,  2.61772808e-01,\n",
       "        9.98106385e-02,  1.71796797e-01,  2.36219850e-02,  5.17807047e-01,\n",
       "        2.16831645e-01,  5.13653348e-02,  1.82651623e-01,  2.22029376e-01,\n",
       "       -1.17412877e-02,  4.53419735e-04,  4.56653035e-02,  5.69009255e-02,\n",
       "        2.18372421e-01,  1.90815918e-01,  8.13537313e-02, -1.71293390e-03,\n",
       "       -5.10700616e-03, -8.27900260e-03,  1.65468565e-02,  2.53683583e-01,\n",
       "        7.14856821e-02,  3.24884236e-02,  3.19823087e-01,  1.26347929e-01,\n",
       "        8.74867645e-02,  9.34923393e-02,  2.25021977e-01,  1.45496648e-01,\n",
       "        1.26819599e-01,  3.09988546e-02,  1.32244984e-01,  1.19981456e-01,\n",
       "        2.56059890e-02,  9.36930147e-02,  4.22778283e-02, -5.26144560e-03,\n",
       "        3.95655412e-02,  1.02295094e-01,  6.25905852e-03,  3.64673293e-01,\n",
       "        2.57334909e-01,  1.06155494e-01,  3.58110954e-01,  3.40411025e-01,\n",
       "        3.36301826e-01,  4.73657766e-03,  9.96687277e-03,  1.51725112e-01,\n",
       "        9.16565947e-02,  1.06550437e-01,  1.32396572e-01,  1.41684920e-01,\n",
       "        2.63755923e-02, -3.99920427e-03,  7.92775970e-02,  1.69700581e-01,\n",
       "        1.51996266e-01,  1.11320186e-01,  7.74621658e-02,  8.24811092e-02,\n",
       "        1.40962786e-01,  1.57808634e-01,  8.42069875e-02,  1.80412780e-01,\n",
       "        2.34710230e-01,  3.13498973e-03,  1.59420385e-01,  1.78434093e-01,\n",
       "        1.22121079e-01,  6.29213502e-02, -1.01150712e-02,  9.91884386e-02,\n",
       "        1.86194869e-02,  2.82532033e-01,  2.01651928e-01,  3.55872107e-02,\n",
       "        6.49075857e-02,  1.32543834e-01,  1.43219472e-01,  2.49064677e-01,\n",
       "        2.17265751e-01,  1.62999472e-02,  1.65064798e-01,  1.11882409e-01,\n",
       "        1.02791338e-01,  1.26520681e-01,  1.15035187e-01,  4.97044640e-02,\n",
       "        2.57340149e-01,  1.42587798e-01,  3.51695981e-01,  1.56517879e-01,\n",
       "        2.34795085e-01,  1.86643857e-01,  1.03564669e-04,  1.36836574e-01,\n",
       "        1.32244927e-01,  7.97845420e-02,  5.18637868e-02,  2.26558814e-02,\n",
       "        4.31510826e-02,  9.70552788e-02,  3.07413295e-01,  7.10272684e-02,\n",
       "        4.51926161e-02,  1.68703199e-02,  2.05945073e-01,  5.39588034e-02,\n",
       "        2.42838611e-01,  2.66051966e-01,  4.10033273e-02,  8.10726667e-02,\n",
       "        3.19835840e-01,  5.12919486e-01,  3.48658348e-02,  1.75454888e-01,\n",
       "        3.31932228e-01,  1.88116865e-01,  1.41803619e-01,  1.41995675e-01,\n",
       "        5.28201222e-03,  3.70760438e-04,  1.44813335e-01,  1.78988218e-01,\n",
       "        1.53259839e-01,  4.78866774e-02,  1.37889563e-01, -1.89502783e-02,\n",
       "        9.95933229e-02,  1.12831739e-01,  4.44030410e-02,  1.16218033e-01,\n",
       "        4.69181674e-01,  5.36577911e-01,  1.96717043e-03,  3.08706595e-02,\n",
       "        3.20971406e-01,  1.39924850e-01,  5.78603378e-02,  1.19936707e-01,\n",
       "        2.75077857e-01,  7.64094756e-02,  1.59055781e-01,  2.49464660e-01,\n",
       "        4.68325308e-03,  2.48009334e-01,  2.89136919e-02,  3.00900746e-01,\n",
       "        1.14506944e-01,  1.52686423e-01,  7.94878636e-02,  3.96227557e-02,\n",
       "        1.38250546e-01,  1.63998032e-01,  2.82334805e-02,  1.60240729e-01,\n",
       "        1.16461448e-01,  4.31981146e-02,  6.06606325e-03,  8.59817308e-02,\n",
       "        9.24105200e-02,  4.85919732e-02,  6.56391300e-01,  1.10698850e-01,\n",
       "        3.40751697e-02,  7.85315610e-02,  3.37900447e-03,  2.40129384e-01,\n",
       "        2.51847616e-01,  1.92206055e-01,  1.08383343e-01,  1.08351027e-01,\n",
       "        1.89218068e-01,  1.48308434e-01,  5.17431415e-01,  1.37620351e-01,\n",
       "        1.65901286e-01,  2.44037646e-01,  3.62387703e-01,  4.80006255e-01,\n",
       "        7.29535153e-02,  2.25161481e-01,  3.68131694e-02,  2.22332892e-01,\n",
       "        7.32370522e-02,  1.15822552e-01,  1.28623351e-01,  9.24850088e-02,\n",
       "        1.98952501e-02,  8.26277740e-02,  2.39493164e-01,  9.97007793e-03,\n",
       "        1.35250705e-02,  1.69970089e-01,  2.59071881e-01,  5.62099014e-02,\n",
       "        3.70334556e-02,  2.11587579e-01,  4.29110291e-02,  3.84513660e-01,\n",
       "        5.31475848e-02,  8.72619990e-02,  1.42991509e-01, -5.27099398e-03,\n",
       "        9.06940355e-02,  7.00921966e-02,  1.55267191e-01,  1.31760165e-01,\n",
       "        3.47141020e-02,  4.49440752e-02,  1.05715280e-01,  1.42628290e-01,\n",
       "        1.45014808e-02,  6.41804219e-03,  1.08701577e-01,  6.52517203e-02,\n",
       "        3.32563292e-02,  1.12586222e-01,  5.55413326e-01,  6.65509049e-02,\n",
       "        1.06846166e-01,  6.48388948e-02, -1.27356772e-02,  8.53401290e-02,\n",
       "        2.40905235e-01,  1.48317490e-01,  1.65358200e-01,  1.95716552e-01,\n",
       "        1.73829674e-01,  2.25018293e-01, -1.07449626e-02,  3.33406024e-01,\n",
       "        3.20603367e-01,  2.47798665e-01,  1.44845754e-01,  8.77683790e-02,\n",
       "        1.66025474e-01,  4.98416071e-01,  5.67633537e-02,  1.56986287e-01,\n",
       "        1.12158762e-01,  8.46073250e-02,  1.92485918e-01, -6.65373909e-03,\n",
       "        8.17992175e-02,  1.89689441e-01,  1.03195434e-02,  5.78264504e-01,\n",
       "        9.45643621e-02,  1.13035412e-01,  2.28889498e-01,  3.11059441e-01,\n",
       "        1.11812696e-01,  2.31059418e-01,  1.62592780e-01,  2.78703484e-01,\n",
       "        5.93174442e-02,  3.74909500e-02,  2.63142765e-01,  9.36423186e-02,\n",
       "        2.76089486e-02, -1.34991382e-02,  1.67754123e-03,  3.36775560e-01,\n",
       "        6.32428327e-02,  1.78570946e-01,  1.54686025e-01,  7.31960207e-02,\n",
       "        5.15492952e-02,  6.59123016e-02,  7.83396564e-02,  8.63891996e-02,\n",
       "        9.52934450e-02,  5.46641522e-02,  1.13866934e-01,  1.44850246e-01,\n",
       "        2.28750078e-01,  1.07578982e-01,  1.26734030e-01,  1.80505338e-01,\n",
       "        3.88620697e-01, -9.90677656e-03, -1.73841863e-02, -9.39769908e-03,\n",
       "        2.11058396e-01,  3.58619780e-01,  1.07478305e-01,  2.26975917e-01,\n",
       "        5.62214193e-01,  2.66188573e-01,  1.39495924e-01,  8.98187610e-02,\n",
       "        7.67260434e-02,  3.32821418e-01,  1.28581098e-02,  1.91558151e-01,\n",
       "        1.37028865e-01,  1.19612781e-01,  1.36025592e-01,  2.40444107e-01,\n",
       "        7.23466603e-02,  1.48948276e-01,  4.15119774e-01,  3.15437886e-01,\n",
       "        2.56728134e-02,  5.47324719e-02,  3.62679485e-02,  2.33105471e-02,\n",
       "        1.87433288e-01,  3.13645603e-01,  3.55311839e-02,  8.65287507e-02,\n",
       "        4.68513282e-03,  3.26769269e-01,  5.00097505e-01,  3.69789581e-01,\n",
       "        1.60155779e-01,  1.78267216e-01,  4.94027843e-02,  6.44731809e-02,\n",
       "        8.32558402e-02,  2.31410720e-01,  7.18090533e-01,  2.19554313e-01,\n",
       "        2.39364710e-01,  1.11324559e-02,  1.14879559e-01,  2.01435118e-01,\n",
       "        2.59644100e-01,  1.30043810e-01,  5.83084261e-02,  5.74910158e-02,\n",
       "        1.50264973e-01,  3.06450912e-02,  1.87679286e-01,  9.30430829e-02,\n",
       "        3.37585553e-01,  2.15420623e-01,  2.04672532e-01,  1.94260540e-01,\n",
       "        3.67674742e-01,  2.97940333e-01,  6.95110876e-02,  2.49641198e-01,\n",
       "        2.12575964e-01, -4.87492997e-03, -7.08433888e-04, -1.61021400e-04,\n",
       "        1.30876080e-02,  6.62419045e-02,  1.43863084e-01,  7.45013247e-02,\n",
       "        1.06403857e-01,  5.42210930e-01,  2.35096761e-01,  1.40850307e-01,\n",
       "        2.10698872e-01,  1.18066955e-01, -2.79112585e-02,  9.47801899e-02,\n",
       "        3.44341624e-01,  6.96672765e-02,  1.47256671e-01, -1.46070902e-02,\n",
       "        8.88849122e-02,  2.51934875e-01,  1.96163572e-01,  8.70244568e-02,\n",
       "        2.29443521e-01,  1.41609149e-02,  3.22383876e-01,  1.99057834e-01,\n",
       "        6.27658691e-02,  1.24700321e-01,  6.26240501e-02,  3.13308419e-02,\n",
       "        1.12069259e-01,  1.53519967e-01,  1.19980887e-01,  1.91933561e-01,\n",
       "        1.00000000e+00,  1.39329785e-01,  3.10167805e-01,  2.21252574e-01,\n",
       "        9.68688702e-02,  6.73460157e-02,  9.67408279e-02,  1.69158991e-01,\n",
       "        6.31982638e-02,  8.47614690e-02,  3.17365312e-01,  6.10555252e-02,\n",
       "        8.66717125e-02,  5.86853628e-02,  6.29890952e-02,  4.83659990e-03,\n",
       "        2.58900718e-01,  6.85349451e-01,  1.25429643e-01,  9.65140250e-02,\n",
       "        7.44471888e-02,  4.62306587e-02,  1.45820138e-01,  1.46568161e-01,\n",
       "        3.98199656e-02,  2.77569077e-01,  1.08447706e-01,  2.44232526e-01,\n",
       "        4.61544358e-02,  1.42367644e-01,  8.19257721e-02,  1.71413878e-01,\n",
       "        1.59589540e-01,  1.77663947e-01,  1.15212161e-01,  1.25268300e-01,\n",
       "        6.49720327e-02,  8.37610381e-02,  2.87431586e-01,  4.16013270e-02,\n",
       "        8.65917066e-03,  3.36063424e-01,  5.09617675e-01,  4.21238708e-01,\n",
       "        4.92628900e-01,  7.96910363e-02,  1.13531281e-02,  1.64737843e-01,\n",
       "        1.25954377e-01,  8.61108078e-02,  1.30685457e-01,  3.32738514e-02,\n",
       "        9.18313381e-02,  1.57519974e-01,  6.18723553e-02,  1.03013360e-01,\n",
       "        7.43017206e-02,  1.55452907e-01,  1.19408554e-03,  1.66457991e-01,\n",
       "        1.24003828e-01,  1.40621334e-01,  1.33392001e-01,  1.28647261e-01,\n",
       "        1.00471744e-01,  2.04019524e-01,  1.76408208e-01,  1.02583808e-01,\n",
       "        6.51626665e-02,  1.30213304e-01,  4.78066842e-02,  2.88498610e-01,\n",
       "        2.66516724e-01,  3.14786568e-02,  1.22450231e-03,  1.37572953e-01,\n",
       "        6.89725412e-02,  1.93810112e-01,  2.75027185e-01,  8.14652083e-02,\n",
       "        1.32160912e-01,  3.51667962e-02,  9.25836112e-02,  1.65554203e-01,\n",
       "       -4.41117366e-03,  2.11761070e-01,  2.41290579e-02,  1.46938066e-02,\n",
       "        5.60201375e-03,  4.09762617e-02,  8.08361673e-02,  8.87337453e-02,\n",
       "        1.17545854e-01,  8.81590416e-02, -4.54137666e-02,  2.13228620e-01,\n",
       "        1.30235967e-01,  3.89812449e-03,  5.81155036e-02,  1.23200644e-01,\n",
       "        7.34841254e-02,  2.14714165e-03,  1.59359206e-01,  7.83288718e-02,\n",
       "        1.05054049e-01,  2.62280182e-01,  1.49413067e-01,  1.23210155e-01,\n",
       "        1.43100535e-01,  7.84295269e-02,  1.02515266e-01,  2.99781557e-01,\n",
       "        7.56557197e-02,  1.55305987e-01,  1.32729862e-01,  5.88826262e-02,\n",
       "        1.06786207e-01, -1.10361675e-02,  7.49632214e-02, -4.46201728e-03,\n",
       "        1.66202997e-01,  4.40815976e-02,  2.72437971e-01,  1.15519391e-01,\n",
       "        3.07875173e-02,  9.67495950e-02,  2.34031824e-02,  5.73143714e-02,\n",
       "        5.02685499e-02,  1.33672941e-01, -1.09995379e-02, -1.04907055e-03,\n",
       "        1.55125990e-01,  1.04937506e-01,  2.95433422e-02,  1.43091930e-01,\n",
       "        4.47247951e-01,  8.09264372e-02,  8.57737132e-02,  1.49347006e-01,\n",
       "        1.37777540e-01,  1.76715070e-01,  1.78015374e-01,  1.12447808e-01,\n",
       "        1.26847623e-01,  9.29350587e-02,  6.17438721e-02,  1.05684002e-01,\n",
       "        1.00655729e-01,  7.15218574e-02,  1.49253474e-01,  2.63649742e-01,\n",
       "        2.47342045e-01,  1.05279387e-01,  1.16760105e-01,  1.34499248e-01,\n",
       "        1.06577258e-01,  1.84703188e-01,  1.25724429e-01,  1.86869326e-02,\n",
       "        4.50989127e-02,  1.85232930e-01,  1.32396443e-01,  9.90251250e-02,\n",
       "        1.42466688e-02,  4.46397905e-02,  3.15617554e-02,  7.26467305e-02,\n",
       "        1.46864837e-01,  1.19369146e-01,  1.27125647e-02,  1.63537788e-01,\n",
       "        3.32432085e-01,  1.58931087e-01,  7.25503488e-02,  1.10659285e-01,\n",
       "        1.22658849e-01,  4.06974758e-02,  5.35848545e-02,  7.44216854e-02,\n",
       "        2.95829448e-01,  2.04812878e-01,  4.68788462e-02,  8.44151633e-02,\n",
       "        1.07113591e-01,  8.62338660e-02,  6.15777543e-02,  5.32851219e-03])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([812, 314, 754, 829, 594, 679, 720, 650, 785, 565, 101, 435, 606,\n",
       "       545, 854, 746, 669, 856, 611, 564], dtype=int64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_index = (-sim_result[0]).argsort()[:20]\n",
    "sim_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['space',\n",
       " 'exploration',\n",
       " 'sci',\n",
       " 'station',\n",
       " 'office',\n",
       " 'propulsion',\n",
       " 'reports',\n",
       " 'planetary',\n",
       " 'shuttle',\n",
       " 'national',\n",
       " 'astro',\n",
       " 'international',\n",
       " 'operations',\n",
       " 'missions',\n",
       " 'technical',\n",
       " 'satellites',\n",
       " 'probes',\n",
       " 'telescope',\n",
       " 'orbiter',\n",
       " 'nasa']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tfidf.get_feature_names_out()[i] for i in sim_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#151p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
