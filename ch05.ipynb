{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    categories=categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    categories=categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 3, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRry the SKywatch project in  Arizona.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRry the SKywatch project in  Arizona.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 카운트 기반 특성 추출 (97page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=2000, min_df=5, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 2000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 2000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '01', ..., 'yourself', 'zero', 'zip'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv[0].toarray()[0, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823992133726647"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.score(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7324464153732446"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRry the SKywatch project in  Arizona. 2\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0], y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available. 1\n"
     ]
    }
   ],
   "source": [
    "print(X_test[1], y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.predict(X_test_cv[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 2000)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 2000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8618485742379548"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7413155949741316"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top10_features(classifier, vectorizer, categories):\n",
    "    features_names = np.asarray(vectorizer.get_feature_names_out())\n",
    "    for i, category in enumerate(categories):\n",
    "\n",
    "        top10 = np.argsort(-classifier.coef_[i])[:10]\n",
    "        print(category, \", \".join(features_names[top10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '01', ..., 'yourself', 'zero', 'zip'], dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9296951819075713"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7339246119733924"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95968534906588"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7346637102734663"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "max_alpha = 0\n",
    "for alpha in np.arange(0.1, 10, 0.1):\n",
    "    ridge_clf = RidgeClassifier(alpha=alpha)\n",
    "    ridge_clf.fit(X_train_ridge, y_train_ridge)\n",
    "    score = ridge_clf.score(X_val_ridge, y_val_ridge)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        max_alpha = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8255528255528255"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7390983000739099"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha=1.6)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "ridge_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism bobby, religion, atheism, atheists, motto, punishment, islam, deletion, islamic, satan\n",
      "comp.graphics graphics, computer, 3d, file, image, hi, 42, using, screen, looking\n",
      "sci.space space, orbit, nasa, spacecraft, moon, sci, launch, flight, funding, idea\n",
      "talk.religion.misc christian, christians, fbi, blood, order, jesus, objective, children, christ, hudson\n"
     ]
    }
   ],
   "source": [
    "top10_features(ridge_clf, tfidf, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7235772357723578"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "lasso_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.48716557, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism bobby, atheism, atheists, islam, religion, islamic, motto, atheist, satan, vice\n",
      "comp.graphics graphics, image, 3d, file, computer, hi, video, files, looking, sphere\n",
      "sci.space space, orbit, launch, nasa, spacecraft, flight, moon, dc, shuttle, solar\n",
      "talk.religion.misc fbi, christian, christians, christ, order, jesus, children, objective, context, blood\n"
     ]
    }
   ],
   "source": [
    "top10_features(lasso_clf, tfidf, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.904573553370483e-08"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf = Lasso(alpha=1)\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "lasso_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=1)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=7)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=7)\n",
    "tree.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9773844641101278\n",
      "0.5358462675535847\n"
     ]
    }
   ],
   "source": [
    "print(tree.score(X_train_tfidf, y_train))\n",
    "print(tree.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=7)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=7)\n",
    "forest.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9773844641101278\n",
      "0.6851441241685144\n"
     ]
    }
   ],
   "source": [
    "print(forest.score(X_train_tfidf, y_train))\n",
    "print(forest.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=7)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=7)\n",
    "gb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932645034414946\n",
      "0.6962305986696231\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(X_train_tfidf, y_train))\n",
    "print(gb.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00018793, ..., 0.00321606, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 0.0\n",
      "000 0.0\n",
      "01 0.0001879332127649151\n",
      "04 0.0\n",
      "05 0.0\n",
      "10 9.883607872510905e-05\n",
      "100 0.0\n",
      "1000 6.473751341709295e-07\n",
      "11 0.0\n",
      "12 0.0\n",
      "128 0.0\n",
      "129 0.0\n",
      "13 2.008425648829126e-07\n",
      "130 0.0\n",
      "14 0.0\n",
      "15 2.516124350974213e-07\n",
      "16 0.0\n",
      "17 0.0\n",
      "18 0.0\n",
      "19 0.0\n",
      "1987 0.0\n",
      "1988 0.0\n",
      "1989 0.0\n",
      "1990 0.0\n",
      "1991 0.0\n",
      "1992 0.0\n",
      "1993 7.276725872058238e-05\n",
      "20 0.0\n",
      "200 0.0\n",
      "202 0.0\n",
      "21 1.412171476439304e-06\n",
      "22 0.0\n",
      "23 0.0008565498604531021\n",
      "24 0.0009253411970573228\n",
      "25 0.0\n",
      "256 0.0026941947928842995\n",
      "26 0.0005861303016457679\n",
      "27 0.0\n",
      "28 0.0\n",
      "2d 0.0\n",
      "30 0.0006247876254295323\n",
      "300 0.0\n",
      "31 0.0\n",
      "32 6.111288453377536e-05\n",
      "33 0.0\n",
      "34 0.0\n",
      "35 0.0\n",
      "39 0.0\n",
      "3d 0.007819020701620837\n",
      "40 0.0\n",
      "400 0.0\n",
      "42 0.0006758577227103907\n",
      "45 0.0\n",
      "50 0.0\n",
      "500 0.0\n",
      "60 0.0\n",
      "600 0.0\n",
      "65 0.0\n",
      "70 0.0\n",
      "75 0.0\n",
      "80 0.0\n",
      "800 0.0\n",
      "90 0.0\n",
      "900 0.0\n",
      "91 0.0\n",
      "92 4.253484346946885e-06\n",
      "93 0.0\n",
      "95 0.0\n",
      "_the 0.0\n",
      "ability 0.0\n",
      "able 2.2247381322709356e-05\n",
      "abortion 0.0013365771956900937\n",
      "about 0.004021200741750711\n",
      "above 0.0001852456871647147\n",
      "absolute 0.0\n",
      "absolutely 0.0\n",
      "ac 0.0\n",
      "accept 2.216823186325628e-09\n",
      "acceptable 0.0\n",
      "accepted 0.0\n",
      "access 0.0\n",
      "according 0.0\n",
      "account 0.0\n",
      "accurate 0.0\n",
      "across 0.0\n",
      "act 0.0\n",
      "action 0.0\n",
      "actions 0.000574468708566203\n",
      "active 4.027015895159583e-06\n",
      "activities 0.0\n",
      "activity 0.0\n",
      "acts 0.0\n",
      "actual 0.00022882978198113802\n",
      "actually 0.001189395929358099\n",
      "ad 0.0\n",
      "add 0.00018543039751701162\n",
      "added 0.0\n",
      "addition 0.0\n",
      "additional 0.0\n",
      "address 0.0\n",
      "addresses 0.0\n",
      "admit 0.0\n",
      "advance 0.0002063886726406131\n",
      "advanced 0.0\n",
      "advantage 0.0\n",
      "advertising 8.00210172513112e-06\n",
      "aerospace 0.00021683921165421892\n",
      "after 0.0003610657093138239\n",
      "again 0.0006667879048352848\n",
      "against 0.00020573593797638872\n",
      "age 0.00045712422927190154\n",
      "agency 8.699201445646343e-05\n",
      "ago 0.0\n",
      "agree 0.00035870538713294556\n",
      "ahead 0.0\n",
      "air 0.0008107025566512087\n",
      "aircraft 1.0550477967945571e-18\n",
      "al 0.0\n",
      "algorithm 0.0027776151808414575\n",
      "algorithms 0.0\n",
      "alive 0.0\n",
      "all 0.00031499417806122063\n",
      "allah 0.0\n",
      "allen 0.0005049868883446301\n",
      "allow 0.00014710063044539296\n",
      "allowed 0.0\n",
      "allows 0.0\n",
      "almost 0.0\n",
      "alone 8.894611013430934e-08\n",
      "along 0.00013851613399685052\n",
      "already 0.0\n",
      "also 0.00012405719772918107\n",
      "alt 6.156303489902423e-05\n",
      "alternative 0.0\n",
      "although 0.0\n",
      "altitude 0.0\n",
      "always 0.0\n",
      "am 0.0002854609591136947\n",
      "amateur 0.0\n",
      "america 0.0\n",
      "american 0.0\n",
      "americans 0.0\n",
      "ames 0.0018415727385718414\n",
      "amiga 0.0\n",
      "among 0.0\n",
      "amount 0.0\n",
      "an 0.0032168676591567045\n",
      "analysis 0.0\n",
      "ancient 0.0\n",
      "animals 0.0009204239234191663\n",
      "animation 0.0\n",
      "announced 0.0\n",
      "anonymous 0.0\n",
      "another 0.00019141136038358284\n",
      "answer 0.0\n",
      "answers 0.0\n",
      "antenna 0.0\n",
      "anti 3.358713698955184e-07\n",
      "any 0.00230765035816326\n",
      "anybody 0.0016964817201429623\n",
      "anyone 0.003638646088176316\n",
      "anything 0.0\n",
      "anyway 0.00034884045255428723\n",
      "apollo 0.0\n",
      "apparently 0.0\n",
      "appear 0.0012206536242558256\n",
      "appears 0.0\n",
      "apple 0.0\n",
      "application 0.0\n",
      "applications 2.197109844871139e-18\n",
      "applied 0.0\n",
      "apply 0.0\n",
      "appreciate 0.000166854694458385\n",
      "appreciated 0.0\n",
      "approach 0.0\n",
      "appropriate 0.0\n",
      "apr 5.070119814950246e-05\n",
      "april 0.0\n",
      "arc 0.00021777802302715846\n",
      "archie 0.0\n",
      "archive 0.0\n",
      "archives 0.0\n",
      "are 0.0011629183625439209\n",
      "area 0.0012048706222428686\n",
      "areas 0.0\n",
      "aren 0.0\n",
      "argue 0.0\n",
      "argument 0.0016343202858588562\n",
      "arguments 0.0\n",
      "ariane 0.0\n",
      "army 0.0\n",
      "around 4.4803328988586855e-07\n",
      "array 0.0\n",
      "art 0.0\n",
      "article 0.0006110995204927513\n",
      "articles 0.00012871614263591113\n",
      "as 0.0014168753112069347\n",
      "aside 0.0\n",
      "ask 0.0012900279192633896\n",
      "asked 0.0\n",
      "asking 0.0\n",
      "aspects 0.0\n",
      "assembly 0.0\n",
      "assist 0.0\n",
      "associated 0.00029804124162728266\n",
      "association 0.0\n",
      "assume 0.00047273438105121303\n",
      "assuming 0.0\n",
      "assumption 0.0\n",
      "astro 0.0008740308560481299\n",
      "astronaut 0.0\n",
      "astronomical 0.0\n",
      "astronomy 0.0\n",
      "at 0.0008206004770786626\n",
      "atheism 0.023543258791466362\n",
      "atheist 0.004805134811116729\n",
      "atheists 0.00940203835982551\n",
      "atlas 0.0\n",
      "atmosphere 0.0\n",
      "attempt 0.0\n",
      "attitude 0.0\n",
      "au 0.0\n",
      "australia 0.0\n",
      "author 0.0\n",
      "authorities 0.0\n",
      "authority 0.002005155158221194\n",
      "authors 1.8977529465396043e-06\n",
      "available 0.0\n",
      "avenue 0.0\n",
      "aviation 0.0\n",
      "avoid 0.0\n",
      "aware 0.0\n",
      "away 0.0\n",
      "back 0.001416769249722398\n",
      "background 0.0\n",
      "bad 6.992649119709222e-06\n",
      "bank 0.0\n",
      "base 0.0\n",
      "based 2.8998804942863516e-05\n",
      "basic 0.0\n",
      "basically 0.0\n",
      "basis 0.0\n",
      "bbs 0.0\n",
      "be 0.0017557468654310216\n",
      "became 0.0\n",
      "because 0.0011928133734964701\n",
      "become 7.206001337932068e-06\n",
      "becomes 0.0\n",
      "been 0.00036551644510102074\n",
      "before 0.00010529099564449867\n",
      "begin 0.0\n",
      "beginning 0.0\n",
      "behavior 0.0008049883063323705\n",
      "behind 0.0\n",
      "being 0.0008661304423458539\n",
      "beings 0.0008654350432102584\n",
      "belief 0.0\n",
      "beliefs 0.000891231295794348\n",
      "believe 0.00014914634712008375\n",
      "believed 0.0\n",
      "believers 0.0\n",
      "believing 0.0009122578985673935\n",
      "below 0.0\n",
      "benefit 0.0\n",
      "besides 0.0\n",
      "best 0.0\n",
      "better 1.0367839720829817e-07\n",
      "between 0.00017919936035047237\n",
      "beyond 8.586199953200856e-05\n",
      "bible 0.0022369513388350807\n",
      "biblical 0.0\n",
      "big 2.0600202880061013e-06\n",
      "bill 0.0\n",
      "billion 0.0\n",
      "bit 4.393515363585692e-05\n",
      "bitnet 0.0\n",
      "bits 0.0\n",
      "black 0.0001035699074081951\n",
      "blood 0.002212849497278084\n",
      "board 0.0\n",
      "bob 0.0\n",
      "bobby 0.010225361352506714\n",
      "body 0.0\n",
      "book 0.0\n",
      "books 0.0\n",
      "booster 0.0\n",
      "born 0.0\n",
      "both 0.0\n",
      "bottom 0.0\n",
      "box 0.0\n",
      "branch 0.0\n",
      "brian 0.0\n",
      "bring 0.0\n",
      "brought 0.0017292541803986912\n",
      "btw 0.0\n",
      "budget 0.0\n",
      "build 0.0\n",
      "building 0.00015652665009648244\n",
      "built 0.00024912703605869144\n",
      "business 0.0\n",
      "but 0.001745838787689392\n",
      "buy 0.0\n",
      "by 0.000727187469264633\n",
      "ca 0.0\n",
      "cad 0.0\n",
      "calculations 0.0\n",
      "california 0.0\n",
      "call 4.159563387144104e-05\n",
      "called 2.2304536093293546e-06\n",
      "calls 0.0\n",
      "came 0.0\n",
      "camera 0.0\n",
      "can 0.0030699596519815683\n",
      "canada 0.0\n",
      "cannot 0.0\n",
      "capabilities 0.0\n",
      "capability 0.0\n",
      "capable 0.0\n",
      "car 0.0\n",
      "card 0.0047679402132682755\n",
      "care 0.00016312463554904612\n",
      "carry 0.0\n",
      "case 0.0\n",
      "cases 0.0\n",
      "catalog 0.0\n",
      "catholic 0.0\n",
      "cause 1.91848803257755e-06\n",
      "caused 0.0\n",
      "causes 0.0\n",
      "cc 0.0\n",
      "cd 0.0\n",
      "centaur 0.0023356055769653836\n",
      "center 4.1331769358962026e-19\n",
      "centers 0.0\n",
      "central 0.0\n",
      "century 0.0\n",
      "certain 0.0\n",
      "certainly 0.0\n",
      "ch 0.0\n",
      "chance 0.00018136316387042038\n",
      "change 1.8312257306308527e-05\n",
      "changed 0.0\n",
      "changes 0.0\n",
      "chapter 0.0\n",
      "character 0.0\n",
      "charge 0.0\n",
      "cheap 0.0\n",
      "cheaper 0.0\n",
      "check 0.0\n",
      "cheers 0.0\n",
      "child 0.0\n",
      "children 0.003878081793618038\n",
      "choice 0.00013154059944658664\n",
      "choose 0.0\n",
      "chosen 0.0\n",
      "christ 0.010426583770790022\n",
      "christian 0.009663039306452306\n",
      "christianity 0.0\n",
      "christians 0.008981046753380316\n",
      "church 0.0007713310930969447\n",
      "circle 0.0\n",
      "circular 0.0\n",
      "city 0.0\n",
      "civil 0.0\n",
      "civilian 0.0\n",
      "claim 0.0021941385982135655\n",
      "claimed 0.0\n",
      "claims 0.0\n",
      "class 0.0\n",
      "clear 0.0001392521807621185\n",
      "clearly 0.00016414886195183136\n",
      "close 0.0\n",
      "closed 1.840083880856948e-05\n",
      "co 0.0\n",
      "code 0.0008497766735795678\n",
      "col 0.0\n",
      "college 0.0\n",
      "color 0.005513872126424359\n",
      "colors 0.00013200544360436505\n",
      "com 0.00010916803223177912\n",
      "come 3.528435204550263e-06\n",
      "comes 2.7840198210878303e-09\n",
      "comet 0.0\n",
      "coming 0.0\n",
      "command 0.0\n",
      "comment 0.0\n",
      "commentary 0.0\n",
      "comments 0.0\n",
      "commercial 0.0\n",
      "committed 0.0\n",
      "committee 0.0\n",
      "common 0.0\n",
      "communications 0.0\n",
      "community 0.0\n",
      "comp 0.0\n",
      "companies 0.00022566153375722708\n",
      "company 0.0\n",
      "compatible 0.0\n",
      "complete 0.0\n",
      "completely 0.0\n",
      "complex 0.0\n",
      "compression 0.0\n",
      "computer 0.006698870635101263\n",
      "computers 5.623294285862016e-07\n",
      "computing 0.0\n",
      "concept 0.0\n",
      "concerned 0.0\n",
      "concerning 0.0\n",
      "conclude 0.0\n",
      "conclusion 0.0\n",
      "conclusions 0.0\n",
      "conference 0.0\n",
      "consequences 0.0\n",
      "consider 0.0\n",
      "considered 0.0\n",
      "considering 0.0\n",
      "consistent 0.0\n",
      "constant 0.0\n",
      "contact 0.0\n",
      "contain 0.0\n",
      "containing 0.0\n",
      "contains 0.0\n",
      "content 0.0\n",
      "context 0.0037359640824929847\n",
      "continue 0.0\n",
      "contracts 0.0004082965684754363\n",
      "contradiction 0.0\n",
      "contradictions 0.0\n",
      "contradictory 0.0\n",
      "contrary 0.0\n",
      "control 0.00035105606336604855\n",
      "controlled 0.0\n",
      "conversion 0.0\n",
      "convert 0.0\n",
      "converter 0.0\n",
      "convince 0.0\n",
      "copies 0.0\n",
      "copy 0.0\n",
      "core 0.0\n",
      "corp 0.0\n",
      "corporation 0.0\n",
      "correct 0.0005166034615067739\n",
      "cost 0.001414288798939538\n",
      "costs 0.0\n",
      "could 0.0011874733126069998\n",
      "couldn 0.0\n",
      "count 0.0\n",
      "countries 0.0\n",
      "country 0.0\n",
      "couple 6.557423406101305e-05\n",
      "course 0.00022542877062161547\n",
      "court 0.0\n",
      "cover 0.0\n",
      "coverage 0.0\n",
      "covered 0.0\n",
      "craft 0.0\n",
      "create 1.2388156723071158e-08\n",
      "created 0.0\n",
      "creation 0.00032481947753776677\n",
      "creator 0.0\n",
      "crew 0.0\n",
      "crime 0.0007752224605710041\n",
      "cross 0.0\n",
      "cs 0.000300620583453601\n",
      "current 0.00011801487025913063\n",
      "currently 5.3582521394159696e-06\n",
      "cut 5.530269081560681e-05\n",
      "cview 0.0002951647099991048\n",
      "dark 0.0\n",
      "data 0.0\n",
      "database 0.0\n",
      "date 0.0\n",
      "dave 0.0\n",
      "david 0.0\n",
      "day 0.0\n",
      "days 0.0008596005691745591\n",
      "dc 0.0016625590454612373\n",
      "de 0.00013392566552518462\n",
      "dead 0.0008383353444774061\n",
      "deal 0.0\n",
      "death 6.2535475804496746e-09\n",
      "debate 0.0\n",
      "dec 0.0\n",
      "decenso 0.0\n",
      "decide 0.0\n",
      "decided 0.0\n",
      "decision 0.0\n",
      "deep 0.0\n",
      "default 0.0\n",
      "defense 0.0\n",
      "define 0.0\n",
      "defined 0.0\n",
      "definitely 0.0\n",
      "definition 0.0\n",
      "degree 0.0\n",
      "degrees 0.0\n",
      "deity 0.0\n",
      "deleted 8.173310803839805e-05\n",
      "deletion 0.002280539797177893\n",
      "delta 0.0\n",
      "demand 2.3149490765453783e-07\n",
      "demo 0.0\n",
      "department 0.0\n",
      "describe 0.0\n",
      "described 0.0\n",
      "describes 0.0\n",
      "description 3.0262150005179176e-06\n",
      "design 0.0\n",
      "designed 0.0\n",
      "detailed 0.0\n",
      "details 0.0\n",
      "determine 0.0\n",
      "determined 0.00045361041998769676\n",
      "develop 0.0\n",
      "developed 0.0\n",
      "development 0.0\n",
      "devices 0.0\n",
      "did 0.001194220072259786\n",
      "didn 0.00010208376712202417\n",
      "die 0.0\n",
      "died 0.0\n",
      "difference 0.0\n",
      "different 2.7901627343921874e-06\n",
      "difficult 0.0\n",
      "digital 0.0\n",
      "direct 1.9178831721988568e-05\n",
      "direction 0.0\n",
      "directly 0.0\n",
      "directory 0.0\n",
      "disagree 0.0\n",
      "discovered 0.00012724482679248259\n",
      "discuss 0.0\n",
      "discussed 0.0\n",
      "discussion 0.0005274698751468405\n",
      "disk 0.0\n",
      "display 0.0\n",
      "displays 0.0\n",
      "distance 0.00012284999022582342\n",
      "distributed 0.0\n",
      "distribution 0.0\n",
      "divine 0.0\n",
      "division 0.0\n",
      "do 0.0006281755411658071\n",
      "doctrine 0.0\n",
      "document 0.0\n",
      "documentation 0.0\n",
      "does 0.0006063748435298301\n",
      "doesn 2.8550209473289137e-08\n",
      "doing 0.0005260575196558689\n",
      "dollars 0.0\n",
      "domain 0.0\n",
      "don 0.0030420856546431382\n",
      "done 0.0\n",
      "dos 0.0016426986393924079\n",
      "double 0.0\n",
      "doubt 0.0\n",
      "douglas 0.0\n",
      "down 0.000179561849646387\n",
      "dr 8.485015203714497e-06\n",
      "draw 0.0\n",
      "drawing 0.0\n",
      "drive 0.0\n",
      "driver 0.0\n",
      "drivers 0.0\n",
      "due 0.0\n",
      "during 0.0006452263849305291\n",
      "dynamics 3.0962643370446876e-07\n",
      "each 0.0\n",
      "earlier 0.0001831634930438586\n",
      "early 0.0007032381081861648\n",
      "earth 0.003958609175073013\n",
      "easier 0.0\n",
      "easily 0.0\n",
      "east 0.0\n",
      "easy 0.00025669305378470906\n",
      "eat 0.0\n",
      "ed 0.0\n",
      "edge 0.0\n",
      "edges 0.0005362239065294314\n",
      "edition 0.0\n",
      "edu 4.250777720193582e-05\n",
      "education 0.0\n",
      "educational 0.0\n",
      "effect 0.0\n",
      "effects 0.0\n",
      "effort 0.00011835915700208143\n",
      "efforts 0.0\n",
      "either 0.0005239327855033156\n",
      "electronic 0.0\n",
      "element 0.0\n",
      "elements 0.0\n",
      "else 8.48265505900154e-05\n",
      "email 0.0005805296514802775\n",
      "end 0.0\n",
      "energy 0.0\n",
      "engine 0.0\n",
      "engineering 0.0017989524402974352\n",
      "engines 0.0\n",
      "english 0.0\n",
      "enjoy 0.0\n",
      "enough 0.0010375996561850104\n",
      "enter 0.0\n",
      "entire 0.0\n",
      "entirely 0.0\n",
      "environment 2.635531665081521e-05\n",
      "equipment 0.0\n",
      "error 0.0\n",
      "errors 0.0\n",
      "esa 0.0\n",
      "especially 0.0\n",
      "essentially 0.0\n",
      "established 0.0\n",
      "et 0.0\n",
      "etc 0.0\n",
      "eternal 0.0\n",
      "european 0.0\n",
      "even 0.0003476816378487133\n",
      "event 0.0\n",
      "events 0.0\n",
      "eventually 0.0\n",
      "ever 0.000857912064822305\n",
      "every 0.0013906274281025002\n",
      "everyone 0.0\n",
      "everything 0.0002029206548586842\n",
      "evidence 8.208144839617542e-07\n",
      "evil 0.0\n",
      "evolution 0.0\n",
      "ex 0.0\n",
      "exactly 0.0\n",
      "example 8.341923319379657e-05\n",
      "examples 0.0002508406421371261\n",
      "excellent 0.0\n",
      "except 0.0\n",
      "excuse 0.0\n",
      "exist 0.0\n",
      "existence 2.7304122431486432e-05\n",
      "existing 0.0\n",
      "exists 0.0\n",
      "expect 0.0\n",
      "expected 0.0\n",
      "expensive 0.0\n",
      "experience 0.0\n",
      "experiment 0.0\n",
      "explain 0.00022415019063168223\n",
      "explanation 0.0\n",
      "exploration 0.0\n",
      "export 0.0\n",
      "extended 0.0\n",
      "external 0.0\n",
      "extra 0.0\n",
      "eye 0.0\n",
      "face 0.0\n",
      "facility 0.0\n",
      "fact 0.0014463798416662422\n",
      "factor 0.0\n",
      "facts 0.0\n",
      "failed 0.0\n",
      "fair 0.0\n",
      "fairly 0.0\n",
      "faith 0.0\n",
      "fall 0.0\n",
      "fallacy 0.0\n",
      "false 0.0014013786902603211\n",
      "family 0.0\n",
      "faq 4.892190349894197e-07\n",
      "far 4.47740666784297e-07\n",
      "fast 0.0\n",
      "faster 0.00022319667461234715\n",
      "father 0.0\n",
      "fax 0.0\n",
      "fbi 0.008827368636033589\n",
      "fear 0.0\n",
      "features 0.0\n",
      "federal 0.0\n",
      "fee 0.0\n",
      "feel 0.0\n",
      "feet 0.0\n",
      "few 9.14389547298412e-05\n",
      "fi 0.0\n",
      "fiction 0.0\n",
      "field 0.0\n",
      "figure 0.0\n",
      "file 0.02055581240238831\n",
      "files 0.013797145686816017\n",
      "film 0.001244997255337577\n",
      "final 0.0\n",
      "finally 0.0\n",
      "find 7.268201052954367e-05\n",
      "fine 0.0\n",
      "fire 0.0001930762272330564\n",
      "first 2.0821277450376522e-05\n",
      "fit 0.0\n",
      "fits 0.0\n",
      "five 0.0\n",
      "flat 0.0\n",
      "flight 0.006899060277543797\n",
      "fly 0.0\n",
      "flying 0.0\n",
      "folks 0.0\n",
      "follow 0.0\n",
      "followed 0.0\n",
      "followers 0.0\n",
      "following 0.0\n",
      "follows 0.0\n",
      "food 0.0\n",
      "force 6.790703696691442e-05\n",
      "forget 0.0\n",
      "form 0.0\n",
      "format 0.002753642914068192\n",
      "formats 0.0\n",
      "former 0.0\n",
      "forward 0.0\n",
      "found 3.275501124741085e-05\n",
      "foundation 0.0\n",
      "founded 0.0\n",
      "four 0.0\n",
      "frame 1.019574450132984e-06\n",
      "frank 0.0015559642580893983\n",
      "fred 0.0\n",
      "free 0.0\n",
      "freedom 0.0\n",
      "french 0.0\n",
      "frequently 0.0\n",
      "friend 0.0\n",
      "friends 0.0\n",
      "from 0.0009025485645248978\n",
      "ftp 0.0062457492372051055\n",
      "fuel 0.0\n",
      "full 0.0\n",
      "fully 0.0\n",
      "function 0.0\n",
      "functions 0.0\n",
      "fund 0.0\n",
      "fundamental 0.0\n",
      "funding 0.0013645342384177024\n",
      "funds 0.0\n",
      "further 0.0\n",
      "fusion 0.0\n",
      "future 0.0\n",
      "gain 0.0\n",
      "galaxy 0.0\n",
      "galileo 0.0\n",
      "game 0.0\n",
      "gamma 0.002279013681895662\n",
      "gas 0.0\n",
      "gave 0.0\n",
      "gay 0.0\n",
      "general 0.0\n",
      "generally 0.0\n",
      "generate 0.0\n",
      "generation 0.0\n",
      "george 0.0\n",
      "germany 0.0004303555820234818\n",
      "get 0.0011793161696191947\n",
      "gets 0.0\n",
      "getting 1.2092088618855296e-08\n",
      "gif 0.0\n",
      "gifs 0.0\n",
      "give 0.0\n",
      "given 0.0\n",
      "gives 0.0\n",
      "giving 0.0\n",
      "global 0.0\n",
      "go 8.194779536438983e-05\n",
      "goal 0.0\n",
      "god 0.017712702350040938\n",
      "gods 0.0\n",
      "goes 8.712937810859155e-05\n",
      "going 0.00029022745526198046\n",
      "gone 1.3113756925521325e-06\n",
      "good 0.0006053506112290903\n",
      "gospel 0.0\n",
      "got 0.0012886132536782198\n",
      "gov 0.00039673496602739207\n",
      "government 0.0\n",
      "graphic 0.0\n",
      "graphics 0.07955738535484687\n",
      "gravity 0.0\n",
      "great 0.0\n",
      "greater 0.0\n",
      "greatly 0.0\n",
      "greek 0.00010841595889788165\n",
      "ground 0.0\n",
      "group 0.0003626505478546586\n",
      "groups 0.0\n",
      "guess 0.0\n",
      "guide 0.0\n",
      "guilty 0.0\n",
      "gun 0.0\n",
      "guy 7.701325681999664e-05\n",
      "had 0.00028178468033954093\n",
      "half 0.0004636107279619241\n",
      "hand 0.0\n",
      "handle 0.0\n",
      "hands 0.0\n",
      "hanging 0.0\n",
      "happen 0.0\n",
      "happened 0.0\n",
      "happens 0.0\n",
      "happy 0.0\n",
      "hard 0.0\n",
      "hardly 0.0\n",
      "hardware 0.0\n",
      "harm 0.0\n",
      "has 0.0004549517471414819\n",
      "have 0.0011450091500655724\n",
      "haven 0.0\n",
      "having 0.0\n",
      "he 0.0038225793804440326\n",
      "head 0.0\n",
      "hear 0.0\n",
      "heard 0.0004053439180347534\n",
      "heart 0.0\n",
      "heaven 0.0\n",
      "heavy 0.0005630966852445066\n",
      "held 0.00017277233656109265\n",
      "hell 0.0\n",
      "hello 0.0\n",
      "help 0.0003961244726651213\n",
      "helps 0.0\n",
      "hence 0.0\n",
      "her 0.0007904847828314182\n",
      "here 0.0003096897589318853\n",
      "hi 0.016857094927865728\n",
      "hidden 0.0\n",
      "high 0.0006393779494035694\n",
      "higher 0.0\n",
      "highly 0.0\n",
      "him 0.0009426062831141956\n",
      "himself 0.0\n",
      "his 0.004571604182502271\n",
      "historical 0.0006453011673272355\n",
      "history 1.7566457391529566e-06\n",
      "hit 0.0\n",
      "hitler 0.0\n",
      "hold 0.0\n",
      "hole 0.0\n",
      "holy 0.0\n",
      "home 0.0\n",
      "homosexual 0.0\n",
      "homosexuality 9.365891298196054e-07\n",
      "homosexuals 0.0\n",
      "hope 5.330483119327981e-06\n",
      "host 0.0\n",
      "hours 0.0\n",
      "house 0.0\n",
      "how 0.0002669469158859094\n",
      "however 0.0\n",
      "hp 0.0001654957613492829\n",
      "hst 0.0\n",
      "hudson 0.0004659897334301078\n",
      "huge 0.0\n",
      "human 0.0\n",
      "humans 0.0007645248517751807\n",
      "hundred 0.0\n",
      "hundreds 0.0\n",
      "ibm 0.00035570999717740153\n",
      "idea 0.0019465034044709112\n",
      "ideal 0.0\n",
      "ideas 0.0\n",
      "ie 0.0\n",
      "if 0.0003518147890719381\n",
      "ignorance 0.0\n",
      "ignore 0.0\n",
      "ii 3.494161070440823e-05\n",
      "iii 0.000384300076302786\n",
      "image 0.015023452519852164\n",
      "images 0.003979800156585894\n",
      "imagine 0.0\n",
      "imaging 0.0\n",
      "immoral 0.0\n",
      "impact 0.0\n",
      "important 0.0\n",
      "impossible 0.0\n",
      "inc 0.0\n",
      "include 0.0\n",
      "included 0.0\n",
      "includes 0.0\n",
      "including 0.0\n",
      "incoming 0.0\n",
      "increase 0.0\n",
      "indeed 0.0\n",
      "independent 0.0\n",
      "index 6.019478480264712e-06\n",
      "indicates 0.0\n",
      "individual 0.0\n",
      "individuals 0.0\n",
      "industry 0.0\n",
      "info 0.0\n",
      "information 4.669006570913476e-05\n",
      "innocent 0.0\n",
      "input 0.0\n",
      "inside 0.0\n",
      "instance 0.002261864198410176\n",
      "instead 0.0\n",
      "institute 0.0\n",
      "integration 1.4904064868556818e-05\n",
      "intelligence 0.0\n",
      "intended 0.0\n",
      "interactive 0.0\n",
      "interest 2.0591731634517822e-06\n",
      "interested 1.0159638302042263e-07\n",
      "interesting 0.0\n",
      "interface 4.393556644505389e-05\n",
      "international 0.0\n",
      "internet 0.0\n",
      "interpret 0.0\n",
      "interpretation 0.0\n",
      "interpretations 0.0\n",
      "into 0.0\n",
      "introduction 0.0\n",
      "involved 0.0\n",
      "isbn 0.0\n",
      "islam 0.006529364772733121\n",
      "islamic 0.007255118998822582\n",
      "isn 0.003970071813706964\n",
      "israel 0.0\n",
      "issue 0.0\n",
      "issues 0.0\n",
      "its 0.00014980950621723029\n",
      "itself 0.0\n",
      "james 0.0\n",
      "japan 0.0\n",
      "jesus 0.01814149212443511\n",
      "jet 0.0\n",
      "jewish 0.0\n",
      "jews 0.0\n",
      "jim 5.255504965593684e-08\n",
      "job 0.0\n",
      "john 0.0\n",
      "johnson 0.0\n",
      "joint 0.0\n",
      "joseph 0.0\n",
      "journal 0.0\n",
      "jpeg 0.0004934686072367636\n",
      "jpl 0.0\n",
      "jsc 0.0\n",
      "judge 0.0\n",
      "june 0.0\n",
      "jupiter 0.0003839393135279627\n",
      "just 0.000479508032556587\n",
      "justice 0.0\n",
      "justify 0.0\n",
      "keep 0.0\n",
      "ken 0.0\n",
      "kent 0.004415620817426218\n",
      "kept 0.0\n",
      "key 0.0\n",
      "kg 0.0\n",
      "kill 0.0004476809977456047\n",
      "killed 0.0\n",
      "killing 0.0\n",
      "kind 0.0007888059080417774\n",
      "king 0.0\n",
      "kingdom 0.0\n",
      "km 0.0\n",
      "knew 0.0\n",
      "know 0.00036102986529546594\n",
      "knowing 0.0\n",
      "knowledge 0.0\n",
      "known 0.00027922844046069154\n",
      "knows 0.00042485984148497846\n",
      "koresh 0.0046083726402196415\n",
      "lab 0.0\n",
      "laboratory 0.0\n",
      "lack 0.0\n",
      "land 0.0\n",
      "landing 0.0023434918282320572\n",
      "language 0.0\n",
      "large 5.415964325691409e-05\n",
      "larger 0.0005484617007554058\n",
      "last 4.9027856246030266e-05\n",
      "late 0.0\n",
      "later 0.0\n",
      "latest 0.0\n",
      "latter 0.0\n",
      "launch 0.010061136447910934\n",
      "launched 0.0\n",
      "launcher 0.0\n",
      "launches 0.0\n",
      "law 0.0\n",
      "laws 0.0004743132601215618\n",
      "lds 0.0\n",
      "lead 0.0\n",
      "leaders 0.0\n",
      "learn 0.0\n",
      "learning 1.1252181666875853e-05\n",
      "least 0.0006348378207779071\n",
      "leave 0.0\n",
      "led 0.0\n",
      "left 0.0\n",
      "legal 0.0\n",
      "length 0.0\n",
      "leo 0.0\n",
      "less 0.0\n",
      "let 0.0\n",
      "lets 0.0\n",
      "letter 0.0\n",
      "level 0.0\n",
      "levels 0.0\n",
      "lewis 0.0004956459391670244\n",
      "liar 0.0008333327172740278\n",
      "libraries 0.0\n",
      "library 0.00026008492186409754\n",
      "lie 0.0\n",
      "life 0.0009150846456509991\n",
      "light 1.5671144191595974e-06\n",
      "like 0.0006006562246313029\n",
      "likely 0.00015587034581383702\n",
      "limit 0.0\n",
      "limited 0.0\n",
      "line 0.0007515464692248082\n",
      "lines 0.0\n",
      "liquid 0.0004991924185064901\n",
      "list 3.735326318435081e-05\n",
      "listed 0.0\n",
      "listing 0.0\n",
      "lists 0.0\n",
      "literature 0.0\n",
      "little 0.0005492663826017807\n",
      "live 0.0\n",
      "lives 0.0\n",
      "living 0.0\n",
      "ll 0.00039664037528382265\n",
      "load 0.0\n",
      "local 0.0\n",
      "location 0.0\n",
      "logic 0.00017380775083034595\n",
      "logical 0.0\n",
      "long 0.0008076171681764072\n",
      "longer 0.0\n",
      "look 0.0\n",
      "looked 0.0\n",
      "looking 0.009733618292917433\n",
      "looks 0.0\n",
      "lord 0.0017760397728634534\n",
      "loss 0.0\n",
      "lost 0.0\n",
      "lot 9.744092657486346e-05\n",
      "lots 0.0\n",
      "love 0.0\n",
      "low 0.0\n",
      "lower 0.0006291320151541631\n",
      "lucifer 0.0\n",
      "luck 0.0\n",
      "luke 0.0\n",
      "lunar 0.0003167077756661945\n",
      "mac 0.0\n",
      "machine 0.0\n",
      "machines 0.0\n",
      "macintosh 0.0\n",
      "made 0.000634351554492784\n",
      "magazine 0.0\n",
      "magellan 0.0\n",
      "mail 0.0015114858285654455\n",
      "mailing 0.0\n",
      "main 0.0\n",
      "maintain 0.0\n",
      "major 0.0\n",
      "majority 0.0\n",
      "make 9.812484301112591e-05\n",
      "makes 0.0026457059890133564\n",
      "making 0.0\n",
      "man 2.3342515806469015e-06\n",
      "management 0.0\n",
      "manipulation 0.0\n",
      "mankind 0.0\n",
      "manned 0.0\n",
      "manner 0.0001601224390638462\n",
      "manual 0.0\n",
      "many 0.00037832136186519876\n",
      "map 0.0\n",
      "mapping 0.0\n",
      "maps 0.0\n",
      "march 0.0\n",
      "mark 0.0\n",
      "market 0.0\n",
      "mars 0.0009495101897504724\n",
      "mary 0.0\n",
      "mass 0.0\n",
      "master 0.0\n",
      "material 0.0\n",
      "materials 0.0\n",
      "math 0.0\n",
      "matter 0.0\n",
      "matters 0.0\n",
      "matthew 0.0006181273160759118\n",
      "may 0.00021955420406091544\n",
      "maybe 7.49594213554309e-06\n",
      "me 0.0008450955721967616\n",
      "mean 0.0013731926349991558\n",
      "meaning 0.0010454074797123926\n",
      "means 0.0\n",
      "meant 0.0\n",
      "measurements 0.0\n",
      "media 0.0\n",
      "meet 0.0\n",
      "meeting 0.0\n",
      "member 0.0\n",
      "members 0.0\n",
      "memory 0.0\n",
      "men 0.0\n",
      "mention 4.854729661299284e-05\n",
      "mentioned 0.0\n",
      "menu 0.0\n",
      "mercury 0.0\n",
      "merely 0.0\n",
      "message 0.000372550458181858\n",
      "messiah 0.0\n",
      "method 0.0\n",
      "methods 0.0\n",
      "michael 0.0\n",
      "mid 0.0\n",
      "middle 0.003501303783097672\n",
      "might 4.091120123975836e-06\n",
      "mil 0.0\n",
      "military 0.0\n",
      "million 0.0\n",
      "mind 0.00012312530821232513\n",
      "mine 0.0\n",
      "minutes 0.0\n",
      "miracles 0.0\n",
      "mirror 0.0\n",
      "mirrors 0.0\n",
      "misc 0.00012223451158268258\n",
      "missed 0.0\n",
      "mission 0.0003234627382487826\n",
      "missions 0.0\n",
      "mit 0.0\n",
      "mode 3.154423917053411e-05\n",
      "model 0.0\n",
      "modeling 0.0\n",
      "models 0.0\n",
      "modern 0.0\n",
      "modes 0.0\n",
      "modified 0.0\n",
      "module 0.0\n",
      "molecular 0.0\n",
      "moment 0.0002856115790776782\n",
      "money 0.0004378450208577286\n",
      "monitor 0.0\n",
      "months 1.8775608243122939e-06\n",
      "moon 0.010376173054679735\n",
      "moral 0.0\n",
      "morality 0.003708287839986858\n",
      "morals 0.00015899092990213679\n",
      "more 0.0005931787767118047\n",
      "mormon 0.0\n",
      "mormons 0.0\n",
      "most 4.1812812085434826e-05\n",
      "mostly 0.0\n",
      "motif 0.0\n",
      "motion 0.0\n",
      "motto 0.003489481716737809\n",
      "move 0.0\n",
      "movie 0.0001286286322172202\n",
      "mr 0.0\n",
      "ms 0.0\n",
      "msdos 0.0\n",
      "much 0.00016962888293392992\n",
      "muhammad 0.0\n",
      "multi 0.0\n",
      "multiple 0.0\n",
      "murder 0.0\n",
      "muslim 0.0\n",
      "muslims 0.0\n",
      "must 0.002054011790496542\n",
      "my 2.2929707756345686e-06\n",
      "myself 0.0\n",
      "name 0.00191115375756526\n",
      "named 0.0005444529201618805\n",
      "names 0.0\n",
      "nasa 0.015308260768876465\n",
      "nation 0.0\n",
      "national 0.0\n",
      "natural 0.00014695400611861945\n",
      "nature 0.0\n",
      "navy 0.0\n",
      "near 0.0\n",
      "nearly 0.0\n",
      "necessarily 0.0\n",
      "necessary 0.0\n",
      "need 0.0025997082494940427\n",
      "needed 7.863717310557088e-05\n",
      "needs 0.0\n",
      "neither 0.0\n",
      "net 0.0003390600485993923\n",
      "network 0.0\n",
      "never 0.0\n",
      "new 0.00023130424874347487\n",
      "news 0.0\n",
      "newsgroup 0.0\n",
      "next 0.0\n",
      "nice 0.000165176670889614\n",
      "nick 0.0\n",
      "night 0.0\n",
      "no 0.0013786647172583514\n",
      "non 0.0\n",
      "none 0.0\n",
      "nor 0.0\n",
      "normal 0.0\n",
      "north 0.0\n",
      "not 0.007515358150120414\n",
      "note 3.6731892523203144e-07\n",
      "noted 0.0\n",
      "notes 0.0\n",
      "nothing 3.65869837382592e-06\n",
      "notice 0.0\n",
      "notion 0.0003712228742702646\n",
      "now 0.0003581908564172062\n",
      "nuclear 0.0\n",
      "number 0.001549562240133334\n",
      "numbers 0.0\n",
      "ny 0.0\n",
      "object 0.0006086791705081454\n",
      "objective 0.0035798279805276533\n",
      "objects 0.0\n",
      "observation 0.00020936192190479938\n",
      "observations 0.0\n",
      "observatory 0.0008548955965391742\n",
      "observer 0.0\n",
      "obvious 8.77952848624698e-06\n",
      "obviously 0.0\n",
      "occurs 0.0\n",
      "odd 0.0\n",
      "off 0.0013060366235285586\n",
      "offer 0.00017883708039570956\n",
      "offers 0.0\n",
      "office 0.0\n",
      "official 0.0\n",
      "often 0.0\n",
      "oh 0.0\n",
      "ok 7.716487022533708e-06\n",
      "okay 0.0\n",
      "old 0.0007962936810091196\n",
      "on 0.0012132857965526792\n",
      "once 3.543933155984333e-07\n",
      "one 4.067636327254046e-06\n",
      "ones 0.0\n",
      "online 0.0\n",
      "only 0.0005607004822454306\n",
      "open 0.0\n",
      "operating 0.0\n",
      "operation 0.0\n",
      "operations 0.0\n",
      "opinion 0.0\n",
      "opinions 0.0\n",
      "opposite 0.0\n",
      "option 0.0\n",
      "options 0.0\n",
      "or 0.0014411371748415116\n",
      "orbit 0.020063273938036058\n",
      "orbital 0.0\n",
      "orbiter 0.0\n",
      "orbiting 0.0\n",
      "orbits 0.0\n",
      "order 0.0031761637974542073\n",
      "ordered 0.0\n",
      "org 0.0\n",
      "organization 0.0\n",
      "organizations 0.0\n",
      "oriented 0.0\n",
      "origin 0.0\n",
      "original 0.00017346445431237596\n",
      "originally 0.0\n",
      "orthodox 0.0\n",
      "os 0.0\n",
      "other 0.0003866973745676854\n",
      "others 6.645602954465292e-09\n",
      "otherwise 0.0\n",
      "our 0.0\n",
      "out 0.0001784540566551595\n",
      "output 0.0\n",
      "outside 0.0\n",
      "over 0.0003153202210039964\n",
      "own 0.0010515845256762065\n",
      "ozone 0.0\n",
      "package 0.001162536226599298\n",
      "packages 0.0\n",
      "page 1.368716533362388e-08\n",
      "pages 0.0\n",
      "paper 0.0\n",
      "papers 0.0\n",
      "paradise 0.00038309549981608925\n",
      "parallel 0.0\n",
      "parameters 0.0\n",
      "part 0.0006839613486920049\n",
      "particular 0.0\n",
      "particularly 0.0\n",
      "parts 2.617166799042063e-07\n",
      "pascal 0.0\n",
      "pass 0.0\n",
      "passage 0.0\n",
      "passages 0.0\n",
      "past 1.0714804576174994e-05\n",
      "pat 0.00018450593714059124\n",
      "path 0.0\n",
      "paul 0.0\n",
      "pay 0.00039601159795435773\n",
      "payload 0.0\n",
      "payloads 0.0\n",
      "pc 0.000993466817768178\n",
      "peace 0.0\n",
      "people 0.004624503816321023\n",
      "per 7.578902850233891e-08\n",
      "perfect 0.0004744539167280677\n",
      "perfectly 0.0\n",
      "performance 0.0\n",
      "performed 0.0\n",
      "perhaps 0.000132034039587979\n",
      "period 6.491934638755044e-05\n",
      "permission 0.0\n",
      "person 0.0\n",
      "personal 0.0005341933382549381\n",
      "personally 0.0\n",
      "perspective 0.0\n",
      "peter 0.0\n",
      "philosophy 0.0\n",
      "phone 0.0\n",
      "physical 9.760029280315442e-07\n",
      "physics 2.7829825981178723e-06\n",
      "pick 0.0\n",
      "picture 0.0\n",
      "pictures 0.0\n",
      "piece 0.0\n",
      "pioneer 0.0\n",
      "pixel 0.0\n",
      "pixels 0.0\n",
      "place 0.0005240028518341293\n",
      "placed 0.0\n",
      "places 0.0\n",
      "plan 0.0\n",
      "plane 0.0\n",
      "planet 0.0\n",
      "planetary 0.0\n",
      "planets 0.0\n",
      "planned 0.0\n",
      "platforms 0.0\n",
      "play 0.0\n",
      "please 0.0006327336279207689\n",
      "plot 0.0\n",
      "plotting 0.0\n",
      "plus 0.0\n",
      "point 0.00014680301716511241\n",
      "pointed 0.0\n",
      "points 0.00012685573467914049\n",
      "policy 0.0013898224304465109\n",
      "political 0.0\n",
      "polygon 0.0005126282702360788\n",
      "polygons 0.0005401794540042405\n",
      "poor 0.0\n",
      "popular 0.0\n",
      "population 0.0\n",
      "position 0.00016961741305616078\n",
      "positions 0.0\n",
      "positive 0.0\n",
      "possibility 0.0\n",
      "possible 0.0\n",
      "possibly 0.00011707220754144579\n",
      "post 0.00043750338320032765\n",
      "posted 2.421751702377557e-06\n",
      "posting 0.00044779816267309316\n",
      "postings 0.0\n",
      "posts 4.332328076164999e-10\n",
      "postscript 0.0\n",
      "potential 2.9908839530191897e-06\n",
      "pov 0.0026571656478566836\n",
      "power 0.0007398865355411253\n",
      "practice 0.00039210968102894073\n",
      "pre 0.0\n",
      "premise 0.0\n",
      "premises 0.0\n",
      "present 0.0\n",
      "presented 0.0009693858998124329\n",
      "president 0.0\n",
      "press 0.0\n",
      "pressure 0.0\n",
      "pretty 0.0\n",
      "previous 0.0\n",
      "price 0.0\n",
      "primarily 0.0\n",
      "primary 0.0\n",
      "princeton 0.0\n",
      "principle 0.0\n",
      "principles 0.0\n",
      "print 0.0\n",
      "printer 0.0\n",
      "private 0.0\n",
      "prize 0.0010919723510469828\n",
      "pro 0.0\n",
      "probably 1.0787045057016281e-08\n",
      "probe 0.0\n",
      "probes 0.0\n",
      "problem 0.00022777141500415773\n",
      "problems 0.0\n",
      "process 7.832555907595932e-05\n",
      "processes 0.0\n",
      "processing 0.0\n",
      "produce 0.0\n",
      "produced 0.0\n",
      "product 0.0009585280900717834\n",
      "products 0.0\n",
      "professional 0.0\n",
      "profit 0.0\n",
      "program 0.0003109592387632648\n",
      "programming 0.0\n",
      "programs 0.0\n",
      "project 0.0\n",
      "projects 0.0\n",
      "proof 0.0\n",
      "properly 0.0\n",
      "prophecy 0.0\n",
      "prophet 0.0007443339595418886\n",
      "proposed 0.00042697967159680813\n",
      "propulsion 0.0\n",
      "proton 0.0\n",
      "prove 1.7639579385272698e-06\n",
      "provide 0.0\n",
      "provided 0.0\n",
      "provides 4.833058618699295e-07\n",
      "providing 0.0\n",
      "pub 0.00013314714212570025\n",
      "public 1.8554835949064906e-05\n",
      "published 0.0\n",
      "punishment 0.004251167347701979\n",
      "purpose 0.0\n",
      "purposes 0.0\n",
      "put 0.0\n",
      "putting 0.0\n",
      "quality 0.0\n",
      "question 0.00022669035729934797\n",
      "questions 0.0\n",
      "quicktime 0.0\n",
      "quite 0.0006662970356742854\n",
      "quote 0.0\n",
      "quoted 0.0\n",
      "quotes 0.0\n",
      "qur 0.0008710091857566701\n",
      "ra 0.0\n",
      "radar 0.0\n",
      "radio 0.0\n",
      "radiosity 0.0\n",
      "radius 0.0\n",
      "raise 0.0\n",
      "raised 0.0\n",
      "range 0.0\n",
      "raster 0.0\n",
      "rate 4.81668810252629e-05\n",
      "rather 0.00026667006037260724\n",
      "ray 0.0\n",
      "rayshade 0.0\n",
      "re 0.001577839868796782\n",
      "reach 0.0\n",
      "read 6.19141999323384e-05\n",
      "readers 0.0\n",
      "reading 0.0\n",
      "reads 0.0\n",
      "ready 0.0\n",
      "real 8.281172013451218e-05\n",
      "reality 0.00010276375526062407\n",
      "realize 0.0\n",
      "really 0.00011790060863491506\n",
      "reason 0.0004800135350082655\n",
      "reasonable 0.0\n",
      "reasoning 0.0\n",
      "reasons 0.00023707223545873496\n",
      "recall 0.0\n",
      "receive 0.0\n",
      "received 0.0\n",
      "recent 0.0\n",
      "recently 0.00011883857614644004\n",
      "recommend 0.0\n",
      "red 1.2059290928522796e-08\n",
      "redesign 0.0\n",
      "refer 0.0\n",
      "reference 0.0\n",
      "references 0.0\n",
      "regarding 0.0\n",
      "regards 0.0\n",
      "reject 0.0\n",
      "related 0.0\n",
      "relative 0.0014204959474777212\n",
      "release 0.0\n",
      "released 0.0\n",
      "relevant 0.0\n",
      "reliable 0.0\n",
      "religion 0.007182617149762632\n",
      "religions 0.0\n",
      "religious 0.0027006328761795886\n",
      "remain 0.0\n",
      "remember 0.00023560684146751578\n",
      "remote 0.0\n",
      "removed 0.0\n",
      "rendering 0.0\n",
      "reply 0.0\n",
      "report 0.00017523006098877904\n",
      "reported 0.0\n",
      "reports 0.0\n",
      "represent 0.0\n",
      "request 0.0\n",
      "requests 0.0\n",
      "require 1.485636787530014e-05\n",
      "required 0.0\n",
      "requirements 2.4097665349929973e-07\n",
      "requires 0.0\n",
      "research 0.0007732373003027196\n",
      "resolution 0.0\n",
      "resource 0.0\n",
      "resources 0.0\n",
      "respect 0.0\n",
      "respond 0.0\n",
      "response 8.369365571362257e-05\n",
      "responses 0.0\n",
      "responsibility 0.0\n",
      "responsible 0.0\n",
      "rest 0.0009693641021879354\n",
      "result 0.0\n",
      "results 0.00013157867495587408\n",
      "return 0.0\n",
      "revelation 0.0\n",
      "right 0.0018332419432593675\n",
      "rights 0.00017727688438328321\n",
      "risk 0.001630998931070295\n",
      "road 0.0\n",
      "robert 0.0\n",
      "rocket 0.003030865477849616\n",
      "rocketry 0.0\n",
      "rockets 0.0003790026412635472\n",
      "roll 0.0\n",
      "room 1.2679539237430952e-06\n",
      "routines 0.0\n",
      "row 0.0\n",
      "rule 0.0\n",
      "rules 0.0\n",
      "run 0.0007806379963779749\n",
      "running 0.0002142461991870773\n",
      "runs 0.0\n",
      "rushdie 0.0\n",
      "russian 0.0\n",
      "safety 0.00243070727900811\n",
      "said 0.00014362183822903143\n",
      "sales 0.0\n",
      "salvation 0.0\n",
      "same 0.0\n",
      "san 0.0\n",
      "satan 0.002231094338595317\n",
      "satellite 6.346005519071837e-06\n",
      "satellites 0.0\n",
      "saturn 0.0\n",
      "save 0.0\n",
      "saw 0.0\n",
      "say 0.0008460914003996936\n",
      "saying 0.0005419543789443866\n",
      "says 3.033253972318854e-06\n",
      "scale 0.0\n",
      "scholars 0.0\n",
      "school 0.0\n",
      "sci 0.0\n",
      "science 0.0\n",
      "sciences 0.0\n",
      "scientific 0.0\n",
      "scientists 0.0\n",
      "screen 0.002432274216777441\n",
      "sdio 0.0\n",
      "sea 0.0041914539092050285\n",
      "search 0.0\n",
      "second 4.8374425042621306e-05\n",
      "section 0.0\n",
      "secular 0.0\n",
      "see 0.0024812623278755727\n",
      "seeing 8.202511119701063e-08\n",
      "seem 0.0\n",
      "seemed 0.0\n",
      "seems 0.0008498253823183349\n",
      "seen 0.00010035529743299483\n",
      "select 0.0\n",
      "selection 0.0\n",
      "self 0.0\n",
      "sell 0.0\n",
      "semi 0.0\n",
      "send 0.0004083519314590018\n",
      "sense 0.0008977312361442524\n",
      "sensing 0.0\n",
      "sent 0.0\n",
      "sentence 0.0\n",
      "separate 0.0\n",
      "sequence 0.0\n",
      "series 0.0\n",
      "serious 0.0\n",
      "seriously 0.00015631753074823592\n",
      "server 0.0\n",
      "servers 0.0\n",
      "service 0.0\n",
      "services 0.0\n",
      "set 0.0\n",
      "sets 0.0\n",
      "setting 0.0\n",
      "several 0.0\n",
      "sex 0.0\n",
      "sgi 0.0\n",
      "shall 0.0006834913012315922\n",
      "shape 0.0\n",
      "share 0.0\n",
      "shareware 0.0\n",
      "she 0.0\n",
      "short 0.0\n",
      "should 0.00016436589415548105\n",
      "shouldn 0.0\n",
      "show 3.4245338794855555e-06\n",
      "showing 0.0\n",
      "shown 0.0\n",
      "shows 0.0\n",
      "shuttle 0.002649659482981952\n",
      "side 0.0\n",
      "siggraph 0.0\n",
      "sign 0.0\n",
      "signal 0.0\n",
      "significant 0.0\n",
      "silicon 0.0\n",
      "silver 0.0\n",
      "similar 0.0\n",
      "simple 1.6372291905026454e-07\n",
      "simply 0.00016752555656221365\n",
      "sin 0.0002830955250420604\n",
      "since 0.0\n",
      "single 0.0\n",
      "site 0.0\n",
      "sites 0.0\n",
      "situation 0.0\n",
      "six 0.0005815941686917298\n",
      "size 0.0\n",
      "sky 0.001103154420807574\n",
      "small 0.0\n",
      "smaller 0.0\n",
      "so 0.0007539266215475038\n",
      "social 0.002661107525079609\n",
      "society 0.0008469687394208445\n",
      "software 0.004918770389689074\n",
      "solar 0.003704544523806403\n",
      "solid 0.0\n",
      "solution 0.0\n",
      "some 0.0026782879129570686\n",
      "somehow 0.0\n",
      "someone 0.00045372501422179517\n",
      "something 0.001328907116559956\n",
      "sometimes 6.635867910924274e-05\n",
      "somewhat 0.0\n",
      "somewhere 0.0\n",
      "son 0.00022135893645766557\n",
      "soon 0.0\n",
      "sorry 0.0005602543805846834\n",
      "sort 0.0\n",
      "soul 0.0\n",
      "sound 0.0\n",
      "sounds 0.0008281232039213332\n",
      "source 0.0\n",
      "sources 0.0\n",
      "south 0.0\n",
      "soviet 0.0\n",
      "space 0.12606815556503398\n",
      "spacecraft 0.007074189152295396\n",
      "speak 0.0\n",
      "speaking 0.0\n",
      "special 0.0\n",
      "species 0.0018898283076018308\n",
      "specific 0.0\n",
      "specifically 0.0\n",
      "speed 0.0\n",
      "spend 0.0\n",
      "spent 0.0\n",
      "sphere 0.0043345782339024655\n",
      "spin 0.00016421930043908827\n",
      "spirit 0.0\n",
      "split 0.0\n",
      "spot 0.0\n",
      "ssf 0.0\n",
      "ssto 0.0\n",
      "st 0.0\n",
      "stage 1.8792401632620373e-06\n",
      "stand 0.00048432821172717747\n",
      "standard 0.0\n",
      "standards 0.0\n",
      "stanford 0.0\n",
      "star 0.00022721805621209626\n",
      "stars 0.0\n",
      "start 0.0\n",
      "started 0.0\n",
      "starting 0.0\n",
      "state 0.0\n",
      "stated 0.0\n",
      "statement 0.0\n",
      "statements 0.0\n",
      "states 0.0\n",
      "station 0.0\n",
      "status 9.22569755791523e-06\n",
      "stay 7.0945646524818846e-06\n",
      "step 0.0\n",
      "stephen 0.0\n",
      "steve 0.0013018678644410857\n",
      "still 1.3213649590567541e-05\n",
      "stop 0.0\n",
      "stories 0.000372986062499247\n",
      "story 0.00117210372996638\n",
      "straight 0.0\n",
      "street 0.0\n",
      "strong 0.0\n",
      "strongly 0.0\n",
      "structure 0.0\n",
      "studies 0.0\n",
      "study 0.0\n",
      "stuff 0.0004257546004272344\n",
      "stupid 0.0\n",
      "subject 0.00028818255397644805\n",
      "subjective 1.0735331125951252e-05\n",
      "subscribe 0.0\n",
      "successful 0.0\n",
      "such 0.0\n",
      "sufficient 0.0\n",
      "suggest 0.0\n",
      "suggestions 0.0\n",
      "suite 0.0\n",
      "summary 0.0\n",
      "sun 0.0\n",
      "super 0.0\n",
      "supply 4.521146610069622e-07\n",
      "support 0.0\n",
      "supported 0.0\n",
      "supporting 0.0\n",
      "supports 3.2956514954959094e-06\n",
      "suppose 0.0\n",
      "supposed 0.0\n",
      "supposedly 0.0004025699479603851\n",
      "sure 0.00012168056092492279\n",
      "surely 0.0\n",
      "surface 0.0003820707150858351\n",
      "surfaces 0.0\n",
      "svga 0.0\n",
      "system 5.749308891078484e-06\n",
      "systems 0.0\n",
      "take 0.00014618553164763508\n",
      "taken 0.0\n",
      "takes 0.0\n",
      "taking 0.00021644343444633825\n",
      "talk 0.00030178366346074833\n",
      "talking 5.461557262930497e-05\n",
      "tar 0.0003858051284968009\n",
      "tax 0.0\n",
      "teach 0.00017372753597667362\n",
      "teaches 0.0\n",
      "teaching 0.0\n",
      "teachings 0.0\n",
      "team 0.0\n",
      "technical 0.0\n",
      "techniques 0.0\n",
      "technologies 0.0\n",
      "technology 0.0\n",
      "tel 0.0\n",
      "telephone 0.0\n",
      "telescope 0.0\n",
      "tell 6.816606002203573e-06\n",
      "telling 0.0\n",
      "tells 0.0005050262032379974\n",
      "tend 0.0\n",
      "term 0.0\n",
      "terms 1.3475821022772477e-05\n",
      "test 0.0\n",
      "testament 0.0\n",
      "testing 0.0\n",
      "text 6.748777592386361e-07\n",
      "than 0.00010234061792451569\n",
      "thank 0.0018045393920214517\n",
      "thanks 0.023046507462732756\n",
      "their 1.1954365874962979e-05\n",
      "theists 0.0\n",
      "them 0.00041927775557063\n",
      "themselves 0.0\n",
      "then 0.0003502967295825412\n",
      "theory 0.000975880253521748\n",
      "there 0.0015017249013554647\n",
      "therefore 0.0\n",
      "thermal 0.0\n",
      "these 1.6986206665360382e-05\n",
      "they 0.0006455333868779101\n",
      "thing 0.0007913042727385488\n",
      "things 3.239229791973488e-06\n",
      "think 0.0009652715178819101\n",
      "thinking 0.0\n",
      "thinks 1.4106734330914905e-05\n",
      "third 0.0\n",
      "this 0.0020587283339791236\n",
      "thomas 0.0\n",
      "those 0.0004215135520285458\n",
      "thou 0.0020845648612679716\n",
      "though 0.0\n",
      "thought 0.0010483378356254266\n",
      "thousands 0.0\n",
      "thread 0.0\n",
      "threat 0.000580709373629012\n",
      "three 0.0\n",
      "through 0.0\n",
      "throughout 0.0\n",
      "thus 0.00015885624030137642\n",
      "tiff 0.0\n",
      "time 0.0005416943102065281\n",
      "times 0.0004396160006457924\n",
      "titan 0.0\n",
      "title 0.0\n",
      "today 0.0\n",
      "together 0.0\n",
      "told 0.0\n",
      "tom 0.002598784430882167\n",
      "tony 0.0\n",
      "too 0.00015144822445813002\n",
      "took 0.0\n",
      "tool 0.0\n",
      "tools 0.0\n",
      "top 0.0\n",
      "topic 0.0\n",
      "total 0.0\n",
      "totally 0.0\n",
      "towards 0.0\n",
      "tracer 0.0\n",
      "tracing 0.0\n",
      "track 0.0\n",
      "tracking 0.0\n",
      "tradition 0.0\n",
      "training 0.0\n",
      "transfer 0.0\n",
      "translation 0.00027181973328546004\n",
      "tried 0.0\n",
      "trouble 0.0\n",
      "true 0.0006413766672585178\n",
      "truly 0.0\n",
      "truth 0.002747369720000391\n",
      "try 0.00010581219969615915\n",
      "trying 0.0\n",
      "turn 7.295625354885056e-05\n",
      "turned 0.0\n",
      "tv 0.0\n",
      "two 6.914304874469281e-05\n",
      "type 0.0\n",
      "types 0.0\n",
      "typical 0.0\n",
      "tyre 0.0\n",
      "uk 0.0\n",
      "under 4.3969777624213676e-06\n",
      "understand 0.00037046640318961143\n",
      "understanding 0.00022475589552999615\n",
      "unfortunately 0.0\n",
      "unit 0.0001868569556607031\n",
      "united 0.0\n",
      "universe 0.0\n",
      "university 7.437728973194327e-06\n",
      "unix 0.0011459916480279432\n",
      "unless 0.0\n",
      "unlikely 0.0\n",
      "until 0.0\n",
      "up 0.0027763407707124366\n",
      "upon 0.0\n",
      "upper 0.0\n",
      "us 0.00048305356240955106\n",
      "usa 0.0\n",
      "use 0.000700302390323802\n",
      "used 0.0003842895612586752\n",
      "useful 0.0\n",
      "usenet 0.0\n",
      "user 0.0\n",
      "users 0.0\n",
      "uses 0.0\n",
      "using 0.003006529940852933\n",
      "usual 0.0\n",
      "usually 0.00016715046111961845\n",
      "utah 0.0\n",
      "utilities 0.0\n",
      "valid 0.0\n",
      "value 0.00028088027033067723\n",
      "values 0.0014150637995069494\n",
      "van 0.00018906143577739174\n",
      "variety 0.0\n",
      "various 0.0\n",
      "ve 0.00032266205244313033\n",
      "vehicle 0.0011598547073011225\n",
      "vehicles 0.0\n",
      "velocity 0.0\n",
      "venture 0.0\n",
      "venus 0.0004901254921099725\n",
      "verse 0.0\n",
      "verses 0.0\n",
      "version 0.0016196793482361443\n",
      "versions 0.00031430536781181174\n",
      "very 0.00039582123982335576\n",
      "vesa 0.0\n",
      "vga 0.0027090225677696826\n",
      "via 0.0\n",
      "vice 0.00187174627897788\n",
      "video 0.0025189278937806548\n",
      "view 3.161261327410469e-06\n",
      "viewer 0.0\n",
      "viewers 0.0\n",
      "viewing 0.0\n",
      "viewpoint 0.0\n",
      "views 0.0\n",
      "viking 0.0\n",
      "virtual 0.00041513311916285887\n",
      "visible 0.0\n",
      "vision 0.0\n",
      "visual 0.0\n",
      "visualization 0.0\n",
      "voice 0.0\n",
      "vol 0.0\n",
      "volume 0.0\n",
      "voyager 0.0\n",
      "wait 0.0\n",
      "wall 0.0\n",
      "want 0.00036976361070088483\n",
      "wanted 0.0\n",
      "wants 0.0\n",
      "war 0.0007623387825459219\n",
      "was 0.0013144744953162454\n",
      "washington 0.0\n",
      "wasn 0.0\n",
      "waste 0.0\n",
      "water 0.0\n",
      "way 0.0006552148008421341\n",
      "ways 0.0\n",
      "we 0.0006532303131788518\n",
      "weak 0.00036791306704927026\n",
      "week 7.088544830457518e-06\n",
      "weeks 0.0\n",
      "weight 0.0\n",
      "weiss 0.0\n",
      "welcome 0.0\n",
      "well 0.0004893345771276899\n",
      "went 0.0\n",
      "were 0.0004281257369772854\n",
      "west 0.0\n",
      "western 0.0\n",
      "what 0.002566321088555809\n",
      "whatever 5.0966297958903806e-05\n",
      "when 0.00038779897616703996\n",
      "where 0.00013744853161422245\n",
      "whether 0.00010228758457691337\n",
      "which 0.001172998482953918\n",
      "while 0.0001971501429756365\n",
      "white 0.0005909499853189306\n",
      "who 0.0028970391103206156\n",
      "whole 0.00037379642788262167\n",
      "whom 0.0\n",
      "whose 0.0007092322641962879\n",
      "why 0.00033928121894082834\n",
      "wide 0.0\n",
      "will 0.0013210200340496717\n",
      "willing 0.0\n",
      "window 0.0\n",
      "windows 0.0027366074571366404\n",
      "wings 0.0002401402498160918\n",
      "wish 0.0\n",
      "with 0.0037324291188048464\n",
      "within 0.0\n",
      "without 0.0\n",
      "witness 0.0005888492540385882\n",
      "woman 0.0\n",
      "women 0.0\n",
      "won 0.00010458378286548737\n",
      "wonder 0.00018139411126343657\n",
      "wondering 0.0\n",
      "word 0.00015618648560117358\n",
      "words 0.0021231247155534365\n",
      "work 0.00023441815891104032\n",
      "working 0.00012821299588025706\n",
      "works 0.0029908853630800994\n",
      "workstations 0.0\n",
      "world 8.371106099599103e-05\n",
      "worse 0.0\n",
      "worship 0.0\n",
      "worth 0.0\n",
      "would 0.0010545344791271247\n",
      "wouldn 0.0\n",
      "write 0.0004114768558685018\n",
      "writes 0.0005893469134871454\n",
      "writing 0.00020297383157137882\n",
      "writings 0.0\n",
      "written 0.0\n",
      "wrong 0.002125610245626804\n",
      "wrote 0.0\n",
      "x11 0.0\n",
      "xv 0.0\n",
      "ye 0.00045283044192472185\n",
      "yeah 0.0\n",
      "year 0.0005701902230896116\n",
      "years 0.00039509934871912806\n",
      "yes 4.5427266667188384e-06\n",
      "yet 0.0\n",
      "york 0.0\n",
      "you 0.0077517919234373674\n",
      "young 0.0\n",
      "your 0.0013478020377440622\n",
      "yourself 0.0032160609734238326\n",
      "zero 0.0\n",
      "zip 0.0\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(tfidf.get_feature_names_out(), gb.feature_importances_):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space 0.12606815556503398\n",
      "graphics 0.07955738535484687\n",
      "atheism 0.023543258791466362\n",
      "thanks 0.023046507462732756\n",
      "file 0.02055581240238831\n",
      "orbit 0.020063273938036058\n",
      "jesus 0.01814149212443511\n",
      "god 0.017712702350040938\n",
      "hi 0.016857094927865728\n",
      "nasa 0.015308260768876465\n",
      "image 0.015023452519852164\n",
      "files 0.013797145686816017\n",
      "christ 0.010426583770790022\n",
      "moon 0.010376173054679735\n",
      "bobby 0.010225361352506714\n",
      "launch 0.010061136447910934\n",
      "looking 0.009733618292917433\n",
      "christian 0.009663039306452306\n",
      "atheists 0.00940203835982551\n",
      "christians 0.008981046753380316\n",
      "fbi 0.008827368636033589\n",
      "3d 0.007819020701620837\n",
      "you 0.0077517919234373674\n",
      "not 0.007515358150120414\n",
      "islamic 0.007255118998822582\n",
      "religion 0.007182617149762632\n",
      "spacecraft 0.007074189152295396\n",
      "flight 0.006899060277543797\n",
      "computer 0.006698870635101263\n",
      "islam 0.006529364772733121\n",
      "ftp 0.0062457492372051055\n",
      "color 0.005513872126424359\n",
      "software 0.004918770389689074\n",
      "atheist 0.004805134811116729\n",
      "card 0.0047679402132682755\n",
      "people 0.004624503816321023\n",
      "koresh 0.0046083726402196415\n",
      "his 0.004571604182502271\n",
      "kent 0.004415620817426218\n",
      "sphere 0.0043345782339024655\n",
      "punishment 0.004251167347701979\n",
      "sea 0.0041914539092050285\n",
      "about 0.004021200741750711\n",
      "images 0.003979800156585894\n",
      "isn 0.003970071813706964\n",
      "earth 0.003958609175073013\n",
      "children 0.003878081793618038\n",
      "he 0.0038225793804440326\n",
      "context 0.0037359640824929847\n",
      "with 0.0037324291188048464\n",
      "morality 0.003708287839986858\n",
      "solar 0.003704544523806403\n",
      "anyone 0.003638646088176316\n",
      "objective 0.0035798279805276533\n",
      "middle 0.003501303783097672\n",
      "motto 0.003489481716737809\n",
      "an 0.0032168676591567045\n",
      "yourself 0.0032160609734238326\n",
      "order 0.0031761637974542073\n",
      "can 0.0030699596519815683\n",
      "don 0.0030420856546431382\n",
      "rocket 0.003030865477849616\n",
      "using 0.003006529940852933\n",
      "works 0.0029908853630800994\n",
      "who 0.0028970391103206156\n",
      "algorithm 0.0027776151808414575\n",
      "up 0.0027763407707124366\n",
      "format 0.002753642914068192\n",
      "truth 0.002747369720000391\n",
      "windows 0.0027366074571366404\n",
      "vga 0.0027090225677696826\n",
      "religious 0.0027006328761795886\n",
      "256 0.0026941947928842995\n",
      "some 0.0026782879129570686\n",
      "social 0.002661107525079609\n",
      "pov 0.0026571656478566836\n",
      "shuttle 0.002649659482981952\n",
      "makes 0.0026457059890133564\n",
      "need 0.0025997082494940427\n",
      "tom 0.002598784430882167\n",
      "what 0.002566321088555809\n",
      "video 0.0025189278937806548\n",
      "see 0.0024812623278755727\n",
      "screen 0.002432274216777441\n",
      "safety 0.00243070727900811\n",
      "landing 0.0023434918282320572\n",
      "centaur 0.0023356055769653836\n",
      "any 0.00230765035816326\n",
      "deletion 0.002280539797177893\n",
      "gamma 0.002279013681895662\n",
      "instance 0.002261864198410176\n",
      "bible 0.0022369513388350807\n",
      "satan 0.002231094338595317\n",
      "blood 0.002212849497278084\n",
      "claim 0.0021941385982135655\n",
      "wrong 0.002125610245626804\n",
      "words 0.0021231247155534365\n",
      "thou 0.0020845648612679716\n",
      "this 0.0020587283339791236\n",
      "must 0.002054011790496542\n",
      "authority 0.002005155158221194\n",
      "idea 0.0019465034044709112\n",
      "name 0.00191115375756526\n",
      "species 0.0018898283076018308\n",
      "vice 0.00187174627897788\n",
      "ames 0.0018415727385718414\n",
      "right 0.0018332419432593675\n",
      "thank 0.0018045393920214517\n",
      "engineering 0.0017989524402974352\n",
      "lord 0.0017760397728634534\n",
      "be 0.0017557468654310216\n",
      "but 0.001745838787689392\n",
      "brought 0.0017292541803986912\n",
      "anybody 0.0016964817201429623\n",
      "dc 0.0016625590454612373\n",
      "dos 0.0016426986393924079\n",
      "argument 0.0016343202858588562\n",
      "risk 0.001630998931070295\n",
      "version 0.0016196793482361443\n",
      "re 0.001577839868796782\n",
      "frank 0.0015559642580893983\n",
      "number 0.001549562240133334\n",
      "mail 0.0015114858285654455\n",
      "there 0.0015017249013554647\n",
      "fact 0.0014463798416662422\n",
      "or 0.0014411371748415116\n",
      "relative 0.0014204959474777212\n",
      "as 0.0014168753112069347\n",
      "back 0.001416769249722398\n",
      "values 0.0014150637995069494\n",
      "cost 0.001414288798939538\n",
      "false 0.0014013786902603211\n",
      "every 0.0013906274281025002\n",
      "policy 0.0013898224304465109\n",
      "no 0.0013786647172583514\n",
      "mean 0.0013731926349991558\n",
      "funding 0.0013645342384177024\n",
      "your 0.0013478020377440622\n",
      "abortion 0.0013365771956900937\n",
      "something 0.001328907116559956\n",
      "will 0.0013210200340496717\n",
      "was 0.0013144744953162454\n",
      "off 0.0013060366235285586\n",
      "steve 0.0013018678644410857\n",
      "ask 0.0012900279192633896\n",
      "got 0.0012886132536782198\n",
      "film 0.001244997255337577\n",
      "appear 0.0012206536242558256\n",
      "on 0.0012132857965526792\n",
      "area 0.0012048706222428686\n",
      "did 0.001194220072259786\n",
      "because 0.0011928133734964701\n",
      "actually 0.001189395929358099\n",
      "could 0.0011874733126069998\n",
      "get 0.0011793161696191947\n",
      "which 0.001172998482953918\n",
      "story 0.00117210372996638\n",
      "are 0.0011629183625439209\n",
      "package 0.001162536226599298\n",
      "vehicle 0.0011598547073011225\n",
      "unix 0.0011459916480279432\n",
      "have 0.0011450091500655724\n",
      "sky 0.001103154420807574\n",
      "prize 0.0010919723510469828\n",
      "would 0.0010545344791271247\n",
      "own 0.0010515845256762065\n",
      "thought 0.0010483378356254266\n",
      "meaning 0.0010454074797123926\n",
      "enough 0.0010375996561850104\n",
      "pc 0.000993466817768178\n",
      "theory 0.000975880253521748\n",
      "presented 0.0009693858998124329\n",
      "rest 0.0009693641021879354\n",
      "think 0.0009652715178819101\n",
      "product 0.0009585280900717834\n",
      "mars 0.0009495101897504724\n",
      "him 0.0009426062831141956\n",
      "24 0.0009253411970573228\n",
      "animals 0.0009204239234191663\n",
      "life 0.0009150846456509991\n",
      "believing 0.0009122578985673935\n",
      "from 0.0009025485645248978\n",
      "sense 0.0008977312361442524\n",
      "beliefs 0.000891231295794348\n",
      "astro 0.0008740308560481299\n",
      "qur 0.0008710091857566701\n",
      "being 0.0008661304423458539\n",
      "beings 0.0008654350432102584\n",
      "days 0.0008596005691745591\n",
      "ever 0.000857912064822305\n",
      "23 0.0008565498604531021\n",
      "observatory 0.0008548955965391742\n",
      "seems 0.0008498253823183349\n",
      "code 0.0008497766735795678\n",
      "society 0.0008469687394208445\n",
      "say 0.0008460914003996936\n",
      "me 0.0008450955721967616\n",
      "dead 0.0008383353444774061\n",
      "liar 0.0008333327172740278\n",
      "sounds 0.0008281232039213332\n",
      "at 0.0008206004770786626\n",
      "air 0.0008107025566512087\n",
      "long 0.0008076171681764072\n",
      "behavior 0.0008049883063323705\n",
      "old 0.0007962936810091196\n",
      "thing 0.0007913042727385488\n",
      "her 0.0007904847828314182\n",
      "kind 0.0007888059080417774\n",
      "run 0.0007806379963779749\n",
      "crime 0.0007752224605710041\n",
      "research 0.0007732373003027196\n",
      "church 0.0007713310930969447\n",
      "humans 0.0007645248517751807\n",
      "war 0.0007623387825459219\n",
      "so 0.0007539266215475038\n",
      "line 0.0007515464692248082\n",
      "prophet 0.0007443339595418886\n",
      "power 0.0007398865355411253\n",
      "by 0.000727187469264633\n",
      "whose 0.0007092322641962879\n",
      "early 0.0007032381081861648\n",
      "use 0.000700302390323802\n",
      "part 0.0006839613486920049\n",
      "shall 0.0006834913012315922\n",
      "42 0.0006758577227103907\n",
      "again 0.0006667879048352848\n",
      "quite 0.0006662970356742854\n",
      "way 0.0006552148008421341\n",
      "we 0.0006532303131788518\n",
      "they 0.0006455333868779101\n",
      "historical 0.0006453011673272355\n",
      "during 0.0006452263849305291\n",
      "true 0.0006413766672585178\n",
      "high 0.0006393779494035694\n",
      "least 0.0006348378207779071\n",
      "made 0.000634351554492784\n",
      "please 0.0006327336279207689\n",
      "lower 0.0006291320151541631\n",
      "do 0.0006281755411658071\n",
      "30 0.0006247876254295323\n",
      "matthew 0.0006181273160759118\n",
      "article 0.0006110995204927513\n",
      "object 0.0006086791705081454\n",
      "does 0.0006063748435298301\n",
      "good 0.0006053506112290903\n",
      "like 0.0006006562246313029\n",
      "more 0.0005931787767118047\n",
      "white 0.0005909499853189306\n",
      "writes 0.0005893469134871454\n",
      "witness 0.0005888492540385882\n",
      "26 0.0005861303016457679\n",
      "six 0.0005815941686917298\n",
      "threat 0.000580709373629012\n",
      "email 0.0005805296514802775\n",
      "actions 0.000574468708566203\n",
      "year 0.0005701902230896116\n",
      "heavy 0.0005630966852445066\n",
      "only 0.0005607004822454306\n",
      "sorry 0.0005602543805846834\n",
      "little 0.0005492663826017807\n",
      "larger 0.0005484617007554058\n",
      "named 0.0005444529201618805\n",
      "saying 0.0005419543789443866\n",
      "time 0.0005416943102065281\n",
      "polygons 0.0005401794540042405\n",
      "edges 0.0005362239065294314\n",
      "personal 0.0005341933382549381\n",
      "discussion 0.0005274698751468405\n",
      "doing 0.0005260575196558689\n",
      "place 0.0005240028518341293\n",
      "either 0.0005239327855033156\n",
      "correct 0.0005166034615067739\n",
      "polygon 0.0005126282702360788\n",
      "tells 0.0005050262032379974\n",
      "allen 0.0005049868883446301\n",
      "liquid 0.0004991924185064901\n",
      "lewis 0.0004956459391670244\n",
      "jpeg 0.0004934686072367636\n",
      "venus 0.0004901254921099725\n",
      "well 0.0004893345771276899\n",
      "stand 0.00048432821172717747\n",
      "us 0.00048305356240955106\n",
      "reason 0.0004800135350082655\n",
      "just 0.000479508032556587\n",
      "perfect 0.0004744539167280677\n",
      "laws 0.0004743132601215618\n",
      "assume 0.00047273438105121303\n",
      "hudson 0.0004659897334301078\n",
      "half 0.0004636107279619241\n",
      "age 0.00045712422927190154\n",
      "has 0.0004549517471414819\n",
      "someone 0.00045372501422179517\n",
      "determined 0.00045361041998769676\n",
      "ye 0.00045283044192472185\n",
      "posting 0.00044779816267309316\n",
      "kill 0.0004476809977456047\n",
      "times 0.0004396160006457924\n",
      "money 0.0004378450208577286\n",
      "post 0.00043750338320032765\n",
      "germany 0.0004303555820234818\n",
      "were 0.0004281257369772854\n",
      "proposed 0.00042697967159680813\n",
      "stuff 0.0004257546004272344\n",
      "knows 0.00042485984148497846\n",
      "those 0.0004215135520285458\n",
      "them 0.00041927775557063\n",
      "virtual 0.00041513311916285887\n",
      "write 0.0004114768558685018\n",
      "send 0.0004083519314590018\n",
      "contracts 0.0004082965684754363\n",
      "heard 0.0004053439180347534\n",
      "supposedly 0.0004025699479603851\n",
      "gov 0.00039673496602739207\n",
      "ll 0.00039664037528382265\n",
      "help 0.0003961244726651213\n",
      "pay 0.00039601159795435773\n",
      "very 0.00039582123982335576\n",
      "years 0.00039509934871912806\n",
      "practice 0.00039210968102894073\n",
      "when 0.00038779897616703996\n",
      "other 0.0003866973745676854\n",
      "tar 0.0003858051284968009\n",
      "iii 0.000384300076302786\n",
      "used 0.0003842895612586752\n",
      "jupiter 0.0003839393135279627\n",
      "paradise 0.00038309549981608925\n",
      "surface 0.0003820707150858351\n",
      "rockets 0.0003790026412635472\n",
      "many 0.00037832136186519876\n",
      "whole 0.00037379642788262167\n",
      "stories 0.000372986062499247\n",
      "message 0.000372550458181858\n",
      "notion 0.0003712228742702646\n",
      "understand 0.00037046640318961143\n",
      "want 0.00036976361070088483\n",
      "weak 0.00036791306704927026\n",
      "been 0.00036551644510102074\n",
      "group 0.0003626505478546586\n",
      "after 0.0003610657093138239\n",
      "know 0.00036102986529546594\n",
      "agree 0.00035870538713294556\n",
      "now 0.0003581908564172062\n",
      "ibm 0.00035570999717740153\n",
      "if 0.0003518147890719381\n",
      "control 0.00035105606336604855\n",
      "then 0.0003502967295825412\n",
      "anyway 0.00034884045255428723\n",
      "even 0.0003476816378487133\n",
      "why 0.00033928121894082834\n",
      "net 0.0003390600485993923\n",
      "creation 0.00032481947753776677\n",
      "mission 0.0003234627382487826\n",
      "ve 0.00032266205244313033\n",
      "lunar 0.0003167077756661945\n",
      "over 0.0003153202210039964\n",
      "all 0.00031499417806122063\n",
      "versions 0.00031430536781181174\n",
      "program 0.0003109592387632648\n",
      "here 0.0003096897589318853\n",
      "talk 0.00030178366346074833\n",
      "cs 0.000300620583453601\n",
      "associated 0.00029804124162728266\n",
      "cview 0.0002951647099991048\n",
      "going 0.00029022745526198046\n",
      "subject 0.00028818255397644805\n",
      "moment 0.0002856115790776782\n",
      "am 0.0002854609591136947\n",
      "sin 0.0002830955250420604\n",
      "had 0.00028178468033954093\n",
      "value 0.00028088027033067723\n",
      "known 0.00027922844046069154\n",
      "translation 0.00027181973328546004\n",
      "how 0.0002669469158859094\n",
      "rather 0.00026667006037260724\n",
      "library 0.00026008492186409754\n",
      "easy 0.00025669305378470906\n",
      "examples 0.0002508406421371261\n",
      "built 0.00024912703605869144\n",
      "wings 0.0002401402498160918\n",
      "reasons 0.00023707223545873496\n",
      "remember 0.00023560684146751578\n",
      "work 0.00023441815891104032\n",
      "new 0.00023130424874347487\n",
      "actual 0.00022882978198113802\n",
      "problem 0.00022777141500415773\n",
      "star 0.00022721805621209626\n",
      "question 0.00022669035729934797\n",
      "companies 0.00022566153375722708\n",
      "course 0.00022542877062161547\n",
      "understanding 0.00022475589552999615\n",
      "explain 0.00022415019063168223\n",
      "faster 0.00022319667461234715\n",
      "son 0.00022135893645766557\n",
      "may 0.00021955420406091544\n",
      "arc 0.00021777802302715846\n",
      "aerospace 0.00021683921165421892\n",
      "taking 0.00021644343444633825\n",
      "running 0.0002142461991870773\n",
      "observation 0.00020936192190479938\n",
      "advance 0.0002063886726406131\n",
      "against 0.00020573593797638872\n",
      "writing 0.00020297383157137882\n",
      "everything 0.0002029206548586842\n",
      "while 0.0001971501429756365\n",
      "fire 0.0001930762272330564\n",
      "another 0.00019141136038358284\n",
      "van 0.00018906143577739174\n",
      "01 0.0001879332127649151\n",
      "unit 0.0001868569556607031\n",
      "add 0.00018543039751701162\n",
      "above 0.0001852456871647147\n",
      "pat 0.00018450593714059124\n",
      "earlier 0.0001831634930438586\n",
      "wonder 0.00018139411126343657\n",
      "chance 0.00018136316387042038\n",
      "down 0.000179561849646387\n",
      "between 0.00017919936035047237\n",
      "offer 0.00017883708039570956\n",
      "out 0.0001784540566551595\n",
      "rights 0.00017727688438328321\n",
      "report 0.00017523006098877904\n",
      "logic 0.00017380775083034595\n",
      "teach 0.00017372753597667362\n",
      "original 0.00017346445431237596\n",
      "held 0.00017277233656109265\n",
      "much 0.00016962888293392992\n",
      "position 0.00016961741305616078\n",
      "simply 0.00016752555656221365\n",
      "usually 0.00016715046111961845\n",
      "appreciate 0.000166854694458385\n",
      "hp 0.0001654957613492829\n",
      "nice 0.000165176670889614\n",
      "should 0.00016436589415548105\n",
      "spin 0.00016421930043908827\n",
      "clearly 0.00016414886195183136\n",
      "care 0.00016312463554904612\n",
      "manner 0.0001601224390638462\n",
      "morals 0.00015899092990213679\n",
      "thus 0.00015885624030137642\n",
      "building 0.00015652665009648244\n",
      "seriously 0.00015631753074823592\n",
      "word 0.00015618648560117358\n",
      "likely 0.00015587034581383702\n",
      "too 0.00015144822445813002\n",
      "its 0.00014980950621723029\n",
      "believe 0.00014914634712008375\n",
      "allow 0.00014710063044539296\n",
      "natural 0.00014695400611861945\n",
      "point 0.00014680301716511241\n",
      "take 0.00014618553164763508\n",
      "said 0.00014362183822903143\n",
      "clear 0.0001392521807621185\n",
      "along 0.00013851613399685052\n",
      "where 0.00013744853161422245\n",
      "de 0.00013392566552518462\n",
      "pub 0.00013314714212570025\n",
      "perhaps 0.000132034039587979\n",
      "colors 0.00013200544360436505\n",
      "results 0.00013157867495587408\n",
      "choice 0.00013154059944658664\n",
      "articles 0.00012871614263591113\n",
      "movie 0.0001286286322172202\n",
      "working 0.00012821299588025706\n",
      "discovered 0.00012724482679248259\n",
      "points 0.00012685573467914049\n",
      "also 0.00012405719772918107\n",
      "mind 0.00012312530821232513\n",
      "distance 0.00012284999022582342\n",
      "misc 0.00012223451158268258\n",
      "sure 0.00012168056092492279\n",
      "recently 0.00011883857614644004\n",
      "effort 0.00011835915700208143\n",
      "current 0.00011801487025913063\n",
      "really 0.00011790060863491506\n",
      "possibly 0.00011707220754144579\n",
      "com 0.00010916803223177912\n",
      "greek 0.00010841595889788165\n",
      "try 0.00010581219969615915\n",
      "before 0.00010529099564449867\n",
      "won 0.00010458378286548737\n",
      "black 0.0001035699074081951\n",
      "reality 0.00010276375526062407\n",
      "than 0.00010234061792451569\n",
      "whether 0.00010228758457691337\n",
      "didn 0.00010208376712202417\n",
      "seen 0.00010035529743299483\n",
      "10 9.883607872510905e-05\n",
      "make 9.812484301112591e-05\n",
      "lot 9.744092657486346e-05\n",
      "few 9.14389547298412e-05\n",
      "goes 8.712937810859155e-05\n",
      "agency 8.699201445646343e-05\n",
      "beyond 8.586199953200856e-05\n",
      "else 8.48265505900154e-05\n",
      "world 8.371106099599103e-05\n",
      "response 8.369365571362257e-05\n",
      "example 8.341923319379657e-05\n",
      "real 8.281172013451218e-05\n",
      "go 8.194779536438983e-05\n",
      "deleted 8.173310803839805e-05\n",
      "needed 7.863717310557088e-05\n",
      "process 7.832555907595932e-05\n",
      "guy 7.701325681999664e-05\n",
      "turn 7.295625354885056e-05\n",
      "1993 7.276725872058238e-05\n",
      "find 7.268201052954367e-05\n",
      "two 6.914304874469281e-05\n",
      "force 6.790703696691442e-05\n",
      "sometimes 6.635867910924274e-05\n",
      "couple 6.557423406101305e-05\n",
      "period 6.491934638755044e-05\n",
      "read 6.19141999323384e-05\n",
      "alt 6.156303489902423e-05\n",
      "32 6.111288453377536e-05\n",
      "cut 5.530269081560681e-05\n",
      "talking 5.461557262930497e-05\n",
      "large 5.415964325691409e-05\n",
      "whatever 5.0966297958903806e-05\n",
      "apr 5.070119814950246e-05\n",
      "last 4.9027856246030266e-05\n",
      "mention 4.854729661299284e-05\n",
      "second 4.8374425042621306e-05\n",
      "rate 4.81668810252629e-05\n",
      "information 4.669006570913476e-05\n",
      "interface 4.393556644505389e-05\n",
      "bit 4.393515363585692e-05\n",
      "edu 4.250777720193582e-05\n",
      "most 4.1812812085434826e-05\n",
      "call 4.159563387144104e-05\n",
      "list 3.735326318435081e-05\n",
      "ii 3.494161070440823e-05\n",
      "found 3.275501124741085e-05\n",
      "mode 3.154423917053411e-05\n",
      "based 2.8998804942863516e-05\n",
      "existence 2.7304122431486432e-05\n",
      "environment 2.635531665081521e-05\n",
      "able 2.2247381322709356e-05\n",
      "first 2.0821277450376522e-05\n",
      "direct 1.9178831721988568e-05\n",
      "public 1.8554835949064906e-05\n",
      "closed 1.840083880856948e-05\n",
      "change 1.8312257306308527e-05\n",
      "these 1.6986206665360382e-05\n",
      "integration 1.4904064868556818e-05\n",
      "require 1.485636787530014e-05\n",
      "thinks 1.4106734330914905e-05\n",
      "terms 1.3475821022772477e-05\n",
      "still 1.3213649590567541e-05\n",
      "their 1.1954365874962979e-05\n",
      "learning 1.1252181666875853e-05\n",
      "subjective 1.0735331125951252e-05\n",
      "past 1.0714804576174994e-05\n",
      "status 9.22569755791523e-06\n",
      "obvious 8.77952848624698e-06\n",
      "dr 8.485015203714497e-06\n",
      "advertising 8.00210172513112e-06\n",
      "ok 7.716487022533708e-06\n",
      "maybe 7.49594213554309e-06\n",
      "university 7.437728973194327e-06\n",
      "become 7.206001337932068e-06\n",
      "stay 7.0945646524818846e-06\n",
      "week 7.088544830457518e-06\n",
      "bad 6.992649119709222e-06\n",
      "tell 6.816606002203573e-06\n",
      "satellite 6.346005519071837e-06\n",
      "index 6.019478480264712e-06\n",
      "system 5.749308891078484e-06\n",
      "currently 5.3582521394159696e-06\n",
      "hope 5.330483119327981e-06\n",
      "yes 4.5427266667188384e-06\n",
      "under 4.3969777624213676e-06\n",
      "92 4.253484346946885e-06\n",
      "might 4.091120123975836e-06\n",
      "one 4.067636327254046e-06\n",
      "active 4.027015895159583e-06\n",
      "nothing 3.65869837382592e-06\n",
      "come 3.528435204550263e-06\n",
      "show 3.4245338794855555e-06\n",
      "supports 3.2956514954959094e-06\n",
      "things 3.239229791973488e-06\n",
      "view 3.161261327410469e-06\n",
      "says 3.033253972318854e-06\n",
      "description 3.0262150005179176e-06\n",
      "potential 2.9908839530191897e-06\n",
      "different 2.7901627343921874e-06\n",
      "physics 2.7829825981178723e-06\n",
      "posted 2.421751702377557e-06\n",
      "man 2.3342515806469015e-06\n",
      "my 2.2929707756345686e-06\n",
      "called 2.2304536093293546e-06\n",
      "big 2.0600202880061013e-06\n",
      "interest 2.0591731634517822e-06\n",
      "cause 1.91848803257755e-06\n",
      "authors 1.8977529465396043e-06\n",
      "stage 1.8792401632620373e-06\n",
      "months 1.8775608243122939e-06\n",
      "prove 1.7639579385272698e-06\n",
      "history 1.7566457391529566e-06\n",
      "light 1.5671144191595974e-06\n",
      "21 1.412171476439304e-06\n",
      "gone 1.3113756925521325e-06\n",
      "room 1.2679539237430952e-06\n",
      "frame 1.019574450132984e-06\n",
      "physical 9.760029280315442e-07\n",
      "homosexuality 9.365891298196054e-07\n",
      "evidence 8.208144839617542e-07\n",
      "text 6.748777592386361e-07\n",
      "1000 6.473751341709295e-07\n",
      "computers 5.623294285862016e-07\n",
      "faq 4.892190349894197e-07\n",
      "provides 4.833058618699295e-07\n",
      "supply 4.521146610069622e-07\n",
      "around 4.4803328988586855e-07\n",
      "far 4.47740666784297e-07\n",
      "note 3.6731892523203144e-07\n",
      "once 3.543933155984333e-07\n",
      "anti 3.358713698955184e-07\n",
      "dynamics 3.0962643370446876e-07\n",
      "parts 2.617166799042063e-07\n",
      "15 2.516124350974213e-07\n",
      "requirements 2.4097665349929973e-07\n",
      "demand 2.3149490765453783e-07\n",
      "13 2.008425648829126e-07\n",
      "simple 1.6372291905026454e-07\n",
      "better 1.0367839720829817e-07\n",
      "interested 1.0159638302042263e-07\n",
      "alone 8.894611013430934e-08\n",
      "seeing 8.202511119701063e-08\n",
      "per 7.578902850233891e-08\n",
      "jim 5.255504965593684e-08\n",
      "doesn 2.8550209473289137e-08\n",
      "page 1.368716533362388e-08\n",
      "create 1.2388156723071158e-08\n",
      "getting 1.2092088618855296e-08\n",
      "red 1.2059290928522796e-08\n",
      "probably 1.0787045057016281e-08\n",
      "others 6.645602954465292e-09\n",
      "death 6.2535475804496746e-09\n",
      "comes 2.7840198210878303e-09\n",
      "accept 2.216823186325628e-09\n",
      "posts 4.332328076164999e-10\n",
      "applications 2.197109844871139e-18\n",
      "aircraft 1.0550477967945571e-18\n",
      "center 4.1331769358962026e-19\n",
      "purposes 0.0\n",
      "private 0.0\n",
      "propulsion 0.0\n",
      "printer 0.0\n",
      "print 0.0\n",
      "processes 0.0\n",
      "published 0.0\n",
      "produce 0.0\n",
      "principles 0.0\n",
      "processing 0.0\n",
      "produced 0.0\n",
      "problems 0.0\n",
      "projects 0.0\n",
      "professional 0.0\n",
      "programming 0.0\n",
      "provided 0.0\n",
      "proof 0.0\n",
      "pro 0.0\n",
      "properly 0.0\n",
      "provide 0.0\n",
      "prophecy 0.0\n",
      "products 0.0\n",
      "project 0.0\n",
      "probe 0.0\n",
      "profit 0.0\n",
      "proton 0.0\n",
      "put 0.0\n",
      "probes 0.0\n",
      "providing 0.0\n",
      "programs 0.0\n",
      "purpose 0.0\n",
      "00 0.0\n",
      "particular 0.0\n",
      "princeton 0.0\n",
      "okay 0.0\n",
      "ones 0.0\n",
      "online 0.0\n",
      "open 0.0\n",
      "operating 0.0\n",
      "operation 0.0\n",
      "operations 0.0\n",
      "opinion 0.0\n",
      "opinions 0.0\n",
      "opposite 0.0\n",
      "option 0.0\n",
      "options 0.0\n",
      "orbital 0.0\n",
      "orbiter 0.0\n",
      "oh 0.0\n",
      "orbiting 0.0\n",
      "ordered 0.0\n",
      "org 0.0\n",
      "organization 0.0\n",
      "organizations 0.0\n",
      "oriented 0.0\n",
      "origin 0.0\n",
      "originally 0.0\n",
      "orthodox 0.0\n",
      "os 0.0\n",
      "otherwise 0.0\n",
      "our 0.0\n",
      "output 0.0\n",
      "outside 0.0\n",
      "ozone 0.0\n",
      "orbits 0.0\n",
      "packages 0.0\n",
      "often 0.0\n",
      "office 0.0\n",
      "nearly 0.0\n",
      "necessarily 0.0\n",
      "necessary 0.0\n",
      "needs 0.0\n",
      "neither 0.0\n",
      "network 0.0\n",
      "never 0.0\n",
      "news 0.0\n",
      "newsgroup 0.0\n",
      "next 0.0\n",
      "nick 0.0\n",
      "night 0.0\n",
      "non 0.0\n",
      "none 0.0\n",
      "official 0.0\n",
      "nor 0.0\n",
      "north 0.0\n",
      "noted 0.0\n",
      "notes 0.0\n",
      "notice 0.0\n",
      "nuclear 0.0\n",
      "numbers 0.0\n",
      "ny 0.0\n",
      "objects 0.0\n",
      "observations 0.0\n",
      "observer 0.0\n",
      "obviously 0.0\n",
      "occurs 0.0\n",
      "odd 0.0\n",
      "offers 0.0\n",
      "normal 0.0\n",
      "pages 0.0\n",
      "paper 0.0\n",
      "papers 0.0\n",
      "planets 0.0\n",
      "planned 0.0\n",
      "platforms 0.0\n",
      "play 0.0\n",
      "plot 0.0\n",
      "plotting 0.0\n",
      "plus 0.0\n",
      "pointed 0.0\n",
      "political 0.0\n",
      "poor 0.0\n",
      "popular 0.0\n",
      "population 0.0\n",
      "positions 0.0\n",
      "positive 0.0\n",
      "planetary 0.0\n",
      "possibility 0.0\n",
      "postings 0.0\n",
      "postscript 0.0\n",
      "pre 0.0\n",
      "premise 0.0\n",
      "premises 0.0\n",
      "present 0.0\n",
      "president 0.0\n",
      "press 0.0\n",
      "pressure 0.0\n",
      "pretty 0.0\n",
      "previous 0.0\n",
      "price 0.0\n",
      "primarily 0.0\n",
      "primary 0.0\n",
      "possible 0.0\n",
      "planet 0.0\n",
      "plane 0.0\n",
      "plan 0.0\n",
      "parallel 0.0\n",
      "parameters 0.0\n",
      "particularly 0.0\n",
      "pascal 0.0\n",
      "pass 0.0\n",
      "passage 0.0\n",
      "passages 0.0\n",
      "path 0.0\n",
      "paul 0.0\n",
      "payload 0.0\n",
      "payloads 0.0\n",
      "peace 0.0\n",
      "perfectly 0.0\n",
      "performance 0.0\n",
      "performed 0.0\n",
      "permission 0.0\n",
      "person 0.0\n",
      "places 0.0\n",
      "placed 0.0\n",
      "pixels 0.0\n",
      "pixel 0.0\n",
      "pioneer 0.0\n",
      "piece 0.0\n",
      "principle 0.0\n",
      "pictures 0.0\n",
      "pick 0.0\n",
      "phone 0.0\n",
      "philosophy 0.0\n",
      "peter 0.0\n",
      "perspective 0.0\n",
      "personally 0.0\n",
      "picture 0.0\n",
      "putting 0.0\n",
      "sets 0.0\n",
      "questions 0.0\n",
      "throughout 0.0\n",
      "through 0.0\n",
      "three 0.0\n",
      "thread 0.0\n",
      "thousands 0.0\n",
      "though 0.0\n",
      "thomas 0.0\n",
      "third 0.0\n",
      "tiff 0.0\n",
      "thinking 0.0\n",
      "therefore 0.0\n",
      "themselves 0.0\n",
      "theists 0.0\n",
      "testing 0.0\n",
      "testament 0.0\n",
      "test 0.0\n",
      "term 0.0\n",
      "tend 0.0\n",
      "thermal 0.0\n",
      "titan 0.0\n",
      "title 0.0\n",
      "today 0.0\n",
      "tried 0.0\n",
      "transfer 0.0\n",
      "training 0.0\n",
      "tradition 0.0\n",
      "tracking 0.0\n",
      "track 0.0\n",
      "tracing 0.0\n",
      "tracer 0.0\n",
      "towards 0.0\n",
      "totally 0.0\n",
      "total 0.0\n",
      "topic 0.0\n",
      "top 0.0\n",
      "tools 0.0\n",
      "tool 0.0\n",
      "took 0.0\n",
      "tony 0.0\n",
      "told 0.0\n",
      "together 0.0\n",
      "telling 0.0\n",
      "telescope 0.0\n",
      "telephone 0.0\n",
      "tel 0.0\n",
      "suite 0.0\n",
      "suggestions 0.0\n",
      "suggest 0.0\n",
      "sufficient 0.0\n",
      "such 0.0\n",
      "successful 0.0\n",
      "subscribe 0.0\n",
      "stupid 0.0\n",
      "study 0.0\n",
      "studies 0.0\n",
      "structure 0.0\n",
      "strongly 0.0\n",
      "strong 0.0\n",
      "street 0.0\n",
      "straight 0.0\n",
      "stop 0.0\n",
      "stephen 0.0\n",
      "step 0.0\n",
      "station 0.0\n",
      "summary 0.0\n",
      "trouble 0.0\n",
      "sun 0.0\n",
      "support 0.0\n",
      "technology 0.0\n",
      "technologies 0.0\n",
      "techniques 0.0\n",
      "technical 0.0\n",
      "team 0.0\n",
      "teachings 0.0\n",
      "teaching 0.0\n",
      "teaches 0.0\n",
      "tax 0.0\n",
      "takes 0.0\n",
      "taken 0.0\n",
      "systems 0.0\n",
      "svga 0.0\n",
      "surfaces 0.0\n",
      "surely 0.0\n",
      "supposed 0.0\n",
      "suppose 0.0\n",
      "supporting 0.0\n",
      "supported 0.0\n",
      "super 0.0\n",
      "states 0.0\n",
      "truly 0.0\n",
      "turned 0.0\n",
      "whom 0.0\n",
      "western 0.0\n",
      "west 0.0\n",
      "went 0.0\n",
      "welcome 0.0\n",
      "weiss 0.0\n",
      "weight 0.0\n",
      "weeks 0.0\n",
      "wide 0.0\n",
      "ways 0.0\n",
      "waste 0.0\n",
      "wasn 0.0\n",
      "washington 0.0\n",
      "wants 0.0\n",
      "wanted 0.0\n",
      "wall 0.0\n",
      "wait 0.0\n",
      "voyager 0.0\n",
      "water 0.0\n",
      "willing 0.0\n",
      "window 0.0\n",
      "wish 0.0\n",
      "young 0.0\n",
      "york 0.0\n",
      "yet 0.0\n",
      "yeah 0.0\n",
      "xv 0.0\n",
      "x11 0.0\n",
      "wrote 0.0\n",
      "written 0.0\n",
      "writings 0.0\n",
      "wouldn 0.0\n",
      "worth 0.0\n",
      "worship 0.0\n",
      "worse 0.0\n",
      "workstations 0.0\n",
      "wondering 0.0\n",
      "women 0.0\n",
      "woman 0.0\n",
      "without 0.0\n",
      "within 0.0\n",
      "volume 0.0\n",
      "vol 0.0\n",
      "voice 0.0\n",
      "visualization 0.0\n",
      "users 0.0\n",
      "user 0.0\n",
      "usenet 0.0\n",
      "useful 0.0\n",
      "usa 0.0\n",
      "upper 0.0\n",
      "upon 0.0\n",
      "until 0.0\n",
      "unlikely 0.0\n",
      "unless 0.0\n",
      "universe 0.0\n",
      "united 0.0\n",
      "unfortunately 0.0\n",
      "uk 0.0\n",
      "tyre 0.0\n",
      "typical 0.0\n",
      "types 0.0\n",
      "type 0.0\n",
      "tv 0.0\n",
      "uses 0.0\n",
      "trying 0.0\n",
      "usual 0.0\n",
      "utilities 0.0\n",
      "visual 0.0\n",
      "vision 0.0\n",
      "visible 0.0\n",
      "viking 0.0\n",
      "views 0.0\n",
      "viewpoint 0.0\n",
      "viewing 0.0\n",
      "viewers 0.0\n",
      "viewer 0.0\n",
      "via 0.0\n",
      "vesa 0.0\n",
      "verses 0.0\n",
      "verse 0.0\n",
      "venture 0.0\n",
      "velocity 0.0\n",
      "vehicles 0.0\n",
      "various 0.0\n",
      "variety 0.0\n",
      "valid 0.0\n",
      "utah 0.0\n",
      "quality 0.0\n",
      "statements 0.0\n",
      "stated 0.0\n",
      "revelation 0.0\n",
      "return 0.0\n",
      "result 0.0\n",
      "responsible 0.0\n",
      "responsibility 0.0\n",
      "responses 0.0\n",
      "respond 0.0\n",
      "respect 0.0\n",
      "road 0.0\n",
      "resources 0.0\n",
      "resolution 0.0\n",
      "requires 0.0\n",
      "required 0.0\n",
      "requests 0.0\n",
      "request 0.0\n",
      "represent 0.0\n",
      "reports 0.0\n",
      "reported 0.0\n",
      "resource 0.0\n",
      "robert 0.0\n",
      "rocketry 0.0\n",
      "roll 0.0\n",
      "sci 0.0\n",
      "school 0.0\n",
      "scholars 0.0\n",
      "scale 0.0\n",
      "saw 0.0\n",
      "save 0.0\n",
      "saturn 0.0\n",
      "satellites 0.0\n",
      "san 0.0\n",
      "same 0.0\n",
      "salvation 0.0\n",
      "sales 0.0\n",
      "russian 0.0\n",
      "rushdie 0.0\n",
      "runs 0.0\n",
      "rules 0.0\n",
      "rule 0.0\n",
      "row 0.0\n",
      "routines 0.0\n",
      "reply 0.0\n",
      "rendering 0.0\n",
      "removed 0.0\n",
      "remote 0.0\n",
      "reads 0.0\n",
      "reading 0.0\n",
      "readers 0.0\n",
      "reach 0.0\n",
      "rayshade 0.0\n",
      "ray 0.0\n",
      "raster 0.0\n",
      "range 0.0\n",
      "raised 0.0\n",
      "raise 0.0\n",
      "radius 0.0\n",
      "radiosity 0.0\n",
      "radio 0.0\n",
      "radar 0.0\n",
      "ra 0.0\n",
      "quotes 0.0\n",
      "quoted 0.0\n",
      "quote 0.0\n",
      "quicktime 0.0\n",
      "ready 0.0\n",
      "science 0.0\n",
      "realize 0.0\n",
      "reasoning 0.0\n",
      "remain 0.0\n",
      "religions 0.0\n",
      "reliable 0.0\n",
      "relevant 0.0\n",
      "released 0.0\n",
      "release 0.0\n",
      "related 0.0\n",
      "reject 0.0\n",
      "regards 0.0\n",
      "regarding 0.0\n",
      "references 0.0\n",
      "reference 0.0\n",
      "refer 0.0\n",
      "redesign 0.0\n",
      "recommend 0.0\n",
      "recent 0.0\n",
      "received 0.0\n",
      "receive 0.0\n",
      "recall 0.0\n",
      "reasonable 0.0\n",
      "statement 0.0\n",
      "sciences 0.0\n",
      "scientists 0.0\n",
      "south 0.0\n",
      "sources 0.0\n",
      "source 0.0\n",
      "sound 0.0\n",
      "soul 0.0\n",
      "sort 0.0\n",
      "soon 0.0\n",
      "somewhere 0.0\n",
      "soviet 0.0\n",
      "somewhat 0.0\n",
      "solution 0.0\n",
      "solid 0.0\n",
      "smaller 0.0\n",
      "small 0.0\n",
      "size 0.0\n",
      "situation 0.0\n",
      "sites 0.0\n",
      "site 0.0\n",
      "somehow 0.0\n",
      "speak 0.0\n",
      "speaking 0.0\n",
      "special 0.0\n",
      "state 0.0\n",
      "starting 0.0\n",
      "started 0.0\n",
      "start 0.0\n",
      "stars 0.0\n",
      "stanford 0.0\n",
      "standards 0.0\n",
      "standard 0.0\n",
      "st 0.0\n",
      "ssto 0.0\n",
      "ssf 0.0\n",
      "spot 0.0\n",
      "split 0.0\n",
      "spirit 0.0\n",
      "spent 0.0\n",
      "spend 0.0\n",
      "speed 0.0\n",
      "specifically 0.0\n",
      "specific 0.0\n",
      "single 0.0\n",
      "since 0.0\n",
      "similar 0.0\n",
      "silver 0.0\n",
      "server 0.0\n",
      "serious 0.0\n",
      "series 0.0\n",
      "sequence 0.0\n",
      "separate 0.0\n",
      "sentence 0.0\n",
      "sent 0.0\n",
      "sensing 0.0\n",
      "semi 0.0\n",
      "sell 0.0\n",
      "self 0.0\n",
      "selection 0.0\n",
      "select 0.0\n",
      "seemed 0.0\n",
      "seem 0.0\n",
      "secular 0.0\n",
      "section 0.0\n",
      "search 0.0\n",
      "sdio 0.0\n",
      "servers 0.0\n",
      "scientific 0.0\n",
      "service 0.0\n",
      "set 0.0\n",
      "silicon 0.0\n",
      "significant 0.0\n",
      "signal 0.0\n",
      "sign 0.0\n",
      "siggraph 0.0\n",
      "side 0.0\n",
      "shows 0.0\n",
      "shown 0.0\n",
      "showing 0.0\n",
      "shouldn 0.0\n",
      "short 0.0\n",
      "she 0.0\n",
      "shareware 0.0\n",
      "share 0.0\n",
      "shape 0.0\n",
      "sgi 0.0\n",
      "sex 0.0\n",
      "several 0.0\n",
      "setting 0.0\n",
      "services 0.0\n",
      "near 0.0\n",
      "levels 0.0\n",
      "nature 0.0\n",
      "consequences 0.0\n",
      "conference 0.0\n",
      "conclusions 0.0\n",
      "conclusion 0.0\n",
      "conclude 0.0\n",
      "concerning 0.0\n",
      "concerned 0.0\n",
      "concept 0.0\n",
      "computing 0.0\n",
      "compression 0.0\n",
      "complex 0.0\n",
      "completely 0.0\n",
      "complete 0.0\n",
      "compatible 0.0\n",
      "company 0.0\n",
      "comp 0.0\n",
      "community 0.0\n",
      "communications 0.0\n",
      "common 0.0\n",
      "committee 0.0\n",
      "committed 0.0\n",
      "consider 0.0\n",
      "considered 0.0\n",
      "considering 0.0\n",
      "consistent 0.0\n",
      "costs 0.0\n",
      "corporation 0.0\n",
      "corp 0.0\n",
      "core 0.0\n",
      "copy 0.0\n",
      "copies 0.0\n",
      "convince 0.0\n",
      "converter 0.0\n",
      "convert 0.0\n",
      "conversion 0.0\n",
      "commercial 0.0\n",
      "controlled 0.0\n",
      "contradictory 0.0\n",
      "contradictions 0.0\n",
      "contradiction 0.0\n",
      "continue 0.0\n",
      "content 0.0\n",
      "contains 0.0\n",
      "containing 0.0\n",
      "contain 0.0\n",
      "contact 0.0\n",
      "constant 0.0\n",
      "contrary 0.0\n",
      "couldn 0.0\n",
      "comments 0.0\n",
      "comment 0.0\n",
      "changes 0.0\n",
      "changed 0.0\n",
      "ch 0.0\n",
      "certainly 0.0\n",
      "certain 0.0\n",
      "century 0.0\n",
      "central 0.0\n",
      "centers 0.0\n",
      "cd 0.0\n",
      "cc 0.0\n",
      "causes 0.0\n",
      "caused 0.0\n",
      "catholic 0.0\n",
      "catalog 0.0\n",
      "cases 0.0\n",
      "case 0.0\n",
      "carry 0.0\n",
      "car 0.0\n",
      "capable 0.0\n",
      "capability 0.0\n",
      "capabilities 0.0\n",
      "chapter 0.0\n",
      "character 0.0\n",
      "charge 0.0\n",
      "cheap 0.0\n",
      "command 0.0\n",
      "coming 0.0\n",
      "comet 0.0\n",
      "college 0.0\n",
      "col 0.0\n",
      "co 0.0\n",
      "close 0.0\n",
      "class 0.0\n",
      "claims 0.0\n",
      "claimed 0.0\n",
      "commentary 0.0\n",
      "civilian 0.0\n",
      "city 0.0\n",
      "circular 0.0\n",
      "circle 0.0\n",
      "christianity 0.0\n",
      "chosen 0.0\n",
      "choose 0.0\n",
      "child 0.0\n",
      "cheers 0.0\n",
      "check 0.0\n",
      "cheaper 0.0\n",
      "civil 0.0\n",
      "count 0.0\n",
      "countries 0.0\n",
      "country 0.0\n",
      "double 0.0\n",
      "done 0.0\n",
      "domain 0.0\n",
      "dollars 0.0\n",
      "documentation 0.0\n",
      "document 0.0\n",
      "doctrine 0.0\n",
      "division 0.0\n",
      "divine 0.0\n",
      "distribution 0.0\n",
      "distributed 0.0\n",
      "displays 0.0\n",
      "display 0.0\n",
      "disk 0.0\n",
      "discussed 0.0\n",
      "discuss 0.0\n",
      "disagree 0.0\n",
      "directory 0.0\n",
      "directly 0.0\n",
      "direction 0.0\n",
      "digital 0.0\n",
      "doubt 0.0\n",
      "douglas 0.0\n",
      "draw 0.0\n",
      "drawing 0.0\n",
      "energy 0.0\n",
      "end 0.0\n",
      "elements 0.0\n",
      "element 0.0\n",
      "electronic 0.0\n",
      "efforts 0.0\n",
      "effects 0.0\n",
      "effect 0.0\n",
      "educational 0.0\n",
      "education 0.0\n",
      "difficult 0.0\n",
      "edition 0.0\n",
      "ed 0.0\n",
      "eat 0.0\n",
      "east 0.0\n",
      "easily 0.0\n",
      "easier 0.0\n",
      "each 0.0\n",
      "due 0.0\n",
      "drivers 0.0\n",
      "driver 0.0\n",
      "drive 0.0\n",
      "edge 0.0\n",
      "difference 0.0\n",
      "died 0.0\n",
      "die 0.0\n",
      "decided 0.0\n",
      "decide 0.0\n",
      "decenso 0.0\n",
      "dec 0.0\n",
      "debate 0.0\n",
      "deal 0.0\n",
      "day 0.0\n",
      "david 0.0\n",
      "dave 0.0\n",
      "date 0.0\n",
      "decision 0.0\n",
      "database 0.0\n",
      "dark 0.0\n",
      "cross 0.0\n",
      "crew 0.0\n",
      "creator 0.0\n",
      "created 0.0\n",
      "craft 0.0\n",
      "covered 0.0\n",
      "coverage 0.0\n",
      "cover 0.0\n",
      "court 0.0\n",
      "data 0.0\n",
      "cannot 0.0\n",
      "deep 0.0\n",
      "defense 0.0\n",
      "devices 0.0\n",
      "development 0.0\n",
      "developed 0.0\n",
      "develop 0.0\n",
      "determine 0.0\n",
      "details 0.0\n",
      "detailed 0.0\n",
      "designed 0.0\n",
      "design 0.0\n",
      "describes 0.0\n",
      "default 0.0\n",
      "described 0.0\n",
      "department 0.0\n",
      "demo 0.0\n",
      "delta 0.0\n",
      "deity 0.0\n",
      "degrees 0.0\n",
      "degree 0.0\n",
      "definition 0.0\n",
      "definitely 0.0\n",
      "defined 0.0\n",
      "define 0.0\n",
      "describe 0.0\n",
      "canada 0.0\n",
      "camera 0.0\n",
      "came 0.0\n",
      "address 0.0\n",
      "additional 0.0\n",
      "addition 0.0\n",
      "added 0.0\n",
      "ad 0.0\n",
      "acts 0.0\n",
      "activity 0.0\n",
      "activities 0.0\n",
      "action 0.0\n",
      "act 0.0\n",
      "across 0.0\n",
      "accurate 0.0\n",
      "account 0.0\n",
      "according 0.0\n",
      "access 0.0\n",
      "accepted 0.0\n",
      "acceptable 0.0\n",
      "ac 0.0\n",
      "absolutely 0.0\n",
      "absolute 0.0\n",
      "ability 0.0\n",
      "addresses 0.0\n",
      "admit 0.0\n",
      "advanced 0.0\n",
      "advantage 0.0\n",
      "analysis 0.0\n",
      "amount 0.0\n",
      "among 0.0\n",
      "amiga 0.0\n",
      "americans 0.0\n",
      "american 0.0\n",
      "america 0.0\n",
      "amateur 0.0\n",
      "always 0.0\n",
      "altitude 0.0\n",
      "_the 0.0\n",
      "although 0.0\n",
      "already 0.0\n",
      "almost 0.0\n",
      "allows 0.0\n",
      "allowed 0.0\n",
      "allah 0.0\n",
      "alive 0.0\n",
      "algorithms 0.0\n",
      "al 0.0\n",
      "ahead 0.0\n",
      "ago 0.0\n",
      "alternative 0.0\n",
      "95 0.0\n",
      "93 0.0\n",
      "91 0.0\n",
      "200 0.0\n",
      "20 0.0\n",
      "1992 0.0\n",
      "1991 0.0\n",
      "1990 0.0\n",
      "1989 0.0\n",
      "1988 0.0\n",
      "1987 0.0\n",
      "19 0.0\n",
      "18 0.0\n",
      "202 0.0\n",
      "17 0.0\n",
      "14 0.0\n",
      "130 0.0\n",
      "129 0.0\n",
      "128 0.0\n",
      "12 0.0\n",
      "11 0.0\n",
      "100 0.0\n",
      "05 0.0\n",
      "04 0.0\n",
      "000 0.0\n",
      "16 0.0\n",
      "ancient 0.0\n",
      "22 0.0\n",
      "27 0.0\n",
      "900 0.0\n",
      "90 0.0\n",
      "800 0.0\n",
      "80 0.0\n",
      "75 0.0\n",
      "70 0.0\n",
      "65 0.0\n",
      "600 0.0\n",
      "60 0.0\n",
      "500 0.0\n",
      "25 0.0\n",
      "50 0.0\n",
      "400 0.0\n",
      "40 0.0\n",
      "39 0.0\n",
      "35 0.0\n",
      "34 0.0\n",
      "33 0.0\n",
      "31 0.0\n",
      "300 0.0\n",
      "2d 0.0\n",
      "28 0.0\n",
      "45 0.0\n",
      "engine 0.0\n",
      "animation 0.0\n",
      "anonymous 0.0\n",
      "bill 0.0\n",
      "biblical 0.0\n",
      "best 0.0\n",
      "besides 0.0\n",
      "benefit 0.0\n",
      "below 0.0\n",
      "believers 0.0\n",
      "believed 0.0\n",
      "belief 0.0\n",
      "behind 0.0\n",
      "beginning 0.0\n",
      "begin 0.0\n",
      "becomes 0.0\n",
      "became 0.0\n",
      "bbs 0.0\n",
      "basis 0.0\n",
      "basically 0.0\n",
      "basic 0.0\n",
      "base 0.0\n",
      "bank 0.0\n",
      "background 0.0\n",
      "billion 0.0\n",
      "bitnet 0.0\n",
      "bits 0.0\n",
      "board 0.0\n",
      "calls 0.0\n",
      "california 0.0\n",
      "calculations 0.0\n",
      "cad 0.0\n",
      "ca 0.0\n",
      "buy 0.0\n",
      "business 0.0\n",
      "build 0.0\n",
      "budget 0.0\n",
      "btw 0.0\n",
      "away 0.0\n",
      "bring 0.0\n",
      "branch 0.0\n",
      "box 0.0\n",
      "bottom 0.0\n",
      "both 0.0\n",
      "born 0.0\n",
      "booster 0.0\n",
      "books 0.0\n",
      "book 0.0\n",
      "body 0.0\n",
      "bob 0.0\n",
      "brian 0.0\n",
      "aware 0.0\n",
      "avoid 0.0\n",
      "aviation 0.0\n",
      "arguments 0.0\n",
      "argue 0.0\n",
      "aren 0.0\n",
      "areas 0.0\n",
      "archives 0.0\n",
      "archive 0.0\n",
      "archie 0.0\n",
      "april 0.0\n",
      "appropriate 0.0\n",
      "approach 0.0\n",
      "ariane 0.0\n",
      "appreciated 0.0\n",
      "applied 0.0\n",
      "application 0.0\n",
      "apple 0.0\n",
      "appears 0.0\n",
      "apparently 0.0\n",
      "apollo 0.0\n",
      "anything 0.0\n",
      "antenna 0.0\n",
      "answers 0.0\n",
      "answer 0.0\n",
      "apply 0.0\n",
      "announced 0.0\n",
      "army 0.0\n",
      "art 0.0\n",
      "avenue 0.0\n",
      "available 0.0\n",
      "authorities 0.0\n",
      "author 0.0\n",
      "australia 0.0\n",
      "au 0.0\n",
      "attitude 0.0\n",
      "attempt 0.0\n",
      "atmosphere 0.0\n",
      "atlas 0.0\n",
      "array 0.0\n",
      "astronomy 0.0\n",
      "astronaut 0.0\n",
      "assumption 0.0\n",
      "assuming 0.0\n",
      "association 0.0\n",
      "assist 0.0\n",
      "assembly 0.0\n",
      "aspects 0.0\n",
      "asking 0.0\n",
      "asked 0.0\n",
      "aside 0.0\n",
      "astronomical 0.0\n",
      "engines 0.0\n",
      "english 0.0\n",
      "enjoy 0.0\n",
      "leave 0.0\n",
      "learn 0.0\n",
      "leaders 0.0\n",
      "lead 0.0\n",
      "lds 0.0\n",
      "law 0.0\n",
      "launches 0.0\n",
      "launcher 0.0\n",
      "launched 0.0\n",
      "latter 0.0\n",
      "latest 0.0\n",
      "later 0.0\n",
      "late 0.0\n",
      "language 0.0\n",
      "land 0.0\n",
      "lack 0.0\n",
      "laboratory 0.0\n",
      "lab 0.0\n",
      "knowledge 0.0\n",
      "knowing 0.0\n",
      "knew 0.0\n",
      "led 0.0\n",
      "left 0.0\n",
      "legal 0.0\n",
      "length 0.0\n",
      "location 0.0\n",
      "local 0.0\n",
      "load 0.0\n",
      "living 0.0\n",
      "lives 0.0\n",
      "live 0.0\n",
      "literature 0.0\n",
      "lists 0.0\n",
      "listing 0.0\n",
      "listed 0.0\n",
      "km 0.0\n",
      "lines 0.0\n",
      "limit 0.0\n",
      "lie 0.0\n",
      "libraries 0.0\n",
      "zero 0.0\n",
      "level 0.0\n",
      "letter 0.0\n",
      "lets 0.0\n",
      "let 0.0\n",
      "less 0.0\n",
      "leo 0.0\n",
      "limited 0.0\n",
      "kingdom 0.0\n",
      "king 0.0\n",
      "killing 0.0\n",
      "israel 0.0\n",
      "isbn 0.0\n",
      "involved 0.0\n",
      "introduction 0.0\n",
      "into 0.0\n",
      "interpretations 0.0\n",
      "interpretation 0.0\n",
      "interpret 0.0\n",
      "internet 0.0\n",
      "international 0.0\n",
      "issue 0.0\n",
      "interesting 0.0\n",
      "intended 0.0\n",
      "intelligence 0.0\n",
      "institute 0.0\n",
      "instead 0.0\n",
      "inside 0.0\n",
      "input 0.0\n",
      "innocent 0.0\n",
      "info 0.0\n",
      "industry 0.0\n",
      "individuals 0.0\n",
      "interactive 0.0\n",
      "logical 0.0\n",
      "issues 0.0\n",
      "james 0.0\n",
      "killed 0.0\n",
      "kg 0.0\n",
      "key 0.0\n",
      "kept 0.0\n",
      "ken 0.0\n",
      "keep 0.0\n",
      "justify 0.0\n",
      "justice 0.0\n",
      "june 0.0\n",
      "judge 0.0\n",
      "itself 0.0\n",
      "jsc 0.0\n",
      "journal 0.0\n",
      "joseph 0.0\n",
      "joint 0.0\n",
      "johnson 0.0\n",
      "john 0.0\n",
      "job 0.0\n",
      "jews 0.0\n",
      "jewish 0.0\n",
      "jet 0.0\n",
      "japan 0.0\n",
      "jpl 0.0\n",
      "individual 0.0\n",
      "longer 0.0\n",
      "looked 0.0\n",
      "models 0.0\n",
      "modeling 0.0\n",
      "model 0.0\n",
      "mit 0.0\n",
      "missions 0.0\n",
      "missed 0.0\n",
      "mirrors 0.0\n",
      "mirror 0.0\n",
      "miracles 0.0\n",
      "minutes 0.0\n",
      "mine 0.0\n",
      "million 0.0\n",
      "military 0.0\n",
      "mil 0.0\n",
      "mid 0.0\n",
      "michael 0.0\n",
      "methods 0.0\n",
      "method 0.0\n",
      "messiah 0.0\n",
      "merely 0.0\n",
      "mercury 0.0\n",
      "modern 0.0\n",
      "modes 0.0\n",
      "modified 0.0\n",
      "module 0.0\n",
      "national 0.0\n",
      "nation 0.0\n",
      "names 0.0\n",
      "myself 0.0\n",
      "muslims 0.0\n",
      "muslim 0.0\n",
      "murder 0.0\n",
      "multiple 0.0\n",
      "multi 0.0\n",
      "muhammad 0.0\n",
      "menu 0.0\n",
      "msdos 0.0\n",
      "mr 0.0\n",
      "move 0.0\n",
      "motion 0.0\n",
      "motif 0.0\n",
      "mostly 0.0\n",
      "mormons 0.0\n",
      "mormon 0.0\n",
      "moral 0.0\n",
      "monitor 0.0\n",
      "molecular 0.0\n",
      "ms 0.0\n",
      "mentioned 0.0\n",
      "men 0.0\n",
      "memory 0.0\n",
      "management 0.0\n",
      "making 0.0\n",
      "majority 0.0\n",
      "major 0.0\n",
      "maintain 0.0\n",
      "main 0.0\n",
      "mailing 0.0\n",
      "magellan 0.0\n",
      "magazine 0.0\n",
      "macintosh 0.0\n",
      "manipulation 0.0\n",
      "machines 0.0\n",
      "mac 0.0\n",
      "luke 0.0\n",
      "luck 0.0\n",
      "lucifer 0.0\n",
      "low 0.0\n",
      "love 0.0\n",
      "lots 0.0\n",
      "lost 0.0\n",
      "loss 0.0\n",
      "looks 0.0\n",
      "machine 0.0\n",
      "look 0.0\n",
      "mankind 0.0\n",
      "manual 0.0\n",
      "members 0.0\n",
      "member 0.0\n",
      "meeting 0.0\n",
      "meet 0.0\n",
      "media 0.0\n",
      "measurements 0.0\n",
      "meant 0.0\n",
      "means 0.0\n",
      "matters 0.0\n",
      "matter 0.0\n",
      "manned 0.0\n",
      "math 0.0\n",
      "material 0.0\n",
      "master 0.0\n",
      "mass 0.0\n",
      "mary 0.0\n",
      "market 0.0\n",
      "mark 0.0\n",
      "march 0.0\n",
      "maps 0.0\n",
      "mapping 0.0\n",
      "map 0.0\n",
      "materials 0.0\n",
      "navy 0.0\n",
      "indicates 0.0\n",
      "indeed 0.0\n",
      "flying 0.0\n",
      "fly 0.0\n",
      "flat 0.0\n",
      "five 0.0\n",
      "fits 0.0\n",
      "fit 0.0\n",
      "fine 0.0\n",
      "finally 0.0\n",
      "final 0.0\n",
      "figure 0.0\n",
      "field 0.0\n",
      "fiction 0.0\n",
      "fi 0.0\n",
      "feet 0.0\n",
      "feel 0.0\n",
      "fee 0.0\n",
      "federal 0.0\n",
      "features 0.0\n",
      "fear 0.0\n",
      "fax 0.0\n",
      "father 0.0\n",
      "folks 0.0\n",
      "follow 0.0\n",
      "followed 0.0\n",
      "followers 0.0\n",
      "function 0.0\n",
      "fully 0.0\n",
      "full 0.0\n",
      "fuel 0.0\n",
      "friends 0.0\n",
      "friend 0.0\n",
      "frequently 0.0\n",
      "french 0.0\n",
      "freedom 0.0\n",
      "free 0.0\n",
      "fast 0.0\n",
      "fred 0.0\n",
      "founded 0.0\n",
      "foundation 0.0\n",
      "forward 0.0\n",
      "former 0.0\n",
      "formats 0.0\n",
      "form 0.0\n",
      "forget 0.0\n",
      "food 0.0\n",
      "follows 0.0\n",
      "following 0.0\n",
      "four 0.0\n",
      "family 0.0\n",
      "fallacy 0.0\n",
      "fall 0.0\n",
      "exactly 0.0\n",
      "ex 0.0\n",
      "evolution 0.0\n",
      "evil 0.0\n",
      "everyone 0.0\n",
      "eventually 0.0\n",
      "events 0.0\n",
      "event 0.0\n",
      "european 0.0\n",
      "eternal 0.0\n",
      "excellent 0.0\n",
      "etc 0.0\n",
      "established 0.0\n",
      "essentially 0.0\n",
      "especially 0.0\n",
      "esa 0.0\n",
      "errors 0.0\n",
      "error 0.0\n",
      "equipment 0.0\n",
      "entirely 0.0\n",
      "entire 0.0\n",
      "enter 0.0\n",
      "et 0.0\n",
      "functions 0.0\n",
      "except 0.0\n",
      "exist 0.0\n",
      "faith 0.0\n",
      "fairly 0.0\n",
      "fair 0.0\n",
      "failed 0.0\n",
      "facts 0.0\n",
      "factor 0.0\n",
      "facility 0.0\n",
      "face 0.0\n",
      "eye 0.0\n",
      "extra 0.0\n",
      "excuse 0.0\n",
      "external 0.0\n",
      "export 0.0\n",
      "exploration 0.0\n",
      "explanation 0.0\n",
      "experiment 0.0\n",
      "experience 0.0\n",
      "expensive 0.0\n",
      "expected 0.0\n",
      "expect 0.0\n",
      "exists 0.0\n",
      "existing 0.0\n",
      "extended 0.0\n",
      "independent 0.0\n",
      "fund 0.0\n",
      "funds 0.0\n",
      "host 0.0\n",
      "homosexuals 0.0\n",
      "homosexual 0.0\n",
      "home 0.0\n",
      "holy 0.0\n",
      "hole 0.0\n",
      "hold 0.0\n",
      "hitler 0.0\n",
      "hit 0.0\n",
      "himself 0.0\n",
      "highly 0.0\n",
      "higher 0.0\n",
      "hidden 0.0\n",
      "hence 0.0\n",
      "helps 0.0\n",
      "hello 0.0\n",
      "hell 0.0\n",
      "heaven 0.0\n",
      "heart 0.0\n",
      "hear 0.0\n",
      "head 0.0\n",
      "hours 0.0\n",
      "house 0.0\n",
      "however 0.0\n",
      "hst 0.0\n",
      "increase 0.0\n",
      "incoming 0.0\n",
      "including 0.0\n",
      "includes 0.0\n",
      "included 0.0\n",
      "include 0.0\n",
      "inc 0.0\n",
      "impossible 0.0\n",
      "important 0.0\n",
      "impact 0.0\n",
      "having 0.0\n",
      "immoral 0.0\n",
      "imagine 0.0\n",
      "ignore 0.0\n",
      "ignorance 0.0\n",
      "ie 0.0\n",
      "ideas 0.0\n",
      "ideal 0.0\n",
      "hundreds 0.0\n",
      "hundred 0.0\n",
      "human 0.0\n",
      "huge 0.0\n",
      "imaging 0.0\n",
      "haven 0.0\n",
      "harm 0.0\n",
      "hardware 0.0\n",
      "giving 0.0\n",
      "gives 0.0\n",
      "given 0.0\n",
      "give 0.0\n",
      "gifs 0.0\n",
      "gif 0.0\n",
      "gets 0.0\n",
      "george 0.0\n",
      "generation 0.0\n",
      "generate 0.0\n",
      "global 0.0\n",
      "generally 0.0\n",
      "gay 0.0\n",
      "gave 0.0\n",
      "gas 0.0\n",
      "game 0.0\n",
      "galileo 0.0\n",
      "galaxy 0.0\n",
      "gain 0.0\n",
      "future 0.0\n",
      "fusion 0.0\n",
      "further 0.0\n",
      "general 0.0\n",
      "fundamental 0.0\n",
      "goal 0.0\n",
      "gospel 0.0\n",
      "hardly 0.0\n",
      "hard 0.0\n",
      "happy 0.0\n",
      "happens 0.0\n",
      "happened 0.0\n",
      "happen 0.0\n",
      "hanging 0.0\n",
      "hands 0.0\n",
      "handle 0.0\n",
      "hand 0.0\n",
      "gods 0.0\n",
      "gun 0.0\n",
      "guide 0.0\n",
      "guess 0.0\n",
      "groups 0.0\n",
      "ground 0.0\n",
      "greatly 0.0\n",
      "greater 0.0\n",
      "great 0.0\n",
      "gravity 0.0\n",
      "graphic 0.0\n",
      "government 0.0\n",
      "guilty 0.0\n",
      "zip 0.0\n"
     ]
    }
   ],
   "source": [
    "for x in np.argsort(-gb.feature_importances_):\n",
    "    print(tfidf.get_feature_names_out()[x], gb.feature_importances_[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 성능을 높이는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower())\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    features = list(map(lambda token: PorterStemmer().stem(token), words))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '100', '1000', ..., 'young', 'zero', 'zip'], dtype=object)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf = LogisticRegression()\n",
    "LR_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9301868239921337"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7509238728750924"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 20085)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 20085)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier(alpha=2.4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=2.4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier(alpha=2.4)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha=2.4)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9680432645034415"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.score(X_train_tfidf,  y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7679231337767923"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.score(X_test_tfidf,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.01)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf = MultinomialNB(alpha=0.01)\n",
    "NB_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714847590953786"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7930524759793053"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 카운트 기반의 문제점과 N-gram을 이용한 보완"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "chchedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    token_pattern=\"[a-zA-Z']{3,}\",\n",
    "    decode_error='ignore',\n",
    "    lowercase=True,\n",
    "    ngram_range=(1,3),\n",
    "    stop_words=stopwords.words(\"english\"),\n",
    "    max_df=0.5,\n",
    "    min_df=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(decode_error=&#x27;ignore&#x27;, max_df=0.5, min_df=2, ngram_range=(1, 3),\n",
       "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...],\n",
       "                token_pattern=&quot;[a-zA-Z&#x27;]{3,}&quot;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(decode_error=&#x27;ignore&#x27;, max_df=0.5, min_df=2, ngram_range=(1, 3),\n",
       "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...],\n",
       "                token_pattern=&quot;[a-zA-Z&#x27;]{3,}&quot;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(decode_error='ignore', max_df=0.5, min_df=2, ngram_range=(1, 3),\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                token_pattern=\"[a-zA-Z']{3,}\")"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 32943)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 32943)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976401179941003"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745750184774575"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'bout\",\n",
       " \"'burning'\",\n",
       " \"'cause\",\n",
       " \"'cause can't\",\n",
       " \"'cos\",\n",
       " \"'course\",\n",
       " \"'em\",\n",
       " \"'em better\",\n",
       " \"'em better shots\",\n",
       " \"'expected\",\n",
       " \"'expected errors'\",\n",
       " \"'expected errors' basically\",\n",
       " \"'fast'\",\n",
       " \"'if\",\n",
       " \"'karla'\",\n",
       " \"'karla' next\",\n",
       " \"'karla' next one\",\n",
       " \"'no\",\n",
       " \"'nodis'\",\n",
       " \"'nodis' password\",\n",
       " \"'nodis' password also\",\n",
       " \"'official\",\n",
       " \"'official doctrine\",\n",
       " \"'official doctrine think\",\n",
       " \"'ok\",\n",
       " \"'ok see\",\n",
       " \"'ok see warning\",\n",
       " \"'one\",\n",
       " \"'sci\",\n",
       " \"'sci astro'\",\n",
       " \"'smiley'\",\n",
       " \"'the\",\n",
       " \"'what's\",\n",
       " \"'what's moonbase\",\n",
       " \"'what's moonbase good\",\n",
       " \"'yes\",\n",
       " \"'you\",\n",
       " \"'zlumber\",\n",
       " 'aantal',\n",
       " 'aao',\n",
       " 'aas',\n",
       " 'aas american',\n",
       " 'aas american astronautical',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abc',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'ability means',\n",
       " 'ability means infallible',\n",
       " 'ability pass',\n",
       " 'able',\n",
       " 'able accept',\n",
       " 'able accept donations',\n",
       " 'able afford',\n",
       " 'able afford stuff',\n",
       " 'able control',\n",
       " 'able convince',\n",
       " 'able draw',\n",
       " 'able establish',\n",
       " 'able find',\n",
       " 'able get',\n",
       " 'able help',\n",
       " 'able import',\n",
       " 'able judge',\n",
       " 'able make',\n",
       " 'able read',\n",
       " 'able run',\n",
       " 'able see',\n",
       " 'able support',\n",
       " 'able tell',\n",
       " 'able tell liar',\n",
       " 'able upgrade',\n",
       " 'able use',\n",
       " 'able view',\n",
       " 'able work',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolish',\n",
       " 'abolish law',\n",
       " 'abolish law prophets',\n",
       " 'abolishment',\n",
       " 'abolitionist',\n",
       " 'abort',\n",
       " 'abortion',\n",
       " 'abortion services',\n",
       " 'abortions',\n",
       " 'abraham',\n",
       " 'abraham moses',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absence belief',\n",
       " 'absence belief existence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolute moral',\n",
       " 'absolute moral code',\n",
       " 'absolute morality',\n",
       " 'absolute objective',\n",
       " 'absolute sense',\n",
       " 'absolute truth',\n",
       " 'absolutely',\n",
       " 'absolutely nothing',\n",
       " 'absolutist',\n",
       " 'absorbed',\n",
       " 'absorption',\n",
       " 'abstact',\n",
       " 'abstact submission',\n",
       " 'abstact submission deadline',\n",
       " 'abstract',\n",
       " 'abstract videotape',\n",
       " 'abstract videotape robert',\n",
       " 'abstracts',\n",
       " 'abstracts authors',\n",
       " 'abstracts authors submit',\n",
       " 'abstracts files',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abuse mismanagement',\n",
       " 'abuse mismanagement contact',\n",
       " 'abuses',\n",
       " 'abyss',\n",
       " 'acad',\n",
       " 'acad alaska',\n",
       " 'acad alaska edu',\n",
       " 'academic',\n",
       " 'academic institutions',\n",
       " 'academic press',\n",
       " 'academy',\n",
       " 'acceleration',\n",
       " 'acceleration acceleration',\n",
       " 'acceleration time',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'accept',\n",
       " 'accept donations',\n",
       " 'accept donations keep',\n",
       " 'accept even',\n",
       " 'accept evidence',\n",
       " 'accept may',\n",
       " 'accept premise',\n",
       " 'acceptable',\n",
       " 'acceptable range',\n",
       " 'acceptable range cmd',\n",
       " 'acceptable range orbiter',\n",
       " 'acceptable range rpm',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'acceptance sent',\n",
       " 'acceptance sent may',\n",
       " 'accepted',\n",
       " 'accepted doctrine',\n",
       " 'accepted doctrine clearly',\n",
       " 'accepted give',\n",
       " 'accepted give number',\n",
       " 'accepted presentations',\n",
       " 'accepted presentations published',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'access contact',\n",
       " 'access contact nasa',\n",
       " 'access digex',\n",
       " 'access digex com',\n",
       " 'access extra',\n",
       " 'access extra ram',\n",
       " 'access ftp',\n",
       " 'access huge',\n",
       " 'access huge astronomical',\n",
       " 'access one',\n",
       " 'access roms',\n",
       " 'access roms data',\n",
       " 'access satellite',\n",
       " 'access visa',\n",
       " 'access visa mastercard',\n",
       " 'accessed',\n",
       " 'accessed hours',\n",
       " 'accessed hours day',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidentally set',\n",
       " 'accidentally set blaze',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'accommodate',\n",
       " 'accomodate',\n",
       " 'accompanied',\n",
       " 'accompanied offsetting',\n",
       " 'accompanied offsetting reductions',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplish',\n",
       " 'accomplish exploration',\n",
       " 'accomplish exploration saturnian',\n",
       " 'accomplished',\n",
       " 'accor',\n",
       " 'accor higher',\n",
       " 'accor higher value',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'according bible',\n",
       " 'according bible eternal',\n",
       " 'according faq',\n",
       " 'according islamic',\n",
       " 'according islamic law',\n",
       " 'according jim',\n",
       " 'according jim way',\n",
       " 'according likes',\n",
       " 'according likes dislikes',\n",
       " 'according one',\n",
       " 'according robert',\n",
       " 'according robert weiss',\n",
       " 'account',\n",
       " 'account smile',\n",
       " 'account smile lot',\n",
       " 'accountable',\n",
       " 'accounting',\n",
       " 'accounting method',\n",
       " 'accounts',\n",
       " 'accredited',\n",
       " 'accumulate',\n",
       " 'accuracy',\n",
       " 'accuracy arc',\n",
       " 'accuracy arc minutes',\n",
       " 'accurate',\n",
       " 'accurate arc',\n",
       " 'accurate arc minute',\n",
       " 'accurate global',\n",
       " 'accurate global observations',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'ace',\n",
       " 'achieve',\n",
       " 'achieve orbit',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achieving dominance',\n",
       " 'achieving dominance marketplace',\n",
       " 'achieving goal',\n",
       " 'achieving goal gibbons',\n",
       " 'acid',\n",
       " 'acids',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledgement public',\n",
       " 'acknowledgement public hypocrisy',\n",
       " 'acknowledges',\n",
       " 'acm',\n",
       " 'acm siggraph',\n",
       " 'acorn',\n",
       " 'acquainted',\n",
       " 'acquainted also',\n",
       " 'acquainted also received',\n",
       " 'acquire',\n",
       " 'acquire intelligence',\n",
       " 'acquire intelligence happy',\n",
       " 'acronym',\n",
       " 'acronym list',\n",
       " 'acronyms',\n",
       " 'across',\n",
       " 'across country',\n",
       " 'across sky',\n",
       " 'acrv',\n",
       " 'acrv assured',\n",
       " 'acrv assured crew',\n",
       " 'acs',\n",
       " 'acsu',\n",
       " 'acsu buffalo',\n",
       " 'acsu buffalo edu',\n",
       " 'act',\n",
       " 'act faith',\n",
       " 'act god',\n",
       " 'act morality',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " \"action i'm\",\n",
       " 'action individual',\n",
       " 'action individual may',\n",
       " 'action standard',\n",
       " 'action standard conduct',\n",
       " 'actions',\n",
       " 'actions well',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activist interest',\n",
       " 'activist interest research',\n",
       " 'activities',\n",
       " 'activities key',\n",
       " 'activities orbiting',\n",
       " 'activities orbiting earth',\n",
       " 'activities practiced',\n",
       " 'activities practiced warrior',\n",
       " 'activity',\n",
       " 'activity far',\n",
       " 'activity far know',\n",
       " 'acts',\n",
       " 'acts specifically',\n",
       " 'actual',\n",
       " 'actual existance',\n",
       " 'actualization',\n",
       " 'actually',\n",
       " 'actually anything',\n",
       " 'actually anything perijove',\n",
       " 'actually believing',\n",
       " 'actually caused',\n",
       " 'actually flexible',\n",
       " 'actually flexible way',\n",
       " 'actually important',\n",
       " 'actually important things',\n",
       " 'actually interested',\n",
       " 'actually said',\n",
       " 'actually shown',\n",
       " 'actually simple',\n",
       " 'actually take',\n",
       " 'actually take stance',\n",
       " 'actually think',\n",
       " 'actually trying',\n",
       " 'actually turn',\n",
       " 'actually used',\n",
       " 'actually well',\n",
       " 'acuity',\n",
       " 'acuity better',\n",
       " 'acuity better uncorrected',\n",
       " 'acutally',\n",
       " 'adam',\n",
       " 'adam eve',\n",
       " 'adams',\n",
       " 'adams nsmca',\n",
       " 'adams nsmca acad',\n",
       " 'adams round',\n",
       " 'adams round way',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapting',\n",
       " 'add',\n",
       " 'add airmail',\n",
       " 'add airmail access',\n",
       " 'add another',\n",
       " 'add line',\n",
       " 'add list',\n",
       " 'add one',\n",
       " 'add support',\n",
       " 'add text',\n",
       " 'adda',\n",
       " 'added',\n",
       " 'added text',\n",
       " 'adding',\n",
       " 'addison',\n",
       " 'addison wesley',\n",
       " 'addition',\n",
       " 'addition faq',\n",
       " 'additional',\n",
       " 'additional information',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'address answer',\n",
       " 'address answer point',\n",
       " 'address box',\n",
       " 'address city',\n",
       " 'address city state',\n",
       " 'address convictions',\n",
       " 'address convictions regardless',\n",
       " 'address email',\n",
       " 'address email find',\n",
       " 'address get',\n",
       " 'address info',\n",
       " 'address information',\n",
       " 'address issue',\n",
       " 'address issue raised',\n",
       " 'address listed',\n",
       " 'address mark',\n",
       " 'address mark prado',\n",
       " 'address one',\n",
       " 'address password',\n",
       " 'address phone',\n",
       " 'address please',\n",
       " 'address please distribute',\n",
       " 'address pointer',\n",
       " 'address rather',\n",
       " 'address request',\n",
       " 'address request nssdca',\n",
       " 'address telephone',\n",
       " 'address telephone number',\n",
       " 'addressed',\n",
       " 'addressed key',\n",
       " 'addressed key issues',\n",
       " 'addressed order',\n",
       " 'addressed order reply',\n",
       " 'addressed verses',\n",
       " 'addressed verses copied',\n",
       " 'addresses',\n",
       " 'addresses multi',\n",
       " 'addresses multi author',\n",
       " 'addresses telephone',\n",
       " 'addresses telephone fax',\n",
       " 'addressing',\n",
       " 'addressing one',\n",
       " 'adds',\n",
       " 'adeos',\n",
       " 'adequate',\n",
       " 'adequate program',\n",
       " 'adequate program reserves',\n",
       " 'adequately',\n",
       " 'adherence',\n",
       " 'adhering',\n",
       " 'adj',\n",
       " 'adj material',\n",
       " 'adj material object',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'admin',\n",
       " 'administer',\n",
       " 'administration',\n",
       " 'administration pasadena',\n",
       " 'administration pasadena calif',\n",
       " 'administrative',\n",
       " 'administrative topics',\n",
       " 'administrative topics used',\n",
       " 'administrator',\n",
       " 'admiration',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admit assumption',\n",
       " 'admit assumption may',\n",
       " 'admit objection',\n",
       " 'admit objection entirely',\n",
       " 'admit probably',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admitted counting',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'adobe',\n",
       " 'adobe illustrator',\n",
       " 'adobe photoshop',\n",
       " 'adobe systems',\n",
       " 'adolf',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advance alan',\n",
       " 'advance alan jackson',\n",
       " 'advance help',\n",
       " 'advance hoi',\n",
       " 'advance pascal',\n",
       " 'advance pascal perret',\n",
       " 'advance please',\n",
       " 'advance tiang',\n",
       " 'advance tiang foo',\n",
       " 'advanced',\n",
       " 'advanced ray',\n",
       " 'advanced space',\n",
       " 'advancement',\n",
       " 'advancement space',\n",
       " 'advancement space industrialization',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advantage able',\n",
       " 'advantage using',\n",
       " 'advantages',\n",
       " 'adventists',\n",
       " 'adversary',\n",
       " 'adversely',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertisers',\n",
       " 'advertising',\n",
       " 'advertising help',\n",
       " 'advertising help defray',\n",
       " 'advertising space',\n",
       " 'advertising sure',\n",
       " 'advertising sure nasa',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advisory committee',\n",
       " 'advisory committee consider',\n",
       " 'advisory committee generally',\n",
       " 'advisory committee redesign',\n",
       " 'advisory panel',\n",
       " 'advocate',\n",
       " 'advocate lunar',\n",
       " 'advocate lunar power',\n",
       " 'advocated',\n",
       " 'advocated groups',\n",
       " 'advocated groups prices',\n",
       " 'advocates',\n",
       " 'aerial',\n",
       " 'aero',\n",
       " 'aero space',\n",
       " 'aerobraking',\n",
       " 'aerodynamic',\n",
       " 'aerodynamics',\n",
       " 'aeronautical',\n",
       " 'aeronautics',\n",
       " 'aeronautics astronautics',\n",
       " 'aeronautics space',\n",
       " 'aeronautics space administration',\n",
       " 'aerosol',\n",
       " 'aerosols',\n",
       " 'aerospace',\n",
       " 'aerospace ambassadors',\n",
       " 'aerospace industry',\n",
       " 'aerospace plane',\n",
       " 'aerospace technology',\n",
       " 'aerospace technology technical',\n",
       " 'aerospatiale',\n",
       " 'aesthetic',\n",
       " 'aesthetics',\n",
       " 'afb',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affect future',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliation',\n",
       " 'affiliations',\n",
       " 'affiliations addresses',\n",
       " 'affiliations addresses telephone',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmed',\n",
       " 'affirms',\n",
       " 'afford',\n",
       " 'afford fund',\n",
       " 'afford fund full',\n",
       " 'afford stuff',\n",
       " 'affordable',\n",
       " 'affordably',\n",
       " 'afit',\n",
       " 'afit mil',\n",
       " 'afit mil directory',\n",
       " 'afraid',\n",
       " \"afraid can't\",\n",
       " 'africa',\n",
       " 'african',\n",
       " 'african americans',\n",
       " 'aft',\n",
       " 'afterlife',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterwards',\n",
       " 'afterwards answer',\n",
       " 'afterwards answer question',\n",
       " 'age',\n",
       " 'age grace',\n",
       " 'age grace sin',\n",
       " 'agencies',\n",
       " 'agencies companies',\n",
       " 'agency',\n",
       " 'agency continous',\n",
       " 'agency continous funding',\n",
       " 'agency esa',\n",
       " \"agency's\",\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggravated',\n",
       " 'aggregate',\n",
       " 'aggressive',\n",
       " 'agnostic',\n",
       " 'agnosticism',\n",
       " 'agnostics',\n",
       " 'ago',\n",
       " 'ago going',\n",
       " 'ago going appear',\n",
       " 'ago hope',\n",
       " 'ago know',\n",
       " 'ago little',\n",
       " 'ago little reduced',\n",
       " 'ago men',\n",
       " 'ago moon',\n",
       " 'ago moon source',\n",
       " 'ago would',\n",
       " 'agree',\n",
       " 'agree deleted',\n",
       " 'agree disagree',\n",
       " 'agree generally',\n",
       " 'agree jesus',\n",
       " 'agree may',\n",
       " 'agree rather',\n",
       " 'agree really',\n",
       " 'agree really irrelevant',\n",
       " 'agree robert',\n",
       " 'agree robert weiss',\n",
       " 'agree say',\n",
       " 'agree say yup',\n",
       " \"agree that's\",\n",
       " \"agree today's\",\n",
       " \"agree today's world\",\n",
       " 'agreed',\n",
       " 'agreed upon',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agressive',\n",
       " 'agriculture',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahead time',\n",
       " 'ahem',\n",
       " 'ahmediye',\n",
       " 'ahmediye risalesi',\n",
       " 'ahmediye risalesi treatise',\n",
       " 'ahpcrc',\n",
       " 'ahpcrc umn',\n",
       " 'ahpcrc umn edu',\n",
       " 'ahura',\n",
       " 'ahura mazda',\n",
       " 'aiaa',\n",
       " 'aiaa american',\n",
       " 'aiaa american institute',\n",
       " 'aiaa paper',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aids',\n",
       " 'aiken',\n",
       " 'aiken south',\n",
       " 'aiken south carolina',\n",
       " 'aim',\n",
       " 'aim stanford',\n",
       " 'aim stanford edu',\n",
       " 'aimed',\n",
       " \"ain't\",\n",
       " 'aio',\n",
       " 'aio jsc',\n",
       " 'aio jsc nasa',\n",
       " 'aips',\n",
       " 'aips astronomical',\n",
       " 'aips astronomical image',\n",
       " 'air',\n",
       " 'air conditioners',\n",
       " 'air conditioners vacuums',\n",
       " 'air drag',\n",
       " 'air force',\n",
       " 'air force base',\n",
       " 'air force space',\n",
       " 'air pressure',\n",
       " 'air space',\n",
       " 'air space museum',\n",
       " 'air traffic',\n",
       " 'airborne',\n",
       " 'aircraft',\n",
       " 'aircraft flight',\n",
       " 'airframe',\n",
       " 'airliner',\n",
       " 'airmail',\n",
       " 'airmail access',\n",
       " 'airmail access visa',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airports con',\n",
       " 'airports con shrug',\n",
       " 'airspace',\n",
       " 'airways',\n",
       " 'airways america',\n",
       " 'airways america also',\n",
       " 'aix',\n",
       " 'ajackson',\n",
       " 'ajackson cch',\n",
       " 'ajackson cch cov',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alamos',\n",
       " 'alamos national',\n",
       " 'alamos national laboratory',\n",
       " 'alan',\n",
       " 'alan jackson',\n",
       " 'alan jackson mail',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alaska edu',\n",
       " \"alaska edu i'm\",\n",
       " 'albedo',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'albert einstein',\n",
       " 'alchemy',\n",
       " 'aldus',\n",
       " 'alert',\n",
       " 'alert argument',\n",
       " 'alert argument incredulity',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandria',\n",
       " 'alexei',\n",
       " 'alexei leonov',\n",
       " 'alexei leonov staged',\n",
       " 'alexia',\n",
       " 'alexia lis',\n",
       " 'alexia lis uiuc',\n",
       " 'alexis',\n",
       " 'alexis array',\n",
       " 'alexis array low',\n",
       " 'alfred',\n",
       " 'algebraic',\n",
       " 'algo',\n",
       " 'algorithm',\n",
       " 'algorithm determine',\n",
       " 'algorithm determine given',\n",
       " 'algorithm marching',\n",
       " 'algorithm used',\n",
       " 'algorithm would',\n",
       " 'algorithm would nice',\n",
       " 'algorithmic',\n",
       " 'algorithms',\n",
       " 'algorithms code',\n",
       " 'algorithms computer',\n",
       " 'algorithms computer graphics',\n",
       " 'algorithms ray',\n",
       " 'algorithms ray tracing',\n",
       " 'algorithms think',\n",
       " 'algorithms think making',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'aliasing',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'alive moon',\n",
       " 'alive moon year',\n",
       " 'alive today',\n",
       " 'allah',\n",
       " 'allah allah',\n",
       " \"allah's\",\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'alleged contradictions',\n",
       " 'allegiance',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allen sherzer',\n",
       " 'alley',\n",
       " 'alliant',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'allocated',\n",
       " 'allocation',\n",
       " 'allow',\n",
       " 'allow change',\n",
       " 'allow faiths',\n",
       " 'allow faiths believing',\n",
       " 'allow hussein',\n",
       " 'allow one',\n",
       " 'allowed',\n",
       " 'allowed constitution',\n",
       " 'allowed continue',\n",
       " 'allowed sink',\n",
       " 'allowed sink low',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allows image',\n",
       " 'allows people',\n",
       " 'allows user',\n",
       " 'allows users',\n",
       " 'alluded',\n",
       " 'ally',\n",
       " 'almanac',\n",
       " 'almanac mica',\n",
       " 'almanac mica produced',\n",
       " 'almighty',\n",
       " 'almost',\n",
       " 'almost always',\n",
       " 'almost certainly',\n",
       " 'almost entire',\n",
       " 'almost entire surface',\n",
       " 'almost entirely',\n",
       " 'almost every',\n",
       " 'almost everyone',\n",
       " 'almost everything',\n",
       " 'almost inaudible',\n",
       " 'almost like',\n",
       " 'almost nothing',\n",
       " 'alms',\n",
       " 'alone',\n",
       " 'alone find',\n",
       " 'alone night',\n",
       " 'alone night nasa',\n",
       " 'alone videotape',\n",
       " 'alone videotape author',\n",
       " 'along',\n",
       " 'along david',\n",
       " 'along david criswell',\n",
       " 'along fact',\n",
       " 'along line',\n",
       " 'along lines',\n",
       " 'along rest',\n",
       " 'along thread',\n",
       " 'along thread chaney',\n",
       " 'along way',\n",
       " 'alot',\n",
       " 'alot like',\n",
       " 'aloud',\n",
       " 'alpha',\n",
       " 'alpha shape',\n",
       " 'alphabetical',\n",
       " 'alphabetical order',\n",
       " 'already',\n",
       " 'already done',\n",
       " 'already given',\n",
       " 'already knew',\n",
       " 'already one',\n",
       " 'already reserved',\n",
       " 'already reserved please',\n",
       " 'already sulfate',\n",
       " 'already sulfate process',\n",
       " 'als',\n",
       " 'also',\n",
       " 'also add',\n",
       " 'also allows',\n",
       " 'also announced',\n",
       " 'also announced united',\n",
       " 'also anyone',\n",
       " 'also asked',\n",
       " 'also assume',\n",
       " 'also available',\n",
       " 'also available ames',\n",
       " 'also available mail',\n",
       " 'also available system',\n",
       " 'also available via',\n",
       " 'also believe',\n",
       " 'also book',\n",
       " 'also called',\n",
       " 'also campaigning',\n",
       " 'also campaigning remove',\n",
       " 'also carry',\n",
       " 'also chemical',\n",
       " 'also committed',\n",
       " 'also committed space',\n",
       " 'also contains',\n",
       " 'also contributed',\n",
       " 'also criticized',\n",
       " 'also defines',\n",
       " 'also described',\n",
       " 'also dial',\n",
       " 'also dial baud',\n",
       " 'also display',\n",
       " 'also done',\n",
       " 'also done military',\n",
       " 'also feel',\n",
       " 'also find',\n",
       " 'also find rather',\n",
       " 'also found',\n",
       " 'also gave',\n",
       " 'also get',\n",
       " 'also give',\n",
       " 'also good',\n",
       " 'also heard',\n",
       " 'also helped',\n",
       " \"also i've\",\n",
       " 'also important',\n",
       " 'also include',\n",
       " 'also include human',\n",
       " 'also included',\n",
       " 'also includes',\n",
       " 'also incorporated',\n",
       " 'also interested',\n",
       " 'also knew',\n",
       " 'also know',\n",
       " 'also known',\n",
       " 'also learned',\n",
       " 'also like',\n",
       " 'also made',\n",
       " 'also mail',\n",
       " 'also mail server',\n",
       " 'also makes',\n",
       " 'also many',\n",
       " 'also many atheists',\n",
       " 'also may',\n",
       " 'also means',\n",
       " 'also money',\n",
       " 'also much',\n",
       " 'also must',\n",
       " 'also must include',\n",
       " 'also need',\n",
       " 'also need contact',\n",
       " 'also needed',\n",
       " 'also note',\n",
       " 'also noted',\n",
       " 'also offers',\n",
       " 'also one',\n",
       " 'also people',\n",
       " 'also placed',\n",
       " 'also possible',\n",
       " 'also present',\n",
       " 'also provides',\n",
       " 'also provides partial',\n",
       " 'also provides tools',\n",
       " 'also reason',\n",
       " 'also received',\n",
       " 'also received legal',\n",
       " 'also remember',\n",
       " 'also said',\n",
       " 'also say',\n",
       " 'also see',\n",
       " 'also seem',\n",
       " 'also shareware',\n",
       " 'also show',\n",
       " 'also site',\n",
       " 'also sold',\n",
       " 'also spent',\n",
       " 'also stored',\n",
       " 'also subscribe',\n",
       " 'also supports',\n",
       " 'also tend',\n",
       " \"also there's\",\n",
       " 'also think',\n",
       " 'also took',\n",
       " 'also true',\n",
       " 'also try',\n",
       " 'also two',\n",
       " 'also updated',\n",
       " 'also updated daily',\n",
       " 'also use',\n",
       " 'also used',\n",
       " 'also want',\n",
       " 'also way',\n",
       " 'also welcome',\n",
       " 'also work',\n",
       " 'also working',\n",
       " 'also works',\n",
       " 'also would',\n",
       " 'also wrote',\n",
       " 'also wuarchive',\n",
       " 'alt',\n",
       " 'alt atheism',\n",
       " 'alt atheism alt',\n",
       " 'alt atheism archive',\n",
       " 'alt atheism faq',\n",
       " 'alt atheism moderated',\n",
       " 'alt atheism reading',\n",
       " 'alt atheism reject',\n",
       " 'alt atheist',\n",
       " 'alt binaries',\n",
       " 'alt binaries pictures',\n",
       " 'alt fan',\n",
       " 'alt religion',\n",
       " 'alt sex',\n",
       " 'altar',\n",
       " 'altar boy',\n",
       " 'altar boy finds',\n",
       " 'alter',\n",
       " 'alter bible',\n",
       " 'altered',\n",
       " 'altered reproduction',\n",
       " 'altered reproduction dissemination',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternative allow',\n",
       " 'alternative apply',\n",
       " 'alternative apply periphery',\n",
       " 'alternative funding',\n",
       " 'alternative funding nasa',\n",
       " 'alternative space',\n",
       " 'alternative space station',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " ...]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in tfidf.get_feature_names_out() if len(word) >= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 한국어 문서의 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('daum_movie_review.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "신과함께      4947\n",
       "택시운전사     2322\n",
       "인피니티 워    2042\n",
       "범죄도시      1939\n",
       "곤지암       1547\n",
       "라라랜드      1150\n",
       "코코         778\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.title, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11043"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3009                영상도 아름답고 음악도 좋았어요. 오랜만에 마음 따뜻해진 영화였어요.\n",
       "8833     3단계에서 울었어요....ㅠㅠ 앞으로 4단계나 더 남았다는걸 알고 통곡할 뻔 했어요...\n",
       "5244     Good... 착하게 살자.. 인간이 죄를 짓지 않을순없지만 죄를 지었으면 용서를 ...\n",
       "6381     컴퓨터 그래픽~ 이 볼만하지만 중간 지점가면 지루해지고 마지막 반전이.... 신파!...\n",
       "1766                                           잠못자고 볼 가치있음\n",
       "                               ...                        \n",
       "13123    5.18  민주화 운동의  상황을 실제로 찍은 영상을 토대로 연기하여 서로 번갈아가...\n",
       "3264                                         공포영화냐 코메디 영화냐\n",
       "9845                                      너네....까불지 말고 보라우\n",
       "10799                                     윤계상 연기 쩔음!! 쵴오~~\n",
       "2732                                       최고의 영화 중의 하나!!!\n",
       "Name: review, Length: 11043, dtype: object"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3682"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['몰입',\n",
       " '할수밖에',\n",
       " '없다',\n",
       " '.',\n",
       " '어렵게',\n",
       " '생각',\n",
       " '할',\n",
       " '필요없다',\n",
       " '.',\n",
       " '내',\n",
       " '가',\n",
       " '전투',\n",
       " '에',\n",
       " '참여',\n",
       " '한',\n",
       " '듯',\n",
       " '손',\n",
       " '에',\n",
       " '땀',\n",
       " '이남',\n",
       " '.']"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.nouns(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=okt.morphs,\n",
    "    max_features=2000,\n",
    "    min_df=5,\n",
    "    max_df=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;background-color: white;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7768722267499774"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.694731124388919"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10711     범죄도시\n",
       "9848      범죄도시\n",
       "14545       코코\n",
       "9017      신과함께\n",
       "8659      신과함께\n",
       "11692    택시운전사\n",
       "5911      신과함께\n",
       "6409      신과함께\n",
       "11275     범죄도시\n",
       "10818     범죄도시\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['신과함께', '범죄도시', '코코', '신과함께', '신과함께', '택시운전사', '신과함께', '신과함께',\n",
       "       '신과함께', '인피니티 워'], dtype=object)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범죄도시 신과함께 오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.\n",
      "범죄도시 범죄도시 조연들이 눈에 박힌다. 간만에 집중 ㅎ\n",
      "코코 코코 대감동을 선사. 인사이드 아웃을 잇는 픽사의 감동스토리. 신과함께의 멕시코판이라고나할까요??\n",
      "신과함께 신과함께 돈이 안아까웠던 영화ᆞᆞ  정말 좋았다\n",
      "신과함께 신과함께 역시 김용화감독이 영화는 잘 만들어요. 이제 VFX 제작 부문도 헐리우드 수준 이상입니다.\n",
      "택시운전사 택시운전사 민주화를 위해 힘써주신 분들께 감사하는 마음으로 살아야겠다.\n",
      "신과함께 신과함께 잠만 자다 왔음\n",
      "신과함께 신과함께 오랜만에 잼있고 좋은 영화를 봤다\n",
      "범죄도시 신과함께 잼남\n",
      "범죄도시 인피니티 워 대박~~\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in zip(y_test[:10], clf.predict(X_test_tfidf[:10]), X_test[:10]):\n",
    "    print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text):\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text):\n",
    "    #target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer3(text):\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append('/'.join([word, tag]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=twit_tokenizer3,\n",
    "    max_features=2000,\n",
    "    min_df=5,\n",
    "    max_df=0.5\n",
    ")\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7837544145612605\n",
      "0.7121129820749592\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train))\n",
    "print(clf.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789097165625283\n",
      "0.7180879956545356\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train))\n",
    "print(clf.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7837544145612605\n",
      "0.7129277566539924\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train))\n",
    "print(clf.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#130p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
